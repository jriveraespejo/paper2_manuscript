% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  authoryear,
  review,
  1p]{elsarticle}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\journal{Psychometrika}

\usepackage[]{natbib}
\bibliographystyle{elsarticle-harv}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Let's talk about Thurstone \& Co.: An information-theoretical model for comparative judgments, and its statistical translation},
  pdfauthor={Jose Manuel Rivera Espejo; Tine van van Daal; Sven De De Maeyer; Steven Gillis},
  pdfkeywords={causal inference, directed acyclic graphs, structural
causal models, bayesian statistical methods, thurstonian
model, comparative judgement, probability, statistical modeling},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\setlength{\parindent}{6pt}
\begin{document}

\begin{frontmatter}
\title{Let's talk about Thurstone \& Co.: An information-theoretical
model for comparative judgments, and its statistical translation}
\author[1]{Jose Manuel Rivera Espejo%
\corref{cor1}%
}
 \ead{JoseManuel.RiveraEspejo@uantwerpen.be} 
\author[1]{Tine van Daal%
%
}
 \ead{tine.vandaal@uantwerpen.be} 
\author[1]{Sven De Maeyer%
%
}
 \ead{sven.demaeyer@uantwerpen.be} 
\author[2]{Steven Gillis%
%
}
 \ead{steven.gillis@uantwerpen.be} 

\affiliation[1]{organization={University of Antwerp, Training and
education sciences},,postcodesep={}}
\affiliation[2]{organization={University of
Antwerp, Linguistics},,postcodesep={}}

\cortext[cor1]{Corresponding author}




        
\begin{abstract}
This study revisits Thurstone's law of comparative judgments (CJ) by
addressing two key limitations in traditional approaches. Firstly, it
addresses the overreliance on the assumptions of Thurstone's Case V in
the statistical analysis of CJ data. Secondly, it addresses the apparent
disconnect between CJ's approach to trait measurement and hypothesis
testing. We put forward a systematic approach based on causal analysis
and Bayesian statistical methods, which results in a model that
facilitates a more comprehensive understanding of the factors
influencing CJ experiments while offering a robust statistical
translation. The new model accommodates unequal dispersions and
correlations between stimuli, enhancing the reliability and validity of
CJ's trait estimation, thereby ensuring the accurate measurement and
interpretation of comparative data. The paper highlights the relevance
of this updated framework for modern empirical research, particularly in
education and social sciences. This contribution advances current
research methodologies, providing a robust foundation for future
applications in diverse fields.
\end{abstract}





\begin{keyword}
    causal inference \sep directed acyclic graphs \sep structural causal
models \sep bayesian statistical methods \sep thurstonian
model \sep comparative judgement \sep probability \sep 
    statistical modeling
\end{keyword}
\end{frontmatter}
    

\newcommand{\dsep}{\:\bot\:}
\newcommand{\ndsep}{\:\not\bot\:}
\newcommand{\cond}{\:|\:}

\section{Introduction}\label{sec-introduction}

In \emph{comparative judgment} (CJ) studies, judges assess a specific
trait or attribute across different stimuli by performing pairwise
comparisons \citep{Thurstone_1927a, Thurstone_1927b}. Each comparison
produces a dichotomous outcome, indicating which stimulus is perceived
to have a higher trait level. For example, when assessing writing
quality, judges compare pairs of written texts (the stimuli) to
determine the relative writing quality each text exhibit (the trait)
\citep{Laming_2004, Pollitt_2012b, Whitehouse_2012, vanDaal_et_al_2016, Lesterhuis_2018_thesis, Coertjens_et_al_2017, Goossens_et_al_2018, Bouwer_et_al_2023}.

Numerous studies have documented the effectiveness of CJ in assessing
traits and competencies over the past decade. These studies have
highlighted three aspects of the method's effectiveness: its
reliability, validity, and practical applicability. Research on
reliability suggests that CJ requires a relatively modest number of
pairwise comparisons \citep{Verhavert_et_al_2019, Crompvoets_et_al_2022}
to generate trait scores that are as precise and consistent as those
generated by other assessment methods
\citep{Coertjens_et_al_2017, Goossens_et_al_2018, Bouwer_et_al_2023}. In
addition, the evidence suggests that the reliability and time efficiency
of CJ are comparable, if not superior, to those of other assessment
methods when employing adaptive comparison algorithms
\citep{Pollitt_2012b, Verhavert_et_al_2022, Mikhailiuk_et_al_2021}.
Meanwhile, research on the validity of CJ scores indicates their
capacity to represent accurately the traits under measurement
\citep{Whitehouse_2012, vanDaal_et_al_2016, Lesterhuis_2018_thesis, Bartholomew_et_al_2018, Bouwer_et_al_2023}.
Moreover, research on CJ's practical applicability highlights its
versatility across both educational and non-educational contexts
\citep{Kimbell_2012, Jones_et_al_2015, Bartholomew_et_al_2018, Jones_et_al_2019, Marshall_et_al_2020, Bartholomew_et_al_2020, Boonen_et_al_2020}.

Nevertheless, despite the increasing number of CJ studies, research in
this domain remains unsystematic and fragmented, leaving several
critical issues unresolved. This study discusses two prominent issues
that can compromise the reliability and validity of CJ's trait
estimates. The first issue concerns the overreliance on Thurstone's Case
V assumptions in the statistical analysis of CJ data. The second
involves the apparent disconnect between CJ's approach to trait
measurement and hypothesis testing. The study then addresses these
challenges by adopting a more systematic and integrated approach
grounded in causal inference and Bayesian inference methods.

As a result, the study divides its content into six main sections.
Section~\ref{sec-thurstone_theory} provides an overview of Thurstone's
theory. Section~\ref{sec-theory-issues} discusses the identified issues
in detail. Section~\ref{sec-theoretical} updates the Thurstonian model
to address these challenges. The model integrates the theoretical core
principles alongside key assessment design features relevant to CJ
experiments, such as the selection of judges, stimuli, and comparisons.
Section~\ref{sec-statistical} translates these theoretical and practical
elements into a probabilistic statistical model for the analysis of
pairwise comparison data. Section~\ref{sec-discussion} discusses the
implications of the findings and explores avenues for future research.
Finally, Section~\ref{sec-conclusion} summarizes the study's key
insights.

\section{Thurstone's theory}\label{sec-thurstone_theory}

In its most general form, Thurstone's theory addresses pairwise
comparisons wherein a single judge evaluates multiple stimuli
\citep[pp.~267]{Thurstone_1927b}. The theory posits that two key factors
determine the dichotomous outcome of these comparisons: the discriminal
process of each stimulus and their discriminal difference. The
\emph{discriminal process} captures the psychological impact each
stimulus exerts on the judge or, more simply, his perception of the
stimulus trait. The theory assumes that the discriminal process for any
given stimulus forms a Normal distribution along the trait continuum
\citep[pp.~266]{Thurstone_1927b}. The mode (mean) of this distribution,
known as the \emph{modal discriminal process}, indicates the stimulus
position on this continuum, while its dispersion, referred to as the
\emph{discriminal dispersion}, reflects variability in the perceived
trait of the stimulus.

Figure~\ref{fig-discriminal_process} illustrates the hypothetical
discriminal processes along a quality trait continuum for two written
texts. The figure indicates that the modal discriminal process for Text
B is positioned further along the continuum than that of Text A
\((T_{B} > T_{A})\), suggesting that Text B exhibits higher quality.
Additionally, the figure highlights that Text B has a broader
distribution compared to Text A, which arises from its larger
discriminal dispersion \((\sigma_{B} > \sigma_{A})\).

\begin{figure}

\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{./images/png/discriminal_process.png}

}

\subcaption{\label{fig-discriminal_process}Discriminal processes}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{./images/png/discriminal_difference.png}

}

\subcaption{\label{fig-discriminal_difference}Discriminal difference}

\end{minipage}%

\caption{\label{fig-thurstone_theory}Hypothetical discriminal processes
and discriminant difference along a quality trait continuum for two
written texts.}

\end{figure}%

However, since the individual discriminal processes of the stimuli are
not directly observable, the theory introduces the \emph{law of
comparative judgment}. This law posits that in pairwise comparisons, a
judge perceives the stimulus with a discriminal process positioned
further along the trait continuum as possessing more of the trait
\citep[pp.~251]{Bramley_2008}. This suggests that the relative distance
between stimuli, rather than their absolute positions on the continuum,
likely defines the outcome of pairwise comparisons. Indeed, the theory
assumes that the difference between the underlying discriminal processes
of the stimuli, referred to as the \emph{discriminal difference},
determines the observed dichotomous outcome. Furthermore, the theory
assumes that because the individual discriminal processes form a Normal
distribution on the continuum, the discriminal difference will also
conform to a Normal distribution \citep{Andrich_1978}. In this
distribution, the mode (mean) represents the relative separation between
the stimuli, and its dispersion indicates the variability of that
separation.

Figure~\ref{fig-discriminal_difference} illustrates the distribution of
the discriminal difference for the hypothetical texts depicted in
Figure~\ref{fig-discriminal_process}. The figure indicates that the
judge perceives Text B as having significantly higher quality than Text
A. This conclusion is supported by two key observations: the positive
difference between their modal discriminal processes
\((T_{B} - T_{A} > 0)\) and the probability area where the discriminal
difference distinctly favors Text B over Text A, represented by the
shaded gray area denoted as \(P(B > A)\). As a result, the dichotomous
outcome of this comparison is more likely to favor Text B over Text A.

\section{Two prominent issues in CJ literature}\label{sec-theory-issues}

This section discusses the two prominent issues that can undermine the
reliability and validity of CJ's trait estimates.
Section~\ref{sec-theory-issue1} examines the overreliance on Thurstone's
Case V assumptions in the statistical analysis of CJ data.
Section~\ref{sec-theory-issue2} focuses on the apparent disconnect
between CJ's approach to trait measurement and hypothesis testing.

\subsection{The Case V and the statistical analysis of CJ
data}\label{sec-theory-issue1}

Thurstone noted from the outset that the general form of the theory, as
outlined in Section~\ref{sec-thurstone_theory}, gave rise to a trait
scaling problem. Specifically, the model required estimating more
``unknown'' parameters than the available pairwise comparisons
\citep[pp.~267]{Thurstone_1927b}. To address this issue and facilitate
the practical implementation of the theory, he developed five cases
derived from this general form, each progressively incorporating
additional simplifying assumptions into the model.

In Case I, Thurstone postulated that pairs of stimuli would maintain a
constant correlation across all comparisons. In Case II, he allowed
multiple judges to undertake comparisons instead of confining
evaluations to a single judge. In Case III, he posited that there was no
correlation between stimuli. In Case IV, he assumed that the stimuli
exhibited similar dispersions. Finally, in Case V, he replaced this
assumption with the condition that stimuli had equal discriminal
dispersions. Table~\ref{tbl-thurstone_cases} summarizes the assumptions
of the general form and the five cases. For a detailed discussion of
these cases and their progression, refer to \citet{Thurstone_1927b} and
\citet[pp.~248--253]{Bramley_2008}.

\begin{table}

\caption{\label{tbl-thurstone_cases}Thurstones cases and their
asumptions}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{./images/png/thurstone_cases.png}

}

\end{table}%

Notably, despite relying on the most extensive set of simplifying
assumptions
\citetext{\citealp[pp.~253]{Bramley_2008}; \citealp[pp.~677]{Kelly_et_al_2022}},
Case V remains the most widely used case in the CJ literature. This
popularity stems mainly from its simplified statistical representation
in the Bradley-Terry-Luce (BTL) model
\citep{Bradley_et_al_1952, Luce_1959}. The BTL model mirrors the
assumptions of Case V, with one notable distinction: whereas Case V
assumes a Normal distribution for the stimuli's discriminal processes,
the BTL model uses the more mathematically tractable Logistic
distribution \citep[pp.~254]{Andrich_1978, Bramley_2008} (see
Table~\ref{tbl-thurstone_cases}). This substitution has little impact on
the model's estimation or interpretation, as the Normal and Logistic
distributions exhibit analogous statistical properties, differing only
by a scaling factor of approximately \(1.7\)
\citep[pp.~16]{vanderLinden_et_al_2017_I}.

However, Thurstone originally developed Case V to provide a ``rather
coarse scaling'' of traits \citep[pp.~269]{Thurstone_1927b},
prioritizing statistical simplicity over precision in trait measurement
\citep[pp.~677]{Kelly_et_al_2022}. He explicitly warned against its
untested application, stating that its use ``should not be made without
(an) experimental test'' \citep[pp.~270]{Thurstone_1927b}. Furthermore,
he acknowledged that some assumptions could prove problematic when
researchers assess complex traits or heterogeneous stimuli
\citep[pp.~376]{Thurstone_1927a}. Consequently, given that modern CJ
applications frequently involve such traits and stimuli, two main
assumptions of Case V and, by extension, of the BTL model may not
consistently hold in theory or practice, namely the assumption of equal
dispersion and zero correlation between stimuli.

\subsubsection{The assumption of equal dispersions between
stimuli}\label{sec-theory-issue1a}

According to the theory, discrepancies in the discriminal dispersions of
stimuli shape the distribution of the discriminal difference, exerting a
direct influence on the outcome of pairwise comparisons. A thought
experiment can illustrate this concept. In this experiment, the
researcher observes the discriminal processes for the texts depicted in
Figure~\ref{fig-discriminal_process}. Furthermore, the experiment
assumes that the discriminal dispersion for Text A remains constant and
that the texts are uncorrelated \((\rho=0)\). In this scenario,
Figure~\ref{fig-dispersion} reveals that an increase in the uncertainty
associated with the perception of Text B in comparison to Text A,
\((\sigma_{B}-\sigma_{A})\), broadens the distribution of their
discriminal difference. This broadening affects the probability area
where the discriminal difference distinctly favors Text B over Text A,
expressed as \(P(B > A)\), ultimately influencing the comparison
outcome. Additionally, the figure reveals that when the discriminal
dispersions of the texts are equal \((\sigma_{B}-\sigma_{A}=0)\), the
discriminal difference is more narrow compared to situations where their
dispersions differ. Consequently, the discriminal difference is more
likely to favor Text B over Text A (shaded gray area)

\begin{figure}

\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{./images/png/dispersion.png}

}

\subcaption{\label{fig-dispersion}Discrepancies in the dispersions of
stimuli}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{./images/png/correlation.png}

}

\subcaption{\label{fig-correlation}Correlation between stimuli}

\end{minipage}%

\caption{\label{fig-caseV_issues}The effect of dispersion discrepancies
and stimulus correlation on the distribution of the discriminal
difference.}

\end{figure}%

In experimental practice, however, the thought experiment occurs in
reverse. Researchers first observe the comparison outcome and then use
the BTL model to infer the discriminal difference between the stimuli
and their respective discriminal processes
\citep[pp.~373]{Thurstone_1927a}. Therefore, the outcome's ability to
reflect the ``true'' differences between stimuli largely depends on the
validity of the model's assumptions \citep[pp.~150]{Kohler_et_al_2019},
particularly the assumption of equal dispersions. For instance, when
researchers observe a sample of outcomes favoring Text B over Text A and
correctly assume equal dispersions between the texts, the BTL model
estimates a discriminal difference distribution that accurately
represents the ``true'' discriminal difference of the texts. This
scenario is illustrated in Figure~\ref{fig-dispersion}, when the model's
discriminal difference distribution aligns with the ``true''
distribution, represented by the thick continuous line corresponding to
\(\sigma_{B}-\sigma_{A}=0\). The accuracy of the discriminal difference
then ensures reliable estimates for the texts' discriminal processes
{(citation needed?)}.

However, Thurstone argued that the assumption of equal dispersions may
not be applicable when researchers assess complex traits or
heterogeneous stimuli \citep[pp.~376]{Thurstone_1927a}, as these traits
and stimuli can introduce judgment discrepancies due to their unique
features
\citep{vanDaal_et_al_2016, Lesterhuis_2018, Chambers_et_al_2022}.
Indeed, evidence of this violation may already be present in the CJ
literature in the form of misfit statistics, which measure judgment
discrepancies associated with specific stimuli
\citetext{\citealp[pp.~12]{Pollitt_2004}; \citealp[pp.~20]{Goossens_et_al_2018}}.
For example, labeling texts as ``misfits'' indicates that comparisons
involving these texts result in more judgment discrepancies than those
involving other texts
\citep{Pollitt_2012a, Pollitt_2012b, vanDaal_et_al_2016, Goossens_et_al_2018}.
These discrepancies, in turn, suggest that the discriminal differences
for ``misfit'' texts have broader distributions, indicating that their
discriminal processes may also exhibit more variation than that of other
texts. A similar line of reasoning applies to the concept of ``misfit''
judges, whose evaluations deviate substantially from the shared
consensus due to the unique characteristics of the stimuli or the judges
themselves. These ``misfit'' judges and their associated deviations can
give rise to additional statistical and measurement issues, which we
discuss in more detail in Section~\ref{sec-theory-issue1b}.

Thus, erroneously assuming equal dispersions between stimuli, can give
rise to significant statistical and measurement issues. For instance,
the model may overestimate the degree to which the outcome accurately
reflects the ``true'' discriminal differences between stimuli. This
overestimation can result in researchers drawing spurious conclusions
about these differences \citep[pp.~370]{McElreath_2020} and, by
extension, about the underlying discriminal processes of stimuli.
Figure~\ref{fig-dispersion} also illustrates this issue when the model's
discriminal difference distribution aligns with the thick continuous
line for \(\sigma_{B}-\sigma_{A}=0\), while the ``true'' discriminal
difference follows any discontinuous line where
\(\sigma_{B}-\sigma_{A} \neq 0\). Additionally, if researchers recognize
that misfit statistics highlight these critical differences in
dispersions, the conventional CJ practice of excluding stimuli based on
these statistics
\citep{Pollitt_2012a, Pollitt_2012b, vanDaal_et_al_2016, Goossens_et_al_2018}
can unintentionally discard valuable information, introducing bias into
trait estimates \citep[chap.~12]{Zimmerman_1994, McElreath_2020}. The
direction and magnitude of these biases are often unpredictable, as they
depend on which stimuli are excluded from the analysis.

\subsubsection{The assumption of zero correlation between
stimuli}\label{sec-theory-issue1b}

The correlation, represented by the symbol \(\rho\), measures how much a
judge's perception of a specific trait in one stimulus depends on their
perception of the same trait in another. As with the discriminal
dispersions, this correlation shapes the distribution of the discriminal
difference, directly impacting the outcomes of pairwise comparisons. A
similar thought experiment, as the one in
Section~\ref{sec-theory-issue1a}, can illustrate this concept. The
experiment now assumes that the discriminal dispersions for both texts
remain constant. Figure~\ref{fig-correlation} reveals that as the
correlation between the texts increases, the distribution of their
discriminal difference becomes narrower. This narrowing affects the area
under the curve where the discriminal difference distinctly favors Text
B over Text A, denoted as \(P(B > A)\), thus influencing the comparison
outcome. Furthermore, the figure shows that when two texts are
independent or uncorrelated \((\rho=0)\), their discriminal difference
is less narrow compared to scenarios where the texts are highly
correlated. Consequently, the discriminal difference is less likely to
favor Text B over Text A (shaded gray area).

Again, in experimental practice, researchers approach this process in
reverse. They begin by observing the sample of outcomes favoring Text B
over Text A and then use the BTL model to estimate the discriminal
difference and the discriminal processes of the stimuli. Given that the
BTL model assumes independent discriminal processes across comparisons,
if this assumption holds, then the model estimates a discriminal
difference distribution that accurately reflects the ``true''
discriminal difference of the texts. This scenario is also illustrated
in Figure~\ref{fig-correlation} when the discriminal difference
distribution of the model aligns with the ``true'' distribution,
represented by the thick continuous line corresponding to \(\rho=0\).
Once more, the accuracy of the discriminal difference ensures reliable
estimates for the discriminal processes of the texts {(citation
needed?)}.

Notably, Thurstone attributed the lack of correlation between stimuli to
the cancellation of potential judges' biases. He argued that this
cancellation resulted from two opposing and equally weighted effects
occurring during pairwise comparisons \citep[pp.~268]{Thurstone_1927b}.
\citet{Andrich_1978} provided a mathematical demonstration of this
cancellation using the BTL model under the assumption of discriminal
processes with additive biases. However, it is easy to imagine at least
two scenarios in which the zero correlation assumption is almost
certainly invalid: when the pairwise comparison involves
multidimensional, complex traits with heterogeneous stimuli and when an
additional hierarchical structure is relevant to the stimuli.

In the first scenario, the intricate aspects of multidimensional,
complex traits may introduce dependencies between the stimuli due to
certain judges' biases that resist cancellation. Research on text
quality suggests that when judges evaluate these traits, they often rely
on various intricate characteristics of the stimuli to form their
judgments
\citep{vanDaal_et_al_2016, Lesterhuis_2018, Chambers_et_al_2022}. These
additional relevant characteristics, which are unlikely to be equally
weighted or opposing, can exert an uneven influence on judges'
perceptions, creating biases in their judgments and, ultimately,
introducing dependencies between stimuli
\citep[pp.~346]{vanderLinden_et_al_2017_II}. For example, this could
occur when a judge assessing the argumentative quality of a text places
more weight on its grammatical accuracy than other judges, thereby
favoring texts with fewer errors but weaker arguments. While direct
evidence for this particular scenario is lacking, studies such as
\citet{Pollitt_et_al_2003} demonstrate the presence of such biases,
supporting the notion that the factors influencing pairwise comparisons
may not always cancel out.

In the second scenario, the shared context or inherent connections
created by additional hierarchical structures may further introduce
dependencies between stimuli, creating a statistical phenomenon known as
clustering \citep{Everitt_et_al_2010}. Although the CJ literature
acknowledges the existence of such hierarchical structures, the
statistical handling of this additional source of dependence between
stimuli has been inadequate. For instance, when CJ data incorporates
multiple samples of stimuli from the same individuals, researchers
frequently rely on (average) estimated BTL scores to conduct subsequent
analyses and tests at the individual hierarchical level
\citep{Bramley_et_al_2019, Boonen_et_al_2020, Bouwer_et_al_2023, vanDaal_et_al_2017, Jones_et_al_2019, Gijsen_et_al_2021}.
This approach, however, can introduce additional statistical and
measurement issues, which we discuss in greater detail in
Section~\ref{sec-theory-issue2}.

In any case, similar to Section~\ref{sec-theory-issue1a}, assuming zero
correlation between stimuli by neglecting additional relevant traits,
excluding judges based on misfit statistics, or ignoring hierarchical
(grouping) structures can cause significant statistical and measurement
issues. In general, the model may over- or underestimate how accurately
the outcome reflects the ``true'' discriminal differences between
stimuli. Such inaccuracies can result in spurious inferences about these
differences and, by extension, about the stimuli's discriminal
processes. This scenario is illustrated by Figure~\ref{fig-correlation},
when the model's discriminal difference distribution aligns with the
thick continuous line for \(\rho=0\), while the ``true'' discriminal
difference follows any discontinuous line where \(\rho \neq 0\).

In particular, neglecting relevant traits, such as judges' biases, can
cause dimensional mismatches in the BTL model, artificially inflating
the trait's reliability \citep[pp.~341]{Hoyle_et_al_2023} or, worse,
introducing bias into the trait's estimates \citep{Ackerman_1989}.
Excluding judges based on misfit statistics risks discarding valuable
information, which may further bias the trait's estimates
\citep[chap.~12]{Zimmerman_1994, McElreath_2020}. Finally, ignoring
hierarchical structures may reduce the precision of model parameter
estimates, potentially overestimating the trait's reliability
\citep[pp.~482]{Hoyle_et_al_2023}.

\subsection{The disconnect between trait measurement and hypothesis
testing}\label{sec-theory-issue2}

Building on the previous section, it is clear that, despite its
limitations, the BTL model is commonly used as a measurement model in CJ
assessments. A measurement model specifies how manifest variables
contribute to the estimation of latent variables
\citep{Everitt_et_al_2010}. For example, when evaluating writing
quality, researchers use the BTL model to process the dichotomous
outcomes resulting from the pairwise comparisons (the manifest
variables) to estimate scores that reflect the underlying level of
writing quality (the latent variable)
\citep{Laming_2004, Pollitt_2012b, Whitehouse_2012, vanDaal_et_al_2016, Lesterhuis_2018_thesis, Coertjens_et_al_2017, Goossens_et_al_2018, Bouwer_et_al_2023}.

Researchers then typically use these estimated BTL scores, or their
transformations, to conduct additional analyses or hypothesis tests. For
example, these scores have been used to identify `misfit' judges and
stimuli \citep{Pollitt_2012b, vanDaal_et_al_2016, Goossens_et_al_2018},
detect biases in judges' ratings
\citep{Pollitt_et_al_2003, Pollitt_2012b}, calculate correlations with
other assessment methods \citep{Goossens_et_al_2018, Bouwer_et_al_2023},
or test hypotheses related to the underlying trait of interest
\citep{Bramley_et_al_2019, Boonen_et_al_2020, Bouwer_et_al_2023, vanDaal_et_al_2017, Jones_et_al_2019, Gijsen_et_al_2021}.

However, the statistical literature advises caution when using estimated
scores for additional analyses and tests. A key consideration is that
BTL scores are parameter estimates that inherently carry uncertainty.
Ignoring this uncertainty can bias the analysis and reduce the precision
of hypothesis tests. Notably, the direction and magnitude of such biases
are often unpredictable. Results may be attenuated, exaggerated, or
remain unaffected depending on the degree of uncertainty in the scores
and the actual effects being tested
\citetext{\citealp[pp.~25]{Kline_et_al_2023}; \citealp[pp.~137]{Hoyle_et_al_2023}}.
Finally, the reduced precision in hypothesis tests diminishes their
statistical power, increasing the likelihood of committing type-I or
type-II errors \citep{McElreath_2020}.

In aggregate, the overreliance on Thurstone's Case V assumptions in the
statistical analysis of CJ data can compromise the reliability of CJ's
trait estimates. This overreliance, coupled with the apparent disconnect
between CJ's approach to trait measurement and hypothesis testing, may
also undermine the validity of these estimates
\citep[pp.~2]{Perron_et_al_2015}. Consequently, addressing these issues
by adopting a more systematic and integrated approach could offer
several statistical and measurement benefits.

\section{Extending Thurstone's model}\label{sec-theoretical}

This section addresses the challenges outlined in
Section~\ref{sec-theory-issues} by leveraging the structural approach to
causal inference to extend Thurstone's model. The extension combines the
core theoretical principles from Section~\ref{sec-thurstone_theory} with
several key assessment design features relevant to CJ experiments, such
as the selection of judges, stimuli, and comparisons. Specifically,
Section~\ref{sec-theory-theoretical_P} incorporates the theoretical
principles into a \emph{conceptual-population model}. Conversely,
Section~\ref{sec-theory-theoretical_SC} integrates the assessment design
features into a \emph{sample-comparison model}. Combining these elements
helps to elucidate how all actors and processes interact during CJ
experiments.

The \emph{structural approach} to causal inference provides a formal
framework for identifying causes and estimating their effects using
data. This approach uses structural causal models (SCMs) and directed
acyclic graphs (DAGs)
\citep{Pearl_2009, Pearl_et_al_2016, Gross_et_al_2018, Neal_2020} to
formally and graphically represent the assumed causal structure of a
system, such as the one found in CJ experiments. Essentially, SCMs and
DAGs function as \emph{conceptual models} on which identification
analysis rests \citep[pp.~4]{Schuessler_et_al_2023}. Identification
analysis helps researchers determine whether an estimator can accurately
compute an estimand based solely on its (causal) assumptions, regardless
of random variability \citep[pp.~4]{Schuessler_et_al_2023}. Here,
\emph{estimands} represent the specific quantities researchers aim to
determine \citep{Everitt_et_al_2010}. \emph{Estimators} denote the
methods or functions that transform data into an estimate
\citep{Neal_2020}, while \emph{estimates} are the numerical values
approximating the estimand. These estimates are obtained through
\emph{estimation}, which is the process that integrates data with an
estimator \citep{Everitt_et_al_2010}.

For instance, researchers might aim to answer the question: ``To what
extent do different teaching methods influence students' ability to
produce high-quality written texts?'' To investigate this, they could
design a CJ experiment by randomly assigning students to two groups,
each exposed to a different teaching method. Afterward, judges would
compare pairs of written texts, generating a dichotomous outcome that
reflects the relative quality of each text. In this scenario,
researchers can rephrase the research question as the estimand:
``\emph{On average}, is there a difference in the ability to produce
high-quality written texts between the two groups of students?''.
Researchers would then use estimates from the BTL model, or its
transformations, to approximate this estimand.

However, Section~\ref{sec-theory-issues} provides compelling evidence
that the BTL model suffers from several statistical and measurement
issues, including identification problems. These issues ultimately raise
concerns about the consistency of the model's estimates. An estimator is
\emph{consistent} if it converges to the ``true'' value of an estimand
as the data size approaches infinity \citep{Everitt_et_al_2010}. Since
identification is a prerequisite for consistency, the absence of proper
identification means that researchers cannot achieve consistency, even
with ``infinite'' and error-free data. As a result, deriving meaningful
insights from finite data also becomes impossible
\citep[pp.~5]{Schuessler_et_al_2023}.

Luckily, SCMs and DAGs support identification analysis through two key
advantages. First, regardless of complexity, they can represent various
causal structures using only five fundamental building blocks
\citep{Neal_2020, McElreath_2020}. This feature allows researchers to
decompose complex structures into manageable components, facilitating
their analysis \citep{McElreath_2020}. Second, they depict causal
relationships in an interactive, non-parametric manner. This flexibility
enables feasible identification strategies without defining the
variables' data types, the functional forms, or their parameters
\citep[pp.~35]{Pearl_et_al_2016}.

\subsection{The conceptual-population
model}\label{sec-theory-theoretical_P}

Before integrating the theoretical principles from
Section~\ref{sec-thurstone_theory}, it is important to define SCMs and
DAGs. SCMs are formal mathematical models defined by a set of
\emph{endogenous} variables, a set of \emph{exogenous} variables, and a
set of functions \citep{Pearl_2009, Cinelli_et_al_2020}. Endogenous
variables are those whose causal mechanisms a researcher chooses to
model \citep{Neal_2020}. In contrast, exogenous variables represent
\emph{errors} or \emph{disturbances} arising from omitted factors that
the investigator chooses not to model explicitly
\citep[pp.~27,68]{Pearl_2009}. Lastly, the functions, referred to as
\emph{structural equations}, express the endogenous variables as
non-parametric functions of other variables. These function use the
symbol `\(:=\)' to denote the asymmetrical causal dependence between
variables and the symbol `\(\:\bot\:\)' to represent
\emph{d-separation}, a concept akin to (conditional) independence.

Notably, every SCM has an associated DAG
\citep{Pearl_et_al_2016, Cinelli_et_al_2020}. A DAG is a graph
consisting of nodes connected by edges, where the nodes represent random
variables. The term \emph{directed} means that the edges extend from one
node to another, with arrows indicating the direction of causal
influence. The term \emph{acyclic} implies that the causal influences do
not form loops, ensuring the influences do not cycle back on themselves
\citep{McElreath_2020}. DAGs represent observed variables as solid black
circles, while they use open circles for unobserved (latent) variables
\citep{Morgan_et_al_2014}. While the \emph{standard representation} of
DAGs typically omits exogenous variables for simplicity, the
\emph{magnified representation} includes them, offering offering the
advantage of highlighting potential issues related to conditioning and
confounding \citep{Cinelli_et_al_2020}.

Figure~\ref{fig-CJ1} displays CJ's outcome, discriminal difference,
discriminal processes and judges' biases assumed by the Thurstone's
theory. Notice that in the figure, the structural

\begin{figure}[H]

\begin{minipage}{\linewidth}

\centering{

\[
\begin{aligned}
  O_{kjabi_{1}i_{2}} & := f_{O}(D_{kjabi_{1}i_{2}}) \\
  D_{kjabi_{1}i_{2}} & := f_{D}(PT_{kjai_{1}}, PT_{kjbi_{2}}) \\
  PT_{kjai_{1}} & := f_{PT}(T_{ai_{1}}, T_{bi_{2}}, B_{kj})
\end{aligned}
\]

}

\subcaption{\label{fig-CJ1_scm}SCM}

\end{minipage}%
\newline
\begin{minipage}{\linewidth}

\centering{

\includegraphics[width=0.45\linewidth,height=\textheight,keepaspectratio]{./images/png/CJ_TM_04.png}

}

\subcaption{\label{fig-CJ1_DAG}DAG}

\end{minipage}%

\caption{\label{fig-CJ1}CJ's outcome, discriminal difference,
discriminal processes and judges' biases}

\end{figure}%

without loosing generality, the (latent) ``perceived'' and ``true''
discriminal processes for the stimuli can be depicted in a vector for
each judge, as in

\begin{figure}

\centering{

\includegraphics[width=0.44\linewidth,height=\textheight,keepaspectratio]{./images/png/CJ_TM_05.png}

}

\caption{\label{fig-CJ_TM_05}}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.68\linewidth,height=\textheight,keepaspectratio]{./images/png/CJ_TM_10.png}

}

\caption{\label{fig-CJ_TM_10}}

\end{figure}%

\subsection{The sample-comparison
model}\label{sec-theory-theoretical_SC}

Considering the sampling mechanism

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{./images/png/CJ_TM_12.png}

}

\caption{\label{fig-CJ_TM_12}}

\end{figure}%

Considering comparison mechanisms

\begin{figure}

\centering{

\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{./images/png/CJ_TM_14.png}

}

\caption{\label{fig-CJ_TM_14}}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{./images/png/CJ_TM_15.png}

}

\caption{\label{fig-CJ_TM_15}}

\end{figure}%

\section{Extending the BTL model}\label{sec-statistical}

\section{Discussion}\label{sec-discussion}

\subsection{Findings}\label{sec-discussion-finding}

\subsection{Limitations and further
research}\label{sec-discussion-limitations}

\section{Conclusion}\label{sec-conclusion}

\newpage{}

\section*{Declarations}\label{declarations}
\addcontentsline{toc}{section}{Declarations}

\textbf{Funding:} The project was founded through the Research Fund of
the University of Antwerp (BOF).

\textbf{Financial interests:} The authors have no relevant financial
interest to disclose.

\textbf{Non-financial interests:} The authors have no relevant
non-financial interest to disclose.

\textbf{Ethics approval:} The University of Antwerp Research Ethics
Committee has confirmed that no ethical approval is required.

\textbf{Consent to participate:} Not applicable

\textbf{Consent for publication:} All authors have read and agreed to
the published version of the manuscript.

\textbf{Availability of data and materials:} No data was utilized in
this study.

\textbf{Code availability:} All the code utilized in this research is
available in the digital document located at:
\url{https://jriveraespejo.github.io/paper2_manuscript/}.

\textbf{AI-assisted technologies in the writing process:} The authors
utilized a range of AI-based language tools throughout the preparation
of this work. They occasionally employed the tools to refine phrasing
and optimize wording, ensuring appropriate language use and enhancing
the manuscript's clarity and coherence. The authors take full
responsibility for the final content of the publication.

\textbf{CRediT authorship contribution statement:}
\emph{Conceptualization:} S.G., S.DM., T.vD., and J.M.R.E;
\emph{Methodology:} S.DM., T.vD., and J.M.R.E; \emph{Software:}
J.M.R.E.; \emph{Validation:} J.M.R.E.; \emph{Formal Analysis:} J.M.R.E.;
\emph{Investigation:} J.M.R.E; \emph{Resources:} S.G., S.DM., and T.vD.;
\emph{Data curation:} J.M.R.E.; \emph{Writing - original draft:}
J.M.R.E.; \emph{Writing - review and editing:} S.G., S.DM., and T.vD.;
\emph{Visualization:} J.M.R.E.; \emph{Supervision:} S.G. and S.DM.;
\emph{Project administration:} S.G. and S.DM.; \emph{Funding
acquisition:} S.G. and S.DM.

\newpage{}

\section{Appendix}\label{sec-appendix}

This section introduces fundamental statistical and causal inference
concepts necessary for understanding the core theoretical principles
described in this document. It does not, however, offer a comprehensive
overview of causal inference methods. Readers seeking more in-depth
understanding may wish to explore introductory papers such as
\citet{Pearl_2010}, \citet{Rohrer_2018}, \citet{Pearl_2019}, and
\citet{Cinelli_et_al_2020}. They may also find it helpful to consult
introductory books like \citet{Pearl_et_al_2018}, \citet{Neal_2020}, and
\citet{McElreath_2020}. For more advanced study, readers may refer to
seminal intermediate papers such as \citet{Neyman_et_al_1923},
\citet{Rubin_1974}, \citet{Spirtes_et_al_1991}, and \citet{Sekhon_2009},
as well as books such as \citet{Pearl_2009}, \citet{Morgan_et_al_2014},
and \citet{Hernan_et_al_2020}.

\subsection{Empirical research and randomized
experiments}\label{sec-appendix-A}

Empirical research uses evidence from observation and experimentation to
address real-world challenges. In this context, researchers typically
formulate their research questions as \emph{estimands} or \emph{targets
of inference}, i.e., the specific quantities they seek to determine
\citep{Everitt_et_al_2010}. For instance, researchers might be
interested in answering the following question: ``To what extent do
different teaching methods \((T)\) influence students' ability to
produce high-quality written texts \((Y)\)?'' To investigate this,
researchers could randomly assign students to two groups, each exposed
to a different teaching method \((T_{i} = \{1,2\})\). Then, they would
perform pairwise comparisons, generating a dichotomous outcome
\((Y_{i} = \{0,1\})\) showing which student exhibits more of the
ability. In this scenario, the research question can be rephrased as the
estimand, ``\emph{On average}, is there a difference in the ability to
produce high-quality written texts between the two groups of students?''
and this estimand can be mathematically represented by the random
associational quantity in Equation~\ref{eq-group_diff}, where
\(E[\cdot]\) denotes the expected value.

\begin{equation}\phantomsection\label{eq-group_diff}{
E[Y_{i} \:|\:T_{i}=1] - E[Y_{i} \:|\:T_{i}=2]
}\end{equation}

Researchers then proceed to identify the estimands.
\emph{Identification} determines whether an estimator can accurately
compute the estimand based solely on its assumptions, regardless of
random variability \citep[pp.~4]{Schuessler_et_al_2023}. An
\emph{estimator} refers to a method or function that transforms data
into an estimate \citep{Neal_2020}. \emph{Estimates} are numerical
values that approximate the estimand derived through the process of
\emph{estimation}, which integrates data with an estimator
\citep{Everitt_et_al_2010}. The Identification-Estimation flowchart
\citep{McElreath_2020, Neal_2020}, shown in Figure~\ref{fig-IEflow},
visually represents the transition from estimands to estimates.

\begin{figure}

\centering{

\includegraphics[width=0.35\linewidth,height=\textheight,keepaspectratio]{images/png/IEflow.png}

}

\caption{\label{fig-IEflow}Identification-Estimation flowchart.
Extracted and slightly modified from \citet[pp.~32]{Neal_2020}}

\end{figure}%

Identification is a necessary condition to ensure \emph{consistent}
estimators. An estimator achieves \emph{consistency} when it converges
to the ``true'' value of an estimand as the data size approaches
infinity \citep{Everitt_et_al_2010}. Without identification, researchers
cannot achieve consistency, even with ``infinite'' and error-free data.
As a result, deriving meaningful insights about an estimand from finite
data becomes impossible \citep[pp.~5]{Schuessler_et_al_2023}. Therefore,
to ensure accurate and reliable estimates, researchers prioritize
estimators with desirable identification properties. For instance, the
Z-test is a widely used estimator for comparing group proportions,
yielding accurate estimates when its underlying assumptions are
satisfied \citep{Kanji_2006}. Furthermore, researchers can interpret
estimates from the Z-test as causal, provided the data is collected
through a randomized experiment.

Randomized experiments are widely recognized as the gold standard in
evidence-based science \citep{Hariton_et_al_2018, Hansson_2014}. This
recognition stems from their ability to enable researchers interpret
associational estimates as causal. They achieve this by ensuring data,
and by extension an estimator, satisfies several key identification
properties, such as common support, no interference, and consistency
\citep{Morgan_et_al_2014, Neal_2020}. The most critical property,
however, is the elimination of confounding. \emph{Confounding} occurs
when an external variable \(X\) simultaneously influences the outcome
\(Y\) and the variable of interest \(T\), resulting in spurious
associations \citep{Everitt_et_al_2010}. Randomization addresses this
issue by decoupling the association between the intervention allocation
\(T\) from any other variable \(X\)
\citep{Morgan_et_al_2014, Neal_2020}.

Nevertheless, researchers often face constraints that limit their
ability to conduct randomized experiments. These constraints include
ethical concerns, such as the assignment of individuals to potentially
harmful interventions, and practical limitations, such as the
infeasibility of, for example, assigning individuals to genetic
modifications or physical impairments \citep{Neal_2020}. In these cases,
causal inference offers a valuable alternative for generating causal
estimates and understanding the mechanisms underlying specific data. In
addition, the framework can provide significant theoretical insights
that can enhance the design of experimental and observational studies
\citep{McElreath_2020}.

\subsection{Identification under causal inference}\label{sec-appendix-B}

Unlike classical statistical modeling, which focuses primarily on
summarizing data and inferring associations, the \emph{causal inference}
framework is designed to identify causes and estimate their effects
using data \citep{Shaughnessy_et_al_2010, Neal_2020}. The framework uses
rigorous mathematical techniques to address the \emph{fundamental
problem of causality}
\citep{Pearl_2009, Pearl_et_al_2016, Morgan_et_al_2014}. This problem
revolves around the question, ``What would have happened `in the world'
under different circumstances?'' This question introduces the concept of
counterfactuals, which are instrumental in defining and identifying
causal effects.

\emph{Counterfactuals} are hypothetical scenarios that are
\emph{contrary to fact}, where alternative outcomes resulting from a
given cause are neither observed nor observable
\citep{Neal_2020, Counterfactual_2024}. The structural approach to
causal inference \citep{Pearl_2009, Pearl_et_al_2016} provides a formal
framework for defining counterfactuals. For instance, in the scenario
described in Section~\ref{sec-appendix-A}, the approach begins by
defining the \emph{individual causal effect} (ICE) as the difference
between each student's potential outcomes, as in Equation~\ref{eq-ICE}.

\begin{equation}\phantomsection\label{eq-ICE}{
\tau_{i} = Y_{i} \:|\:do(T_{i}=1) - Y_{i} \:|\:do(T_{i}=2)
}\end{equation}

where \(do(T_{i}=t)\) represents the intervention operator,
\(Y_{i} \:|\:do(T_{i}=1)\) represents the potential outcome under
intervention \(T_{i}=1\), and \(Y_{i} \:|\:do(T_{i}=1)\) represents the
potential outcome under intervention \(T_{i}=2\). Here, an
\emph{intervention} involves assigning a constant value to the treatment
variable for each student's potential outcomes. Note that if a student
is assigned to intervention \(T_{i}=1\), the potential outcome under
\(T_{i}=2\) becomes a counterfactual, as it is no longer observed nor
observable. To address this challenge, the structural approach extends
the ICE to the \emph{average causal effect} (ACE,
Equation~\ref{eq-ACE}), representing the average difference between the
students' observed potential outcomes and their counterfactual
counterparts.

\begin{equation}\phantomsection\label{eq-ACE}{
\begin{aligned}
\tau & = E[\tau_{i}] \\
  & = E[Y_{i} \:|\:do(T_{i}=1)]- E[Y_{i} \:|\:do(T_{i}=2)]
\end{aligned}
}\end{equation}

Even though counterfactuals are unobservable, researchers can still
identify the ACE from associational estimates by leveraging the
structural approach. The approach identifies the ACE by statistically
conditioning data on a \emph{sufficient adjustment set} of variables
\(X\) \citep{Pearl_2009, Pearl_et_al_2016, Morgan_et_al_2014}. This
\emph{sufficient} set (potentially empty) must block all non-causal
paths between \(T\) to \(Y\) without opening new ones. When such a set
exists, then \(T\) and \(Y\) are \emph{d-separated} by \(X\)
(\(T \:\bot\:Y \:|\:X\)) \citep{Pearl_2009}, and \(X\) satisfies the
\emph{backdoor criterion} \citep[pp 37]{Neal_2020}. Here,
\emph{conditioning} describes the process of restricting the focus to
the subset of the population defined by the conditioning variable
\citep[pp.~32]{Neal_2020} (see Equation~\ref{eq-CACE}).

Conditioning on a sufficient adjustment set enables researchers to
estimate the ACE, even when the data comes from an observational study.
This process is feasible because such conditioning ensures that the ACE
estimator satisfies several critical properties, including confounding
elimination \citep{Morgan_et_al_2014}. Naturally, the validity of claims
about the causal effects of \(T\) on \(Y\) now hinges on the assumption
that \(X\) serves as a sufficient adjustment set. However, as
\citet[pp.~150]{Kohler_et_al_2019} noted, drawing conclusions about the
real world from observed data inevitably requires assumptions. This
requirement holds true for both observational and experimental data.

For instance, if researchers cannot conduct the randomized experiments
described in Section~\ref{sec-appendix-A} and must instead rely on
observational data, they can still identify the ACE as long as an
observed variable \(X\), such as the socio-economic status of the
school, satisfies the backdoor criterion. Under these circumstances,
researchers first identify the \emph{conditional average causal effect}
(CACE, Equation~\ref{eq-CACE})

\begin{equation}\phantomsection\label{eq-CACE}{
CACE_{t} = E[Y_{i} \:|\:T_{i}=t, X]
}\end{equation}

From the CACE, researchers can identify the ACE from associational
quantities as in Equation~\ref{eq-mACE1}. This identification process is
commonly known as the \emph{backdoor adjustment}. Here, \(E_{X}[\cdot]\)
represents the marginal expected value over \(X\)
\citep{Morgan_et_al_2014}.

\begin{equation}\phantomsection\label{eq-mACE1}{
\begin{aligned}
  \tau & = E[Y_{i} \:|\:do(T_{i}=1)]- E[Y_{i} \:|\:do(T_{i}=2)] \\
  & = E_{X}[CACE_{1} - CACE_{2}] \\
  & = E_{X}\left[ E[Y_{i} \:|\:T_{i}=1, X] - E[Y_{i} \:|\:T_{i}=2, X] \right]
\end{aligned}
}\end{equation}

Notably, the approach extends the ACE identification for a continuous
variable \(T\) as in Equation~\ref{eq-mACE_cont}, ensuring broad
applicability across different causal scenarios
\citep[pp.~45]{Neal_2020}

\begin{equation}\phantomsection\label{eq-mACE_cont}{
\begin{aligned}
  \tau &= E[Y_{i} \:|\:do(T_{i}=t)] \\
  & = d E_{X}\left[ E[Y_{i} \:|\:T_{i}=t, X]\right]/ dt
  \end{aligned}
}\end{equation}

\subsubsection{Diving into the specifics}\label{sec-appendix-B2}

The structural approach to causal inference uses SCMs and DAGs to
formally and graphically represent the presumed causal structure
underlying the ACE
\citep{Pearl_2009, Pearl_et_al_2016, Gross_et_al_2018, Neal_2020}.
Essentially, these tools serve as \emph{conceptual (theoretical) models}
on which identification analysis rests
\citep[pp.~4]{Schuessler_et_al_2023}. Thus, using these tools,
researchers can determine which statistical models can identify (ACE,
CACE, or other), assuming the depicted causal structure is correct
\citep{McElreath_2020}, thus enabling valid causal inference.
Figure~\ref{fig-IEflow} shows the role of theoretical models in the
inference process.

SCMs and DAGs support identification analysis through two key
advantages. First, regardless of complexity, they can represent various
causal structures using only five fundamental building blocks
\citep{Neal_2020, McElreath_2020}. This feature allows researchers to
decompose complex structures into manageable components, facilitating
their analysis \citep{McElreath_2020}. Second, they depict causal
relationships in a non-parametric and fully interactive way. This
flexibility enables feasible ACE identification strategies without
defining the variables' data types, the functional form between them, or
their parameters \citep[pp.~35]{Pearl_et_al_2016}.
Section~\ref{sec-appendix-B21} and Section~\ref{sec-appendix-B22}
elaborate on the first advantage, while Section~\ref{sec-appendix-B22}
and Section~\ref{sec-appendix-B23} do so for the second.

\paragraph{The five fundamental block for SCMs and
DAGs}\label{sec-appendix-B21}

Figures \ref{fig-dags_scms1}, \ref{fig-dags_scms2},
\ref{fig-dags_scms3}, \ref{fig-dags_scms4}, and \ref{fig-dags_scms5}
display the five fundamental building blocks for SCMs and DAGs. The left
panels of the figures show the formal mathematical models, represented
by the SCMs, defined in terms of a set of \emph{endogenous} variables
\(X=\{X_{1},X_{2},X_{3}\}\), a set of \emph{exogenous} variables
\(E=\{e_{X1},e_{X2},e_{X3}\}\), and a set of functions
\(F=\{f_{X1},f_{X2},f_{X3}\}\) \citep{Pearl_2009, Cinelli_et_al_2020}.
Endogenous variables are those whose causal mechanisms a researcher
chooses to model \citep{Neal_2020}. In contrast, exogenous variables
represent \emph{errors} or \emph{disturbances} arising from omitted
factors that the investigator chooses not to model explicitly
\citep[pp.~27,68]{Pearl_2009}. Lastly, the functions, referred to as
\emph{structural equations}, express the endogenous variables as
non-parametric functions of other variables. These functions use the
symbol `\(:=\)' to denote the asymmetrical causal dependence of the
variables and the symbol `\(\:\bot\:\)' to represent
\emph{d-separation}, a concept akin to (conditional) independence.

Notably, every SCM has an associated DAG
\citep{Pearl_et_al_2016, Cinelli_et_al_2020}. The right panels of the
figures display these DAGs. A DAG is a graph consisting of nodes
connected by edges, where the nodes represent random variables. The term
\emph{directed} means that the edges extend from one node to another,
with arrows indicating the direction of causal influence. The term
\emph{acyclic} implies that the causal influences do not form loops,
ensuring the influences do not cycle back on themselves
\citep{McElreath_2020}. DAGs represent observed variables as solid black
circles, while they use open circles for unobserved (latent) variables
\citep{Morgan_et_al_2014}. Although the \emph{standard representation}
of DAGs typically omits exogenous variables for simplicity, the
\emph{magnified representation} depicted in the figures offers one key
advantage: including exogenous variables can help researchers highlight
potential issues related to conditioning and confounding
\citep{Cinelli_et_al_2020}.

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{3} & := f_{X3}(e_{X3}) \\
  e_{X1} & \:\bot\:e_{X3}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_bb1}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.54\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_bb1.png}

}

\subcaption{\label{fig-mdag_bb1}DAG}

\end{minipage}%

\caption{\label{fig-dags_scms1}Two unconnected nodes}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{3} & := f_{X3}(X_{1},e_{X3}) \\
  e_{X1} & \:\bot\:e_{X3}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_bb2}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.54\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_bb2.png}

}

\subcaption{\label{fig-mdag_bb2}DAG}

\end{minipage}%

\caption{\label{fig-dags_scms2}Two connected nodes or descendant}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{2} & := f_{X2}(X_{1},e_{X2}) \\
  X_{3} & := f_{X3}(X_{2},e_{X3}) \\
  e_{X1} & \:\bot\:e_{X2} \\
  e_{X1} & \:\bot\:e_{X3} \\
  e_{X2} & \:\bot\:e_{X3}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_bb3}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.65\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_bb3.png}

}

\subcaption{\label{fig-mdag_bb3}DAG}

\end{minipage}%

\caption{\label{fig-dags_scms3}Chain or mediator}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X_{1} & := f_{X1}(X_{2},e_{X1}) \\
  X_{2} & := f_{X2}(e_{X2}) \\
  X_{3} & := f_{X3}(X_{2},e_{X3}) \\
  e_{X1} & \:\bot\:e_{X2} \\
  e_{X1} & \:\bot\:e_{X3} \\
  e_{X2} & \:\bot\:e_{X3}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_bb4}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.65\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_bb4.png}

}

\subcaption{\label{fig-mdag_bb4}DAG}

\end{minipage}%

\caption{\label{fig-dags_scms4}Fork or confounder}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{2} & := f_{X2}(X_{1},X_{3},e_{X2}) \\
  X_{3} & := f_{X3}(e_{X3}) \\
  e_{X1} & \:\bot\:e_{X2} \\
  e_{X1} & \:\bot\:e_{X3} \\
  e_{X2} & \:\bot\:e_{X3}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_bb5}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.65\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_bb5.png}

}

\subcaption{\label{fig-mdag_bb5}DAG}

\end{minipage}%

\caption{\label{fig-dags_scms5}Collider or inmorality}

\end{figure}%

A careful examination of these building blocks highlights the
theoretical assumptions underlying their observed variables. SCM
\ref{fig-scm_bb1} and DAG \ref{fig-mdag_bb1} depict two unconnected
nodes, representing a scenario where variables \(X_{1}\) and \(X_{3}\)
are independent or not causally related. SCM \ref{fig-scm_bb2} and DAG
\ref{fig-mdag_bb2} illustrate two connected nodes, representing a
scenario where a \emph{parent} node \(X_{1}\) exerts a causal influence
on a \emph{child} node \(X_{3}\). In this setup, \(X_{3}\) is considered
a \emph{descendant} of \(X_{1}\). Additionally, \(X_{1}\) and \(X_{3}\)
are described as \emph{adjacent} because there is a \emph{direct path}
connecting them. SCM \ref{fig-scm_bb3} and DAG \ref{fig-mdag_bb3} depict
a \emph{chain}, where \(X_{1}\) influences \(X_{2}\), and \(X_{2}\)
influences \(X_{3}\). In this configuration, \(X_{1}\) is a parent node
of \(X_{2}\), which is a parent node of \(X_{3}\). This structure
creates a \emph{directed path} between \(X_{1}\) and \(X_{3}\).
Consequently, \(X_{1}\) is an \emph{ancestor} of \(X_{3}\), and
\(X_{2}\) fully \emph{mediates} the relationship between the two. SCM
\ref{fig-scm_bb4} and DAG \ref{fig-mdag_bb4} illustrate a \emph{fork},
where variables \(X_{1}\) and \(X_{3}\) are both influenced by
\(X_{2}\). Here, \(X_{2}\) is a parent node that \emph{confounds} the
relationship between \(X_{1}\) and \(X_{3}\). Finally, SCM
\ref{fig-scm_bb5} and DAG \ref{fig-mdag_bb5} show a \emph{collider},
where variables \(X_{1}\) and \(X_{3}\) are concurrent causes of
\(X_{2}\). In this configuration, \(X_{1}\) and \(X_{3}\) are not
causally related to each other but both influence \(X_{2}\) (an
\emph{inmorality}). Notably, all building blocks assume the errors are
independent of each other and from all other variables in the graph, as
evidenced by the pairwise relations \(e_{X1} \:\bot\:e_{X2}\),
\(e_{X1} \:\bot\:e_{X3}\), and \(e_{X2} \:\bot\:e_{X3}\).

Researchers can then use these building blocks to represent the scenario
outlined in Section~\ref{sec-appendix-B}. SCM \ref{fig-scm_example1} and
DAG \ref{fig-mdag_example1} depict the plausible causal structure for
this example. In this context, the variable \(X\) (socio-economic status
of the school) is thought to be a confounder in the relationship between
the teaching method \(T\) and the outcome \(Y\). In this scenario, the
figures display multiple descendant relationships such as
\(X \rightarrow T\), \(X \rightarrow Y\), and \(T \rightarrow Y\). They
also highlight unconnected node pairs, evident from the relationships
\(e_{T} \:\bot\:e_{X}\), \(e_{T} \:\bot\:e_{Y}\), and
\(e_{X} \:\bot\:e_{Y}\). Additional, the figures show one fork,
\(X \rightarrow \{T, Y\}\), and two colliders:
\(\{X, e_{T}\} \rightarrow T\) and \(\{X, T, e_{Y}\} \rightarrow Y\).

\begin{figure}

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  T & := f_{T}(X,e_{T}) \\
  Y & := f_{Y}(T,X,e_{Y}) \\
  e_{T} & \:\bot\:e_{X} \\
  e_{T} & \:\bot\:e_{Y} \\
  e_{X} & \:\bot\:e_{Y}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_example1}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.65\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_example1.png}

}

\subcaption{\label{fig-mdag_example1}DAG}

\end{minipage}%

\caption{\label{fig-example1}Plausible causal structure the scenario
outlined in Section~\ref{sec-appendix-B}.}

\end{figure}%

\paragraph{The probabilistic implications of these
blocks}\label{sec-appendix-B22}

Beyond their graphical capabilities, SCMs and DAGs can encode the
probabilistic information embedded within a causal structure. They
achieve this encoding by relying on three fundamental assumptions: the
local Markov, the minimality, the causal edges assumption. The
\emph{local Markov assumption} encodes probabilistic independencies
between variables by declaring that nodes in a graph are independent of
all its non-descendants, given its parents \citep[pp.~20]{Neal_2020}.
Meanwhile, the \emph{minimality assumption} encodes probabilistic
dependencies among variables by stating that every pair of adjacent
nodes exhibits a dependency \citep[pp.~21]{Neal_2020}. Finally, the
\emph{causal edges assumption} encodes causal relationships between
variables by declaring that each parent node acts as a direct cause of
its children \citep[pp.~22]{Neal_2020}. Figure~\ref{fig-ACflow}
illustrates how these assumptions influence the statistical and causal
interpretations of graphs.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{images/png/ACflow.png}

}

\caption{\label{fig-ACflow}The flow of association and causation in
graphs. Extracted and slightly modified from \citet[pp.~31]{Neal_2020}}

\end{figure}%

A notable implication of the assumptions underlying the probabilistic
encoding is that any conceptual model described by an SCM and DAG can
represent the joint distribution of variables more efficiently
\citep[pp.~29]{Pearl_et_al_2016}. This expression takes the form of a
product of conditional probability distributions (CPDs) of the type
\(P(child \:|\:parents)\). This property is formally known as the
\emph{Bayesian Network factorization} (BNF,
Equation~\ref{eq-net_factor})
\citetext{\citealp[pp.~29]{Pearl_et_al_2016}; \citealp[pp.~21]{Neal_2020}}.
In this expression, \(pa(X_{i})\) denotes the set of variables that are
the parents of \(X_{i}\).

\begin{equation}\phantomsection\label{eq-net_factor}{
\begin{aligned}
P(X_{1}, X_{2}, \dots, X_{P}) & = X_{1} \cdot \prod^{P}_{p=2} P(X_{i} \:|\:X_{i-1}, \dots, X_{1}) & (\small{\text{by chain rule})}\\
& = X_{1} \cdot \prod^{P}_{p=2} P(X_{i} \:|\:pa(X_{i}) ) & (\small{\text{by BNF}})
\end{aligned}
}\end{equation}

This encoding enables researchers with conceptual (theoretical)
knowledge in the form of an SCM and DAG to predict patterns of
(in)dependencies in the data. As highlighted by
\citet[pp.~35]{Pearl_et_al_2016}, these predictions depend solely on the
structure of these conceptual models without requiring the quantitative
details of the equations or the distributions of the errors. Moreover,
once researchers observe empirical data, the patterns of
(in)dependencies in the data can provide significant insights into the
validity of the proposed conceptual model.

The five fundamental building blocks described in
Section~\ref{sec-appendix-B21} clearly illustrate which (in)dependencies
can SMCs and DAGs predict. For instance, applying the BNF to the causal
structure shown in the SCM \ref{fig-scm_bb1} and DAG \ref{fig-mdag_bb1}
enables researchers to express the joint probability distribution of the
observed variables as \(P(X_{1}, X_{3}) = P(X_{1}) P(X_{3})\),
supporting the theoretical assumption that the observed variables
\(X_{1}\) and \(X_{3}\) are unconditionally independent
(\(X_{1} \:\bot\:X_{3}\)) \citep[pp.~24]{Neal_2020}. Conversely, when
\(X_{3}\) is unconditionally dependent on \(X_{1}\)
(\(X_{1} \:\not\bot\:X_{3}\)), as depicted in the SCM \ref{fig-scm_bb2}
and DAG \ref{fig-mdag_bb2}, the BNF express their joint probability
distribution as \(P(X_{1}, X_{3}) = P(X_{3} \:|\:X_{1}) P(X_{1})\).
Notably, these descriptions demonstrate the clear correspondence between
the structural equations illustrated in Section~\ref{sec-appendix-B21}
and the CPDs.

Beyond the insights gained from two-node structures, researchers can
uncover more nuanced patterns of(in)dependencies from chains, forks, and
colliders. These (in)dependencies apply to any data set generated by a
causal model with those structures, regardless of the specific functions
attached to the SCM \citep[pp.~36]{Pearl_et_al_2016}. For instance,
applying the BNF to the chain structure depicted in the SCM
\ref{fig-scm_bb3} and DAG \ref{fig-mdag_bb3} allow researchers to
represent the joint distribution for the observed variables as
\(P(X_{1},X_{2},X_{3}) =\)
\(P(X_{1}) P(X_{2} \:|\:X_{1}) P(X_{3} \:|\:X_{2})\). This expression
implies that \(X_{1}\) and \(X_{3}\) are unconditionally dependent
\((X_{1} \:\not\bot\:X_{3})\), but conditionally independent when
controlling for \(X_{2}\) \((X_{1} \:\bot\:X_{3} \:|\:X_{2})\).
Moreover, in the fork structure shown in the SCM \ref{fig-scm_bb4} and
DAG \ref{fig-mdag_bb4}, researchers can express the joint distribution
of the observed variables as \(P(X_{1},X_{2},X_{3}) =\)
\(P(X_{1} \:|\:X_{2}) P(X_{2}) P(X_{3} \:|\:X_{2})\). Similar to the
chain structure, this expression allows researchers to further infer
that \(X_{1}\) and \(X_{3}\) are unconditionally dependent
\((X_{1} \:\not\bot\:X_{3})\), but conditionally independent when
controlling for \(X_{2}\) \((X_{1} \:\bot\:X_{3} \:|\:X_{2})\). Finally,
researchers analyzing the collider structure illustrated in the SCM
\ref{fig-scm_bb5} and DAG \ref{fig-mdag_bb5} can express the joint
distribution of the observed variables as \(P(X_{1},X_{2},X_{3}) =\)
\(P(X_{1}) P(X_{2} \:|\:X_{1}, X_{3}) P(X_{3})\). This representation
allows researchers to infer that \(X_{1}\) and \(X_{3}\) are
unconditionally independent \((X_{1} \:\bot\:X_{3})\), but conditionally
dependent when controlling for \(X_{2}\)
\((X_{1} \:\not\bot\:X_{3} \:|\:X_{2})\). The authors \citet[pp.~37, 40,
41]{Pearl_et_al_2016} and \citet[pp.~25--26]{Neal_2020} provide the
mathematical proofs for these conclusions.

Using these additional probabilistic insights, researchers can revisit
the scenario in Section~\ref{sec-appendix-B}. In this context, applying
the BNF to the SCM \ref{fig-scm_example2} structure, enables the
representation of the joint probability distribution of the observed
variables as \(P(Y, T, X) =\) \(P(Y \:|\:T, X) P(T \:|\:X) P(X)\). From
this expression, researchers can infer that the outcome \(Y\) is
unconditionally dependent on the teaching method \(T\)
\((Y \:\not\bot\:T)\). This dependency arises from two key structures: a
direct causal path from the teaching method \(T\) to the outcome \(Y\),
represented by the two-connected-nodes structure \(T \rightarrow Y\)
(black path in DAG \ref{fig-mdag_example2}), and a confounding
non-causal path from the teaching method \(T\) to the outcome \(Y\)
through the socio-economic status of the school \(X\), represented by
the fork structure \(T \leftarrow X \rightarrow Y\) (gray path in DAG
\ref{fig-mdag_example2}).

\begin{figure}

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X & := x \\
  T & := f_{T}(x,e_{T}) \\
  Y & := f_{Y}(T,x,e_{Y}) \\
  e_{T} & \:\bot\:e_{X} \\
  e_{T} & \:\bot\:e_{Y} \\
  e_{X} & \:\bot\:e_{Y}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_example2}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.65\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_example1a.png}

}

\subcaption{\label{fig-mdag_example2}Conditioned DAG}

\end{minipage}%

\caption{\label{fig-example2}Plausible causal structure the scenario
outlined in Section~\ref{sec-appendix-B}.}

\end{figure}%

\paragraph{From probability to causality}\label{sec-appendix-B23}

The structural approach to causal inference translates probabilistic
insights into actionable strategies seeking to identify the ACE from
associational quantities. The approach achieves this by relying on the
\emph{modularity assumption}, which posits that intervening on a node
alters only the causal mechanism of that node, leaving others unchanged
\citep[pp.~34]{Neal_2020}.

The modularity assumption underpins the concepts of manipulated graphs
and Truncated Factorization, which are essential for representing
interventions \(P(Y_{i} \:|\:do(T_{i}=t))\) within SCMs and DAGs.
\emph{Manipulated graphs} simulate physical interventions by removing
specific edges from a DAG, while preserving the remaining structure
unchanged \citep[pp.~34]{Neal_2020}. In parallel, \emph{Truncated
Factorization} (TF) achieves a similar simulation by removing specific
functions from the conceptual model and replacing them with constants,
while keeping the rest of the structure unchanged \citep{Pearl_2010}.
The probabilistic implications of this factorization are formalized in
Equation~\ref{eq-trunc_factor}, where \(S\) represents the subset of
variables \(X_{p}\) directly influenced by the intervention, while an
example illustrating these concepts follows below.

\begin{equation}\phantomsection\label{eq-trunc_factor}{
P(X_{1}, X_{2}, \dots, X_{P} \:|\:do(S)) =
\begin{cases}
  \prod P(X_{p} \:|\:pa(X_{p}) ) & \text{if} \: p \not\in S \\
  1 \quad & \text{otherwise}
\end{cases}
}\end{equation}

Using the TF, researchers can define the \emph{backdoor adjustment} to
identify the ACE. This adjustment states that if a variable
\(X_{p} \in S\) serves as a \emph{sufficient adjustment set} for the
effect of \(X_{a}\) on \(X_{b}\), then the ACE can be identified using
Equation~\ref{eq-backdoor}. The sufficient adjustment set (potentially
empty) must block all non-causal paths between \(X_{a}\) and \(X_{b}\)
without introducing new paths. If such a set exists, then \(X_{a}\) and
\(X_{b}\) are \emph{d-separated} by \(X_{p}\)
(\(X_{a} \:\bot\:X_{b} \:|\:X_{p}\)) \citep{Pearl_2009}, and \(X_{p}\)
satisfies the \emph{backdoor criterion} \citep[pp.~37]{Neal_2020}.

\begin{equation}\phantomsection\label{eq-backdoor}{
P(X_{a} \:|\:do(X_{b}=x)) = \sum_{Xp} P(X_{a} \:|\:X_{b}=x, X_{p}) P(X_{p})
}\end{equation}

Ultimately, the backdoor adjustment enables researchers to express the
ACE as:

\begin{equation}\phantomsection\label{eq-backdoor_adjustment}{
\begin{aligned}
\tau & = E[X_{a} \:|\:do(X_{b}=1)]- E[X_{a} \:|\:do(X_{b}=2)] \\
  & = E_{Xp}\left[ E[X_{a} \:|\:do(X_{b}=1), X_{p}]- E[X_{a} \:|\:do(X_{b}=2), X_{p}] \right] \\
  & = \sum_{Xp} X_{a} \cdot P(X_{a} \:|\:X_{b}=1, X_{p}) \cdot P(X_{p}) - \sum_{Xp} X_{a} \cdot P(X_{a} \:|\:X_{b}=2, X_{p}) \cdot P(X_{p})
\end{aligned}
}\end{equation}

With these new insights, researchers revisiting the scenario in
Section~\ref{sec-appendix-B22} can infer that the socio-economic status
of the school, \(X\), satisfies the backdoor criterion, assuming the
causal structure depicted by the SCM \ref{fig-scm_example2} and DAG
\ref{fig-mdag_example2} is correct. This means that \(X\) serves as a
sufficient adjustment set, as it effectively blocks all confounding
non-causal paths introduced by the fork structure. Nevertheless, since
\(Y\) remains dependent on \(T\) even after conditioning
\((Y \:\not\bot\:T \:|\:X)\), this dependency can only be attributed to
the direct causal effect \(T \rightarrow Y\). Notably, for the purpose
of identification, the conditioned DAG \ref{fig-mdag_example2} is
equivalent to the manipulated DAG \ref{fig-mdag_example3}, because \(X\)
satisfies the backdoor criterion.

\begin{figure}

\begin{minipage}{0.50\linewidth}

\centering{

\[
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  T & := t \\
  Y & := f_{Y}(t,X,e_{Y}) \\
  e_{T} & \:\bot\:e_{X} \\
  e_{T} & \:\bot\:e_{Y} \\
  e_{X} & \:\bot\:e_{Y}
\end{aligned}
\]

}

\subcaption{\label{fig-scm_example3}SCM}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\centering{

\includegraphics[width=0.65\linewidth,height=\textheight,keepaspectratio]{images/png/mdag_example1b.png}

}

\subcaption{\label{fig-mdag_example3}Manipulated DAG}

\end{minipage}%

\caption{\label{fig-example3}Plausible causal structure the scenario
outlined in Section~\ref{sec-appendix-B22}.}

\end{figure}%

Researchers can then apply the \emph{backdoor adjustment} to identify
the ACE of \(T\) on \(Y\). They achieve this by first identifying the
CACE of \(T\) on \(Y\) by conditioning on \(X\), and then marginalizing
this effect over \(X\) to obtain the ACE. This process is expressed in
Equation~\ref{eq-mACE2} (see Section~\ref{sec-appendix-B}).

\begin{equation}\phantomsection\label{eq-mACE2}{
\begin{aligned}
  \tau & = E[Y_{i} \:|\:do(T_{i}=1)]- E[Y_{i} \:|\:do(T_{i}=2)] \\
  & = E_{X}\left[ E[Y_{i} \:|\:T_{i}=1, X] - E[Y_{i} \:|\:T_{i}=2, X] \right] \\
  & = \sum_{X} Y_{i} \cdot P( Y_{i} \:|\:T_{i}=1, X) \cdot P(X) - \sum_{X} Y_{i} \cdot P( Y_{i} \:|\:T_{i}=2, X) \cdot P(X)
\end{aligned}
}\end{equation}

\paragraph{The estimation process}\label{sec-appendix-C}

Ultimately, researchers can use Bayesian inference methods to estimate
the ACE. The approach begins by defining two probability distributions:
the likelihood of the data,
\(P(X_{1}, X_{2}, \dots, X_{P} \:|\:\theta)\), and the prior
distribution, \(P(\theta)\) \citep{Everitt_et_al_2010}, where \(X_{P}\)
represents a random variable, and \(\theta\) represents a
one-dimensional parameter space for simplicity. After observing
empirical data, researchers can update the priors to posterior
distributions using Bayes' rule in Equation~\ref{eq-bayes_rule}:

\begin{equation}\phantomsection\label{eq-bayes_rule}{
P(\theta \:|\:X_{1}, X_{2}, \dots, X_{P}) = \frac{P(X_{1}, X_{2}, \dots, X_{P} \:|\:\theta) \cdot P(\theta)}{P(X_{1}, X_{2}, \dots, X_{P})}
}\end{equation}

Given that the denominator on the right-hand side of
Equation~\ref{eq-bayes_rule} serves as a normalizing constant
independent of the parameter \(\theta\), researchers can simplify the
posterior updating process into three steps. First, they integrate new
empirical data through the likelihood. Second, they update the
parameters' priors to a posterior distribution according to
Equation~\ref{eq-prop_rule}. Ultimately, they normalize these results to
obtain a valid probability distribution.

\begin{equation}\phantomsection\label{eq-prop_rule}{
P(\theta \:|\:X_{1}, X_{2}, \dots, X_{P}) \propto P(X_{1}, X_{2}, \dots, X_{P}\:|\:\theta) \cdot P(\theta)
}\end{equation}

Temporarily setting aside the definition of prior distributions
\(P(\theta)\), note that the posterior updating process depends heavily
on the assumptions underlying the likelihood of the data. However, as
the number of random variables, \(P\), increases, this joint
distribution quickly becomes intractable \citep{Neal_2020}. This
intractability is evident from Equation~\ref{eq-like_chain}, where the
likelihood distribution is expressed by multiple chained CPDs.

\begin{equation}\phantomsection\label{eq-like_chain}{
P(X_{1}, X_{2}, \dots, X_{P} \:|\:\theta) = P(X_{1} \:|\:\theta) \prod^{P}_{p=2} P(X_{i} \:|\:X_{i-1}, \dots, X_{1}, \theta )
}\end{equation}

Nevertheless, researchers can manage the complexity of the likelihood by
assuming specific local (in)dependencies among variables. SCMs and DAGs
provide a formal framework to represent these assumptions, as detailed
in Section~\ref{sec-appendix-B22}. These assumptions improve model
tractability and simplify the estimation process by enabling the
derivation of the BNF of the likelihood (Equation~\ref{eq-like_BNF}).
With this simplified structure, any probabilistic programming language
can model the system and compute the parameter's posterior distribution
using Equation~\ref{eq-bayes_rule}.

\begin{equation}\phantomsection\label{eq-like_BNF}{
P(X_{1}, X_{2}, \dots, X_{P} \:|\:\theta) = P(X_{1} \:|\:\theta) \prod^{P}_{p=2} P(X_{i} \:|\:pa(X_{i}), \theta )
}\end{equation}

\newpage{}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\renewcommand{\bibsection}{}
\bibliography{references.bib}





\end{document}
