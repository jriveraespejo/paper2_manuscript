---
title: "Let's talk about Thurstone & Co.: An information-theoretical model for comparative judgments, and its statistical translation"
author:
  - name: 
      given: Jose Manuel
      family: Rivera Espejo
    orcid: 0000-0002-3088-2783
    url: https://www.uantwerpen.be/en/staff/jose-manuel-rivera-espejo_23166/
    email: JoseManuel.RiveraEspejo@uantwerpen.be
    corresponding: true
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Tine
      family: van Daal
      non-dropping-particle: van
    orcid: 0000-0001-9398-9775
    url: https://www.uantwerpen.be/en/staff/tine-vandaal/
    email: tine.vandaal@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Sven
      family: De Maeyer
      non-dropping-particle: De
    orcid: 0000-0003-2888-1631
    url: https://www.uantwerpen.be/en/staff/sven-demaeyer/
    email: sven.demaeyer@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Training and education sciences
        group: Edubron
  - name: 
      given: Steven
      family: Gillis
    orcid: 
    url: https://www.uantwerpen.be/nl/personeel/steven-gillis/
    email: steven.gillis@uantwerpen.be
    corresponding: false
    affiliation:
      - name: University of Antwerp
        department: Linguistics
        group: Centre for computational linguistics, psycholinguistics, and sociolinguistics (CLiPS)
funding: 
  statement: "The project was founded through the Research Fund of the University of Antwerp (BOF)."
keywords:
  - causal inference
  - directed acyclic graphs
  - structural causal models
  - bayesian statistical methods
  - thurstonian model
  - comparative judgement
  - probability
  - statistical modeling
abstract: |
  This study revisits Thurstone's law of comparative judgment (CJ), focusing on two prominent issues of traditional approaches. First, it critiques the heavy reliance on Thurstone's Case V assumptions and, by extension, the Bradley-Terry-Luce (BTL) model when analyzing CJ data. Specifically, the study raises concerns about the assumptions of equal discriminal dispersions and zero correlation between the stimuli. While these assumptions simplify the trait measurement model, they may fail to capture the complexity of CJ data, potentially leading to unreliable and inaccurate trait estimates. Second, the study highlights the apparent disconnect between CJ's trait measurement and hypothesis testing processes. Although separating these processes simplifies the analysis of CJ data, it may also undermine the reliability of various statistical results derived from these processes.
  
  To address these issues, the study extends Thurstone's general form using a systematic and integrated approach based on Causal and Bayesian inference methods. This extension integrates core theoretical principles alongside key assessment design features relevant to CJ experiments, such as the selection of judges, stimuli, and comparisons. It then translates these elements into a probabilistic statistical model for analyzing dichotomous CJ data, overcoming the rigid assumptions of Case V and the BTL model.
  
  Finally, the study emphasizes the relevance of this extension for contemporary empirical CJ research, particularly stressing the need for bespoke CJ models tailored to the experiments and data assumptions. It also lays the foundation for broader applications, encouraging researchers across the social sciences to adopt more robust and interpretable methodologies.
key-points:
  - (to do)
date: last-modified
bibliography: references.bib
---

<!-- commands for d-separation -->
\newcommand{\dsep}{\:\bot\:}
\newcommand{\ndsep}{\:\not\bot\:}
\newcommand{\cond}{\:|\:}


<!-- abstract -->
<!-- recording: Sven and Tine 24.11.25; time: 00:58:20 - 00:59:20 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:11:50 - 00:26:10, (Here we did it!) -->


# Introduction {#sec-introduction}

<!-- recording: Sven 24.10.04; time: 00:00:00 - 00:09:10 -->
<!-- recording: Sven 24.10.04; time: 00:14:30 - 00:21:00 -->
<!-- recording: Sven and Tine 24.10.18; time: 00:04:05 - 00:08:30 -->
<!-- recording: Sven and Tine 24.10.25; time: 00:00:00 - 00:17:00 -->
<!-- recording: Sven and Tine 24.10.25; time: 00:00:00 - 00:17:00 -->
<!-- recording: Sven and Tine 25.01.22; time: 00:06:30 - 00:08:25 -->

<!-- 1. Overview of CJ method in assessing traits -->
In *comparative judgment* (CJ) studies, judges assess a specific trait or attribute across different stimuli by performing pairwise comparisons [@Thurstone_1927a; @Thurstone_1927b]. Each comparison produces a dichotomous outcome, indicating which stimulus is perceived to have a higher trait level. For example, when assessing writing quality, judges compare pairs of written texts (the stimuli) to determine the relative writing quality each text exhibit (the trait) [@Laming_2004; @Pollitt_2012b; @Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018_thesis; @Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023].

<!-- and spoken language [@Boonen_et_al_2020]. Additionally, it has been applied to evaluate various competencies, including mathematical problem-solving skills [@Jones_et_al_2015], engineering design skills [@Bartholomew_et_al_2018], build real-time web-based portfolios of performance [@@Kimbell_2012], conceptual understanding in algebra [@Jones_et_al_2019], statistical and English knowledge [@Marshall_et_al_2020], and STEM knowledge and skills [@Bartholomew_et_al_2020]. -->

<!-- 2. What is the effectiveness of CJ -->
Numerous studies have documented the effectiveness of CJ in assessing traits and competencies over the past decade. These studies have highlighted three aspects of the method's effectiveness: its reliability, validity, and practical applicability. Research on reliability suggests that CJ requires a relatively modest number of pairwise comparisons [@Verhavert_et_al_2019; @Crompvoets_et_al_2022] to generate trait scores that are as precise and consistent as those generated by other assessment methods [@Coertjens_et_al_2017; @Goossens_et_al_2018; @Bouwer_et_al_2023]. In addition, the evidence suggests that the reliability and time efficiency of CJ are comparable, if not superior, to those of other assessment methods when employing adaptive comparison algorithms [@Pollitt_2012b; @Verhavert_et_al_2022; @Mikhailiuk_et_al_2021]. Meanwhile, research on validity indicates the capacity of CJ scores to represent accurately the traits under measurement [@Whitehouse_2012; @vanDaal_et_al_2016; @Lesterhuis_2018_thesis; @Bartholomew_et_al_2018; @Bouwer_et_al_2023]. Lastly, research on its practical applicability highlights CJ's versatility across both educational and non-educational contexts [@Kimbell_2012; @Jones_et_al_2015; @Bartholomew_et_al_2018; @Jones_et_al_2019; @Marshall_et_al_2020; @Bartholomew_et_al_2020; @Boonen_et_al_2020].

<!-- rubrics [@Coertjens_et_al_2017; @Goossens_et_al_2018]  -->
<!-- holistic benchmark ratings [@Bouwer_et_al_2023] -->

<!-- Adaptive comparison algorithms dynamically present stimuli to judges, based on the results of previous comparisons. They aim to enhance the informativeness of comparisons while optimizing judges' time [@Bramley_2015].  -->

<!-- 3. But what critical issues remain in CJ Research? -->
Nevertheless, despite the increasing number of CJ studies, research in this domain remains unsystematic and fragmented, leaving several critical issues unresolved. This study identifies and discusses two prominent issues of traditional approaches that can undermine the reliability and validity of CJ's trait estimates  [@Perron_et_al_2015, pp. 2]. First, it critiques the heavy reliance on Thurstone's Case V assumptions [@Thurstone_1927b] and, by extension, the Bradley-Terry-Luce (BTL) model [@Bradley_et_al_1952; @Luce_1959] when analyzing CJ data. Specifically, the study raises concerns about the assumptions of equal discriminal dispersions and zero correlation between the stimuli. While these assumptions simplify the trait measurement model, they may fail to capture the complexity of CJ data, potentially leading to unreliable and inaccurate trait estimates. Second, the study highlights the disconnect between CJ's trait measurement and hypothesis testing processes. Although separating these processes simplifies the analysis of CJ data, it may also undermine the reliability of various statistical results derived from these processes.

<!-- 5. So, what are we doing? -->
To address these issues, this study extends Thurstone's general form using a systematic and integrated approach based on Causal and Bayesian inference methods. In addition to improving statistical accuracy and strengthening measurement reliability and validity, the approach offers two key advantages. First, it clarifies the interactions among all actors and processes involved in CJ experiments. Second, it shifts the current comparative data analysis paradigm from passively accepting the BTL model assumptions to actively testing whether those assumptions fit the data under analysis.

<!-- Many cross-cultural scientists already pay close attention to concerns of causal inference and comparison without use of a formal framework (e.g., Norenzayan & Heine, 2005; Pollet et al., 2014). For these researchers, a formalized framework can provide a vocabulary to articulate their concerns and work toward solutions in a more systematic manner. [@Deffner_et_al_2022, pp. 2] -->

<!-- Specifically, a framework is needed which lets us reason about the causes of non-invariance. [@Sterner_et_al_2024, pp. 751] -->

<!-- 4. what is the organization of the study? -->
As a result, the study divides its content into six main sections. @sec-thurstone_theory provides an overview of Thurstone's theory. @sec-theory-issues discusses the identified issues in detail. @sec-theoretical extends Thurstone's general form to address these challenges. The extension integrates core theoretical principles alongside key assessment design features relevant to CJ experiments, such as the selection of judges, stimuli, and comparisons. @sec-statistical translates these theoretical and practical elements into a probabilistic statistical model to analyze dichotomous pairwise comparison data. @sec-discussion discusses the findings, limitations, and challenges and explores avenues for future research. Finally, @sec-conclusion summarizes the study's conclusions.


# Thurstone's theory {#sec-thurstone_theory}
<!-- recording: Sven and Tine 24.11.18; time: 00:04:30 - 00:14:50 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:19:04 - 00:21:37 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:00:35 - 00:06:55 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:30:35 - 00:35:10 -->
<!-- recording: Sven and Tine 24.12.09; time: 00:00:00 - 00:03:20 -->

<!-- 1. Thurstone's Theory of CJ: discriminal process -->
In its most general form, Thurstone’s theory addresses pairwise comparisons wherein a single judge evaluates multiple stimuli [@Thurstone_1927b, pp. 267]. The theory posits that two key factors determine the dichotomous outcome of these comparisons: the discriminal process of each stimulus and their discriminal difference. The *discriminal process* captures the psychological impact each stimulus exerts on the judge or, more simply, his perception of the stimulus trait. The theory assumes that the discriminal process for any given stimulus forms a Normal distribution along the trait continuum [@Thurstone_1927b, pp. 266]. The mode (mean) of this distribution, known as the *modal discriminal process*, indicates the stimulus position on this continuum, while its dispersion, referred to as the *discriminal dispersion*, reflects variability in the perceived trait of the stimulus.

<!-- The psychological continuum or scale is so constructed or defined that the frequencies of the respective discriminal processes for any given stimulus form a normal distribution on the psychological scale. This involves no assumption of a normal distribution or of anything else. The psychological scale is at best an artificial construct. If it has any physical reality, we certainly have not the remotest idea of what it may be like. ... We define the scale in terms of the frequencies of the discriminal processes for any stimulus. This artificial construct, the psychological scale, is so spaced off that the frequencies of the discriminal processes for any given stimulus form a normal distribution on the scale.[@Thurstone_1927b, pp. 266] -->

<!-- 2. Example of discriminal processes -->
@fig-discriminal_process illustrates the hypothetical discriminal processes along a quality trait continuum for two written texts. The figure indicates that the modal discriminal process for Text B is positioned further along the continuum than that of Text A $(T_{B} > T_{A})$, suggesting that Text B exhibits higher quality. Additionally, the figure highlights that Text B has a broader distribution compared to Text A, which arises from its larger discriminal dispersion $(\sigma_{B} > \sigma_{A})$.

::: {#fig-thurstone_theory layout-ncol=2}

![Discriminal processes](/images/png/discriminal_process.png){#fig-discriminal_process width=100%}

![Discriminal difference](/images/png/discriminal_difference.png){#fig-discriminal_difference width=100%}

Hypothetical discriminal processes and discriminant difference along a quality trait continuum for two written texts.
:::

<!-- 3. Thurstone's Theory of CJ: discriminal difference -->
However, since the individual discriminal processes of the stimuli are not directly observable, the theory introduces the *law of comparative judgment*. This law posits that in pairwise comparisons, a judge perceives the stimulus with a discriminal process positioned further along the trait continuum as possessing more of the trait [@Bramley_2008, pp. 251]. This suggests that pairwise comparison outcomes depend on the relative distance between stimuli, not their absolute positions on the continuum. Indeed, the theory assumes that the difference between the underlying discriminal processes of the stimuli, referred to as the *discriminal difference*, determines the observed dichotomous outcome. Furthermore, the theory assumes that because the individual discriminal processes form a Normal distribution on the continuum, the discriminal difference will also conform to a Normal distribution [@Andrich_1978, pp. 452]. In this distribution, the mode (mean) represents the relative separation between the stimuli, and its dispersion indicates the variability of that separation.

<!-- The mode (mean) of this distribution, representing the (average) relative separation, is given by the difference between the modal discriminal processes of the stimuli $S_{BA}=S_{B}-S_{A}$. Meanwhile, the dispersion of the distribution, reflecting the variability in the relative separation, is calculated as $\sigma_{BA} = \sqrt{\sigma_{B}^{2} + \sigma_{A}^{2} - \rho\sigma_{B}\sigma_{A}}$. Here, $\sigma_{B}$ and $\sigma_{A}$ denote the discriminal dispersions of the stimuli, while $\rho$ represents the correlation between their discriminal processes. This correlation quantifies the dependence of the judge's perception of the trait in one stimulus on his perception of the same trait in another. -->

<!-- 4. Example of discriminal difference -->
@fig-discriminal_difference illustrates the distribution of the discriminal difference for the hypothetical texts depicted in @fig-discriminal_process. The figure indicates that the judge perceives Text B as having significantly higher quality than Text A. Two key observations support this conclusion: the positive difference between their modal discriminal processes $(T_{B} - T_{A} > 0)$ and the probability area where the discriminal difference distinctly favors Text B over Text A, represented by the shaded gray area denoted as $P(B > A)$. As a result, the dichotomous outcome of this comparison is more likely to favor Text B over Text A.


# Two Prominent Issues in Traditional CJ Practice {#sec-theory-issues}

<!-- 1. What is the problem with the general form -->
Thurstone noted from the outset that his general form, described in @sec-thurstone_theory, led to a *trait scaling problem*. Specifically, the model required estimating more "unknown" parameters than the number of available pairwise comparisons [@Thurstone_1927b, pp. 267]. For instance, in a CJ experiment with five texts, the general form would require estimating $20$ parameters: five modal discriminal processes, five discriminal dispersions, and $10$ correlations --one per comparison (see @tbl-thurstone_cases). However, a single judge could only provide ${5 \choose 2} = 10$ unique comparisons, an insufficient data set to estimate the required parameters.

<!-- 2. Thurstone's Cases and their simplifying assumptions -->
To address this issue and facilitate the practical implementation of the theory, Thurstone developed five cases derived from this general form, each progressively incorporating additional simplifying assumptions. In Case I, Thurstone postulated that pairs of stimuli would maintain a constant correlation across all comparisons. In Case II, he allowed multiple judges to undertake comparisons instead of confining evaluations to a single judge. In Case III, he posited that there was no correlation between stimuli. In Case IV, he assumed that the stimuli exhibited similar dispersions. Finally, in Case V, he replaced this assumption with the condition that stimuli had equal discriminal dispersions. @tbl-thurstone_cases summarizes the assumptions of the general form and the five cases. For a detailed discussion of these cases and their progression, refer to @Thurstone_1927b and @Bramley_2008 [pp. 248–253].

<!-- In Case II, Thurstone assumes that "each judge compares each stimulus with every other stimulus only once" [@Thurstone_1927b, pp. 268]. -->

![Thurstones cases and their asumptions](/images/png/thurstone_cases.png){#tbl-thurstone_cases width=100%}

<!-- 3. But are our specific problems? -->
However, Thurstone designed Case V to provide a "rather coarse scaling" of traits [@Thurstone_1927b, pp. 269], prioritizing statistical simplicity over precise trait measurement. He cautioned that its use "should not be made without (an) experimental test" [@Thurstone_1927b, pp. 270], as it imposes the most extensive set of simplifying assumptions among all the proposed cases [@Bramley_2008, pp. 253; @Kelly_et_al_2022, pp. 677] (see @tbl-thurstone_cases). Therefore, it is surprising that, despite these limitations, CJ research has predominantly relied on Case V to measure different traits, raising significant concerns about the reliability and validity of such measurements in contexts where the case's assumptions may not hold [@Kelly_et_al_2022, pp. 677].

<!-- Adding assumptions simplifies the formula and improves its tractability, but one cannot place as much confidence in the outputs of the formula if those assumptions are not met [@Kelly_et_al_2022, pp. 677]. -->

Furthermore, since Thurstone's primary goal was to define a psychological scale and "allocate the compared stimuli on this continuum" [@Thurstone_1927b, pp. 269], he did not provide specific guidance on how to use the measurement scores from Case V to conduct hypothesis tests related to the measured traits. Although the CJ practice has circumvented this issue by using the point estimates of the scores or their transformations for such analyses, a fundamental question remains: Is this method appropriate for addressing these inquiries?

<!-- 4. Section division -->
Thus, this section discusses these two prominent issues. Specifically, @sec-theory-issue1 examines the heavy reliance on Thurstone's Case V assumptions in the statistical analysis of CJ data. Conversely, @sec-theory-issue2 focuses on the apparent disconnect between the approaches to trait measurement and hypothesis testing in CJ.


## The Case V and the statistical analysis of CJ data {#sec-theory-issue1}

<!-- recording: Sven and Tine 24.10.25; time: 00:31:10 - 00:52:20 -->
<!-- recording: Sven and Tine 24.11.12; time: 00:00:00 - 00:00:00 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:00:25 - 00:04:30 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:14:50 - 00:19:04 -->
<!-- recording: Sven and Tine 24.11.18; time: 00:21:37 - 00:47:20 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:06:55 - 00:24:50 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:35:10 - 00:49:30 -->
<!-- recording: Sven and Tine 24.12.09; time: 00:03:20 - 00:08:10 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:00:00 - 00:06:10 -->

<!-- 1. The Case V and its simpler statistical representation: the BTL model -->
As previously discussed, Case V remains the most widely used model in CJ literature. This preference primarily stems from the BTL model, which provides a simplified statistical representation of the case. The BTL model mirrors the assumptions of Case V, with one notable distinction: while Case V assumes a Normal distribution for the stimuli' discriminal processes, the BTL model uses the more mathematically tractable Logistic distribution [@Andrich_1978; @Bramley_2008, pp. 254] (see @tbl-thurstone_cases). However, this substitution has minimal impact on the model's estimation or interpretation because the discriminal process scale is arbitrary up to a non-monotonic transformation [@vanderLinden_et_al_2017_I, pp. 16; @McElreath_2021]. Furthermore, this limited impact is supported by the fact that the Normal and Logistic distributions exhibit analogous statistical properties, differing only by a scaling factor of approximately $1.7$.

<!-- the mathematical function linking dichotomous outcomes to trait scores -->

<!-- Model misspecification happens when the set of probability distributions considered by the statistician does not include the distribution that generated the observed data. -->

<!-- the scale of the latent variable is arbitrary, so there is no loss of generality [@McElreath_2021] 02:40:30 - 02:40:45  -->

<!-- ::: {#fig-logistic_vs_normal layout-nrow=2} -->

<!-- ![Probability density](/images/png/density.png){#fig-density width=70%} -->

<!-- ![Cummulative probability](/images/png/cummulative.png){#fig-cumulative width=70%} -->

<!-- Probability density and cumulative probability of the logistic and Normal distributions. -->
<!-- ::: -->

<!-- 2. But what are limitations of Case V (and the BTL model)? -->
However, Thurstone acknowledged that some assumptions of Case V could be problematic when researchers assess complex traits or heterogeneous stimuli [@Thurstone_1927a, pp. 376]. Thus, given that modern CJ applications often involve such traits and stimuli, two key assumptions of Case V, and by extension, the BTL model, may not always hold in theory or practice. These assumptions are the equal dispersion and zero correlation between stimuli.


### The assumption of equal dispersions between stimuli {#sec-theory-issue1a}

<!-- recording: Sven and Tine 24.12.09; time: 00:08:10 - 00:37:00 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:06:10 - 00:08:50 -->

<!-- 1. What does the equal dispersion between stimuli imply? -->
According to the theory, discrepancies in the discriminal dispersions of stimuli shape the distribution of the discriminal difference, directly influencing the outcome of pairwise comparisons. A thought experiment can help illustrate this idea. In this experiment, researchers observe the discriminal processes for two texts, similar to those shown in @fig-discriminal_process. Additionally, the discriminal dispersion for Text A remains constant, and the texts are uncorrelated  $(\rho=0)$. @fig-dispersion demonstrates that an increase in the uncertainty associated with the perception of Text B relative to Text A $(\sigma_{B} - \sigma_{A})$, broadens the distribution of their discriminal difference. This broadening affects the probability area where the discriminal difference distinctly favors Text B over Text A, expressed as $P(B>A)$, ultimately influencing the comparison outcome. Additionally, the figure reveals that when the discriminal dispersions of the texts are equal, as in the BTL model $(\sigma_{B} - \sigma_{A}=0)$, the discriminal difference is more narrow than when the dispersions differ. As a result, the discriminal difference is more likely to favor Text B over Text A, as it is represented by the shaded gray area.

::: {#fig-casev_issues layout-ncol=2}

![Discrepancies in the dispersions of stimuli](/images/png/dispersion.png){#fig-dispersion width=100%}

![Correlation between stimuli](/images/png/correlation.png){#fig-correlation width=100%}

The effect of dispersion discrepancies and stimuli correlation on the distribution of the discriminal difference.
:::

<!-- 2. But this is not the scenario we observe -->
In experimental practice, however, the thought experiment occurs in reverse. Researchers first observe the comparison outcome and then use the BTL model to infer the discriminal difference between stimuli and their respective discriminal processes [@Thurstone_1927a, pp. 373]. Consequently, the outcome's ability to reflect *true* differences between stimuli largely depends on the validity of the model's assumptions [@Kohler_et_al_2019, pp. 150], in this case, the assumption of equal dispersions. For instance, when the assumption accurately captures the complexity of the data, the BTL model estimates a discriminal difference distribution that accurately represents the *true* discriminal difference between the texts. This scenario is illustrated in @fig-dispersion, when the model's discriminal difference distribution aligns with the *true* discriminal difference distribution, represented by the thick continuous line corresponding to $\sigma_{B}-\sigma_{A}=0$. The accuracy of this discriminal difference then ensures reliable estimates for the texts’ discriminal processes. 

<!-- In experimental practice the procedure is the reverse of this hypothesis because the frequencies are known first experimentally, and from these frequencies we construct the psychological continuum. [@Thurstone_1927a, pp. 373] -->

<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are. [@Kohler_et_al_2019, pp. 150] -->

<!-- 3. But does it hold in practice?  -->
Notably, while the assumption of equal dispersions simplifies the trait measurement model, evidence from the CJ literature suggests that the BTL model may fail to capture the complexity of modern CJ data. Specifically, the assumption of equal dispersions may not hold when researchers assess complex traits or heterogeneous stimuli [@Thurstone_1927a, pp. 376; @Bramley_2008, pp. 273; @Kelly_et_al_2022, pp. 678], as these traits and stimuli can introduce judgment discrepancies due to their unique characteristics [@vanDaal_et_al_2016; @Lesterhuis_2018; @Chambers_et_al_2022]. Indeed, the CJ literature may already provide evidence of such discrepancies, particularly in the form of "misfit" statistics. For instance, *misfit texts* are those whose comparisons result in more judgment discrepancies than those involving other texts [@Pollitt_2004, pp. 11; @Pollitt_2012b, pp. 290].

<!-- It is probably true that this variability of the discriminal dispersion on the psychological continuum is of relatively less serious importance in dealing with strictly homogeneous stimulus series, but it becomes a serious factor in dealing with less conspicuous attributes or with less homogeneous stimulus series, such as handwriting specimens, English compositions, sewing samples, oriental rugs. In measurements of the type known as judgment scales the discriminal dispersion on the psychological continuum becomes one of the unknowns to be determined as well as the scale value of the specimen. Every specimen in such a series presents two unknown values to be determined, namely, the scale value of its modal discriminal process on the psychological continuum and its discriminal dispersion. [@Thurstone_1927a, pp. 376] -->

<!-- Of these, the most questionable is the one that the discriminal dispersions of all the objects are equal. Thurstone clearly did not expect this to hold for any but the most simple stimuli. The scripts used in cross-moderation exercises are obviously far more complex than any used by Thurstone, so it seems naive to expect this assumption to hold here [@Bramley_2008, pp. 273]. -->

<!-- It also seems unclear whether Thurstone’s work really can be applied to the stimuli typically used in assessment. While Thurstone used his Law to create measurement scales for purely psychological or subjective entities, he did so only with stimuli whose values could be evaluated relatively instantaneously, such as short statements and handwriting samples. He was also sceptical about its use for very heterogeneous stimuli (Thurstone, 1927b) [@Kelly_et_al_2022, pp. 678]. -->

<!-- For instance, in evaluating creativity, a student might complete an assignment in a highly creative but unexpected manner. Judges, unprepared for such originality, may produce more divergent evaluations of the assignment. These increased discrepancies in judgments suggest that the discriminal difference associated with the assignment has a broader dispersion, indicating greater variation in the discriminal process for this assignment compared to others. -->

<!-- "weak" writers consistently produce texts of low quality in all aspects that determine the quality of a text, such as grammatical accuracy, organization, and language use. In such cases, judges typically agree on their inferior quality, leading to a clear disfavoring of these texts compared to others. This agreement ultimately imply narrow dispersions for the discriminal differences related to these texts and, by extension, narrow discriminal processes for them. However, as texts improve along the trait continuum, with certain aspects showing improvement and others reaming unaltered, these variations introduce uncertainty into the judgments. Now, since judges often rely on various intricate characteristics of the texts to form their judgments [@vanDaal_et_al_2016; @Lesterhuis_2018; @Chambers_et_al_2022], these changes lead to greater discrepancies in their evaluations. This divergence ultimately imply broader discriminal differences and, by extension, more varied discriminal processes for the texts. -->

<!-- So it seem that the extreme of the discriminal process distribution of the stimuli have higher reliability than the center? -->


<!-- 4. How these judgment discrepancies can happen? -->
These discrepancies may arise from two possible causes. First, the discriminal processes of misfit texts may substantially overlap with those of non-misfit texts. Second, misfit texts may represent outlying observations with characteristics that make them difficult to compare and position on the trait scale. Regarding the first cause, the overlap can occur when misfit texts have equal dispersion and share the same trait space as non-misfit texts or when they exhibit larger discriminal dispersions. Although the BTL model can distinguish the first scenario, it is inherently agnostic to the second. @fig-discriminal_process illustrates how an increased discriminal dispersion can widen the overlap between two texts, leading to more judgment discrepancies. In the figure, Text B has a broader discriminal dispersion than Text A, expanding the overlap between their discriminal processes, a space where judges struggle to determine which text possesses more of the trait.

<!-- A similar challenge arises in the first scenario, where overlapping trait spaces contribute to judgment inconsistencies. -->

<!-- 5. So, what happens when the assumption does not hold? -->
Significant statistical and measurement issues can arise when the assumption of equal dispersions between stimuli does not hold. Specifically, the BTL model may overestimate the trait's reliability, that is, the degree to which the outcome accurately reflects the *true* discriminal differences between stimuli. This overestimation, in turn, results in spurious conclusions about these differences [@McElreath_2020, pp. 370] and, by extension, about the underlying discriminal processes of stimuli. @fig-dispersion also illustrates this scenario when the model's discriminal difference distribution aligns with the thick continuous line for $\sigma_{B}-\sigma_{A}=0$, while the *true* discriminal difference follows any discontinuous line where $\sigma_{B}-\sigma_{A} \neq 0$. 

<!-- But ignoring over-dispersion can also lead to all of the same problems as ignoring any predictor variable. Heterogeneity in counts can be a confound, hiding effects of interest or producing spurious inferences. [@McElreath_2020, pp. 370] -->

Finally, regarding the second cause, if researchers recognize that misfit statistics may represent outlying observations, the conventional CJ practice of  excluding stimuli based on these statistics [@Pollitt_2012a; @Pollitt_2012b; @vanDaal_et_al_2016; @Goossens_et_al_2018], may unintentionally discard valuable information, introducing bias into the trait estimates [@Zimmerman_1994; @McElreath_2020, chap. 12]. The direction and magnitude of these biases remain unpredictable, as they depend on which stimuli researchers exclude from the analysis.

<!-- Moreover, excluding data using ad hoc univariate procedures can compound these issues by discarding potentially valuable information, further exacerbating the bias [@Zimmerman_1994; @McElreath_2020] -->

<!-- If a portfolio’s WMS exceeds the criterion of mean plus two standard deviations, this means the judges did not judge it consistently, some considering it ‘better’ than others did. [@Pollitt_2012a, pp. 165] -->

<!-- Representations with a large infit are representations which lead to more inconsistent judgments [@Goossens_et_al_2018, pp. 20] -->

<!-- a misfit statistic. Essentially this reports the amount of inconsistency in the various judgements that have been made of that script. It can act as a flag identifying scripts that judges find difficult to judge [@Pollitt_2004, pp. 12] -->


### The assumption of zero correlation between stimuli {#sec-theory-issue1b}

<!-- recording: Sven and Tine 24.12.17; time: 00:08:50 - 00:10:30 -->

<!-- 1. What does the zero correlation between stimuli imply? -->
The correlation $\rho$ measures how much the judges' perception of a specific trait in one stimulus depends on their perception of the same trait in another. As with the discriminal dispersions, this correlation shapes the distribution of the discriminal difference, directly impacting the outcomes of pairwise comparisons. A similar thought experiment, as the one depicted in @sec-theory-issue1a, can illustrate this idea. The experiment only assumes that the discriminal dispersions for both texts remain constant. @fig-correlation reveals that as the correlation between the texts increases, the distribution of their discriminal difference becomes narrower. This narrowing affects the area under the curve where the discriminal difference distinctly favors Text B over Text A, denoted as $P(B > A)$, thus influencing the comparison outcome. Furthermore, the figure shows that when two texts are independent or uncorrelated $(\rho=0)$, their discriminal difference is less narrow compared to scenarios where the texts are positively correlated. As a result, the discriminal difference is less likely to favor Text B over Text A, as it is represented by the shaded gray area.

<!-- "It is a safe assumption that when the stimulus series is very homogeneous with no distracting attributes, the correlation between discriminal deviations is low and possible even zero" [@Thurstone_1927b, pp. 268]. -->

<!-- 2. But this is not the scenario we observe -->
As outlined in the previous section, researchers approach this process in reverse. They begin by observing the outcomes and using the BTL model to estimate the stimuli' discriminal differences and discriminal processes. Given that the BTL model assumes independent discriminal processes across comparisons, if this assumption holds in the data, the model estimates a discriminal difference distribution that accurately reflects the *true* discriminal difference between the texts. Once more, the accuracy of the discriminal difference ensures reliable estimates for the discriminal processes of the texts.

<!-- It then follows that the outcome's ability to represent the "true" differences between stimuli largely depends on the validity of the assumption of zero correlation. -->

<!-- 3. But does it hold?  -->
Thurstone assumed that stimuli were uncorrelated because judges' biases, arising from two opposing and equally weighted effects occurring during the pairwise comparisons, canceled each other out [@Thurstone_1927b, pp. 268]. @Andrich_1978 provided a mathematical demonstration of this cancellation using the BTL model under the assumption of discriminal processes with additive biases. However, evidence from the CJ literature indicates that the assumption of zero correlation does not hold in practice in at least two scenarios: when intricate aspects of multidimensional, complex traits or heterogeneous stimuli influence judges' perceptions or when additional hierarchical structures are relevant to the stimuli.

<!-- 2. The first scenario where the assumption does not hold -->
In the first scenario, research on text quality suggests that when judges evaluate multidimensional, complex traits or heterogeneous stimuli, they often rely on various intricate characteristics of the stimuli to form their judgments [@vanDaal_et_al_2016; @Lesterhuis_2018; @Chambers_et_al_2022]. These additional relevant characteristics, when assessed, are unlikely to be equally weighted or opposing. As a result, they may exert an uneven influence on judges' perceptions, creating biases that resist cancellation. For example, this could occur when a judge assessing the argumentative quality of a text places more weight on its grammatical accuracy than other judges, thereby favoring texts with fewer errors but weaker arguments. Furthermore, since the discriminal difference of the stimuli becomes an observable outcome only through the judges' perceptions, these biases could introduce dependencies between the stimuli [@vanderLinden_et_al_2017_II, pp. 346]. While direct evidence for this particular scenario is lacking, studies such as @Pollitt_et_al_2003 demonstrate the presence of such biases, supporting the notion that the factors influencing pairwise comparisons may not always cancel out.

<!-- If the test taker’s position on one latent trait is fixed, the assumption of local stochastic independence requires the association between the responses to the items to vanish. Suppose the assumption is violated and more than one dimension is necessary to describe the test takers’ position in the latent space. The association between the responses to the items given one proficiency parameter does then not vanish. [@vanderLinden_et_al_2017_II, pp. 346]. -->

<!-- research shows that, in the presence of these traits and stimuli, the accuracy of the judges' trait perception is influenced by the rank-order distance of the stimuli [@vanDaal_et_al_2017; @Gijsen_et_al_2021], a coarse measure of the relative positioning of the stimuli within the trait continuum. -->

<!-- 3. The second scenario where the assumption does not hold -->
In the second scenario, the shared context or inherent connections introduced by additional hierarchical structures may create dependencies between stimuli, a statistical phenomenon known as clustering [@Everitt_et_al_2010]. Although the CJ literature acknowledges the existence of such hierarchical structures, the statistical approaches to account for this additional source of dependence have been insufficient. For instance, when CJ data incorporates multiple samples of stimuli from the same individuals, researchers frequently rely on (averaged) point estimates of the BTL scores to conduct subsequent analyses and tests at the individual level [@Bramley_et_al_2019; @Boonen_et_al_2020; @Bouwer_et_al_2023; @vanDaal_et_al_2017; @Jones_et_al_2019; @Gijsen_et_al_2021]. However, this approach can introduce additional statistical and measurement issues, which we discuss in greater detail in @sec-theory-issue2.

<!-- no study explicitly proposes that this assumption could also be violated due to the presence of an additional hierarchical (grouping) structure relevant to the texts. One such scenario might arise, for example, when comparing texts produced by university and secondary school students. In this case, university students may consistently (or more precisely) produce higher-quality texts, while secondary school students, who exhibit a broader range of writing abilities, would show greater variability in the quality of their texts. Although this example is somewhat contrived, it effectively illustrates how assuming equal dispersions across texts can overlook meaningful differences in the reliability of text quality across groups or individuals. -->

<!-- 3. But what are the challenges when this assumption is violated? -->
Thus, erroneously assuming zero correlation between stimuli can also lead to significant statistical and measurement issues. Specifically, neglecting judges' biases or relevant hierarchical structures can create dimensional mismatches in the model, leading to the over- or underestimation of trait reliability [@Ackerman_1989; @Hoyle_et_al_2023, pp. 341, 482]. These inaccuracies can result in spurious conclusions about the discriminal differences [@McElreath_2020, pp. 370] and, by extension, the underlying discriminal processes of the stimuli. This issue is illustrated in @fig-correlation when the discriminal difference distribution of the BTL scores follows the thick continuous line $(\rho = 0)$, while the *true* discriminal difference follows any discontinuous line where $\rho \neq 0$. 

<!-- To show the practical consequences, in Figure 18.1, we present the test information for the two models; clearly, the information is positively biased when the multidimensional data are forced into a unidimensional IRT model. Moreover, in this same figure, we show the test response curves (how expected scores change as a function of trait level) for the two models; again, they, clearly, are not overlapping. The estimated implication is that if one applied a unidimensional IRT model, psychometric information is inflated due to the multidimensionality and examinee standard errors, which are the inverse square root of information, are too small. [@Hoyle_et_al_2023, pp. 340-341] -->

<!-- Accounting for measurement error in defining latent variables improves the accuracy of the model’s estimated structural parameters between the latent constructs, which in turn can provide a stronger test of a proposed theoretical model. [@Hoyle_et_al_2023, pp. 482] -->

Finally, as discussed in the previous section, removing *misfit* judges based risks discarding valuable information and even introduce bias into the trait estimates [@Zimmerman_1994; @McElreath_2020, chap. 12]. The direction and magnitude of these biases remain unpredictable because they depend on which judges researchers exclude from the analysis. *Misfit judges* are those whose evaluations deviate substantially from the shared consensus due to the unique characteristics of either the stimuli or the judges themselves [@Pollitt_2012a, pp. 164-165; @Pollitt_2012b, pp. 289-290; @vanDaal_et_al_2016, pp. 4; @Goossens_et_al_2018, pp. 20]. 

<!-- These "misfit" judges and their associated deviations can give rise to additional statistical and measurement issues, which we discuss in more detail in @sec-theory-issue1b. -->


## The disconnect between trait measurement and hypothesis testing {#sec-theory-issue2}

<!-- recording: Sven 24.10.04; time: 00:14:30 - 00:21:00 -->
<!-- recording: Sven and Tine 24.10.18; time: 00:08:30 - 00:14:55 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:49:30 - 00:53:30 -->

<!-- 1. Utilizing BTL Scores for further analysis and hypothesis testing -->
Building on the previous section, it is clear that, researchers typically rely on the BTL model to measure a trait and place the compared stimuli along its continuum [@Thurstone_1927b, pp. 269]. Additionally, the CJ literature shows that researchers frequently use point estimates of BTL scores or their transformations to conduct further analyses or hypothesis tests. For example, researchers have used these scores to identify 'misfit' judges and stimuli [@Pollitt_2012b; @vanDaal_et_al_2016; @Goossens_et_al_2018], detect biases in judges' ratings [@Pollitt_et_al_2003; @Pollitt_2012b], calculate correlations with other assessment methods [@Goossens_et_al_2018; @Bouwer_et_al_2023], or test hypotheses related to the underlying trait of interest [@Casalicchio_et_al_2015; @Bramley_et_al_2019; @Boonen_et_al_2020; @Bouwer_et_al_2023; @vanDaal_et_al_2017; @Jones_et_al_2019; @Gijsen_et_al_2021].

<!-- 3. But what are the challenges in using BTL scores for further analysis? -->
Nevertheless, while separating the trait measurement and hypothesis testing processes simplifies the analysis of CJ data, the statistical literature cautions against relying solely on the point estimates of BTL scores to conduct further analyses or hypothesis tests, as this practice can undermine the resulting statistical conclusions. A key consideration is that BTL scores are parameter estimates that inherently carry uncertainty (measurement error). Ignoring this uncertainty can bias the analysis and reduce the precision of hypothesis tests. The direction and magnitude of such biases are often unpredictable. Results may be attenuated, exaggerated, or remain unaffected depending on the degree of uncertainty in the scores and the actual effects being tested [@Kline_et_al_2023, pp. 25; @Hoyle_et_al_2023, pp. 137]. Furthermore, the reduced precision in hypothesis tests diminishes their statistical power, increasing the likelihood of committing type-I or type-II errors [@McElreath_2020]. @fig-measurement_error illustrates these issues, demonstrating how neglecting measurement error $(\sigma_{T})$ by relying only on outcome averages can reduce the precision of a predictor’s estimated effect.

<!-- A type-I error occurs when a *true* null hypothesis is incorrectly rejected, while a type-II error occurs when a *false* null hypothesis is incorrectly accepted [@Everitt_et_al_2010]. -->

![The effect of outcome uncertainty $\sigma_{T}$ on the estimation of an effect $\beta_{X}$ linked to the predictor. The example assumes a sample size $n=100$ and an uncertainty that increases from left to right.](/images/png/measurement_error.png){#fig-measurement_error width=100%}

<!-- 4. segway for next section -->
In aggregate, the heavy reliance on Thurstone's Case V assumptions in the statistical analysis of comparative data can compromise the reliability of trait estimates. This overreliance may also undermine their validity [@Perron_et_al_2015, pp. 2], particularly when coupled with the disconnect between the trait measurement and hypothesis testing processes. However, the structural approach to causal inference can address these issues by offering a systematic and integrated framework that strengthens measurement reliability and validity while enhancing the statistical accuracy of hypothesis tests.

<!-- Reliability is a necessary but not sufficient condition for validity. Reliability can exist without validity but validity cannot exist without reliability [@Perron_et_al_2015, pp. 2]. -->

<!-- "If Thurstone’s Law is to be used in support of comparative judgment for assessment, his theory must be extended to cover the uses and applications that are required for assessment purposes." [@Kelly_et_al_2022, pp. 678] -->


<!-- ## The diverse assessment design features and their role on reliability and validity {#sec-theory-issue3} -->
<!-- Do not include yet!, until you see if you need it when you write about the next section -->
<!-- recording: Sven and Tine 24.11.18; time: 00:47:20 - 00:56:41 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:53:30 - 01:00:00 -->



# Extending Thurstone's general form {#sec-theoretical}

<!-- recording: Sven and Tine 25.01.22; time: 00:05:40 - 00:06:30 -->
<!-- recording: Sven and Tine 25.01.22; time: 00:08:25 - 00:31:56 -->
<!-- recording: Sven and Tine 25.01.30 p1; time: 00:00:00 - 00:23:25 -->
<!-- recording: Sven and Tine 25.02.07; time: 00:02:20 - 00:06:20 -->

<!-- 1. The structural approach to causal inference -->
The *structural approach* to causal inference provides a formal framework for identifying causes and estimating their effects using data. The approach uses structural causal models (SCMs) and directed acyclic graphs (DAGs) [@Pearl_2009; @Pearl_et_al_2016; @Gross_et_al_2018; @Neal_2020] to formally and graphically represent the assumed causal structure of a system, such as the one found in CJ experiments. Essentially, SCMs and DAGs function as *conceptual models* on which identification analysis rests [@Schuessler_et_al_2023, pp. 4]. *Identification analysis* helps researchers to determine whether an estimator can accurately compute an estimand based solely on its (causal) assumptions, regardless of random variability [@Schuessler_et_al_2023, pp. 4]. Here, *estimands* represent the specific quantities researchers aim to determine [@Everitt_et_al_2010]. *Estimators* denote the methods or functions that transform data into an estimate, while *estimates* are the numerical values approximating the estimand [@Neal_2020; @Everitt_et_al_2010]. 

<!-- The causal assumptions encoded in a DAG constitute the theoretical model on which identification analysis rests. Identification analysis is concerned with determining whether or not the true value of a parameter can be estimated using the assumptions in the model (graph), regardless of random variability in the data due to small samples [@Schuessler_et_al_2023, pp. 4]. -->

<!-- In general terms, causal graphs encode a researcher’s assumptions about the causal process that generated the data in a population of interest [@Schuessler_et_al_2023, pp. 4] -->

<!-- 3. Example of a CJ estimand and estimator, and its limitations -->
A motivating example that will appear in the rest of the document clarifies these concepts. In this example, researchers aim to determine: "To what extent do different teaching methods influence students' ability to produce high-quality written texts?" To investigate this, a researcher designs a CJ experiment by randomly assigning students (individuals) to two groups, each receiving a different teaching method. Judges then compare pairs of students' written texts (stimuli) to produce a dichotomous outcome reflecting the relative quality of each text (trait). Based on this setup, researchers can reformulate the research question as the estimand: "*On average*, is there a difference in the ability to produce high-quality written texts between the two groups of students?". Following current CJ practices, researchers rely on estimates from the BTL model, or its transformations, to approximate this estimand.

<!-- 4. But why identification is so important? -->
However, @sec-theory-issues presents compelling evidence that Thurstone's Case V, and by extension the BTL model, suffers from several statistical and measurement limitations. These limitations hinder the model’s ability to identify various estimands relevant to CJ inquiries, including the one described in the example. Identification is crucial because it is a necessary condition for ensuring consistent estimators. *Consistency* refers to the property of an estimator whose estimates converge to the "true" value of the estimand as the data size approaches infinity [@Everitt_et_al_2010]. Without identification, consistency cannot be achieved, even with "infinite" and error-free data. Thus, deriving meaningful insights from finite data becomes impossible [@Schuessler_et_al_2023, pp. 5].

<!-- The main reason to focus on identification is that if these parameters cannot be identified using "infinite" and error free data, we certainly cannot learn anything about it using finite data. So, for the time being, we assume large samples and error-free measurements [@Schuessler_et_al_2023, pp. 5]. -->

<!-- 5. So, how do SCMs and DAGs support identification? -->
Luckily, SCMs and DAGs support identification analysis through two key advantages. First, regardless of complexity, they can represent various causal structures using only five fundamental building blocks. This feature allows researchers to decompose complex structures into manageable components, facilitating their analysis [@Neal_2020; @McElreath_2020]. Second, they depict causal relationships in a non-parametric way. This flexibility enables feasible identification strategies without requiring specification of the types of variables, the functional forms relating them, or the parameters of those functional forms [@Pearl_et_al_2016, pp. 35].

<!-- 6. What the section will do? -->
Thus, this section addresses the issues identified in @sec-theory-issues by extending Thurstone's general form using the structural approach to Causal inference. Specifically, it combines the core theoretical principles outlined in @sec-thurstone_theory with key assessment design features relevant to CJ experiments, such as the selection of judges, stimuli, and comparisons. In addition to improving statistical accuracy and strengthening measurement reliability and validity, the approach offers two key advantages. First, it clarifies the interactions among all actors and processes involved in CJ experiments. Second, it shifts the current comparative data analysis paradigm from passively accepting the model assumptions to actively testing whether those assumptions fit the data under analysis.

<!-- 7. How the section is divided? -->
Accordingly, @sec-theory-theoretical_P incorporates the theoretical principles into what we refer to as the *conceptual-population model*. This model assumes that researchers have access to a *conceptual population* of comparative data, that is, data representing all repeated judgments made by every available judge for each pair of stimuli produced by each pair of individuals in the population. Conversely, @sec-theory-theoretical_SC integrates the assessment design features into what we refer to as the *sample-comparison model*. This model assumes a more realistic scenario where researchers only have access to a sample of judges, individuals, stimuli, and comparisons from the conceptual population.

<!-- Generalizability is the degree to which you can apply the results of your study to a broader context.  -->
<!-- https://www.scribbr.com/research-bias/generalizability/ -->

<!-- A theoretical model is a framework that researchers create to structure a study process and plan how to approach a specific research inquiry. It can allow you to define the purpose of your research and develop an informed perspective. Creating a theoretical model typically involves analyzing a subject's literature, including previous research studies and journal articles. Researchers often include a written description of a theoretical model in a beginning section of a dissertation or similar document so a reader can gain more context. -->
<!-- url: https://www.indeed.com/career-advice/career-development/theoretical-model -->


## The conceptual-population model {#sec-theory-theoretical_P}

<!-- general development -->
<!-- recording: Sven 24.10.04; time: 00:21:00 - 00:34:10 -->
<!-- recording: Sven 24.10.04; time: 00:41:00 - 00:46:00 -->
<!-- recording: Sven and Tine 24.10.18; time: 00:00:00 - 00:04:05 -->
<!-- recording: Sven and Tine 24.11.25; time: 01:00:00 - 01:08:40 -->
<!-- recording: Sven and Tine 24.12.17; time: 00:26:10 - 00:54:00 -->
<!-- recording: Sven and Tine 25.01.30 p1; time: 00:23:25 - 00:48:00 -->
<!-- recording: Sven and Tine 25.02.07; time: 00:00:00 - 00:02:20 -->

<!-- 1. What is the assumption on the conceptual-population model -->
In the conceptual-population model, we assume an idealized scenario where researchers have access to a *conceptual population* of comparative data --data representing *all repeated judgments made by each judge for every stimulus pair produced by each pair of individuals* in the population. This assumption allows us to integrate Thurstone's theoretical principles and propose innovations to address some of the issues raised in @sec-theory-issues.


### Integrating the first theoretical principles {#sec-theory-theoretical_P1}

<!-- 1. The SCMs -->
Before incorporating the first theoretical principles of Thurstone's theory, it is essential to further define SCMs. SCMs are formal mathematical models characterized by a set of *endogenous* variables $V$, a set of *exogenous* variables $E$, and a set of functions $F$ [@Pearl_2009; @Cinelli_et_al_2020]. Endogenous variables are those whose causal mechanisms a researcher chooses to model [@Neal_2020]. In contrast, exogenous variables represent *errors* or *disturbances* arising from omitted factors that the investigator chooses not to model explicitly [@Pearl_2009, pp. 27,68]. Lastly, the functions, referred to as *structural equations*, express the endogenous variables as non-parametric functions of other endogenous and exogenous variables. These functions use the symbol '$:=$' to denote the asymmetrical causal dependence between variables and the symbol '$\dsep$' to represent *d-separation*, a concept akin to (conditional) independence.

<!-- 2. the preliminary SCM for CJ -->
[SCM -@fig-cj03_scm] illustrates the inclusion of the first theoretical principles into the conceptual-population model designed to examine the impact of different teaching methods on students' writing ability. This SCM outlines the relationship between the conceptual-population outcome $(O^{cp}_{hiabjk})$ and several related variables. The subscripts $h$ and $i$ label the students who authored the texts (individuals), while the indices $a$ and $b$ represent the compared texts (stimuli). The index $j$ refers to the judge, and $k$ represents the judgment index, accounting for experimental conditions where judges perform the same judgment multiple times, i.e., a *repeated measures design* [@Lawson_2015, pp. 366-376]. Notably, the indexing system facilitates comparisons between texts written by the same student $(h = i, a \neq b)$ and between texts written by distinct students ($h \neq i$, where $a = b$ is possible). However, it excludes cases where judges compare a student's text to itself $(h = i, a = b)$, as such comparison lacks practical relevance within the CJ framework.

In line with Thurstone's theory, [SCM -@fig-cj03_scm] depicts the texts' discriminal processes $(T_{ha}, T_{ib})$ and their discriminal difference $(D_{hiabjk})$ (see @sec-thurstone_theory). Additionally, based on the arguments developed in @sec-theory-issue1b and the recommendations of @Andrich_1978 and @Wainer_et_al_1978, the SCM incorporates the judges' biases $(B_{kj})$. Together with the outcome, these variables constitute the preliminary set of endogenous variables, $V = \{ O_{hiabjk}, D_{hiabjk}, T_{ha}, T_{ib}, B_{kj} \}$. Finally, the SCM presents the preliminary set of structural equations, $F = \{ f_{O}, f_{D} \}$, which define the non-parametric dependencies among these variables.

<!-- @Andrich_1978 and @Wainer_et_al_1978 recommend integrating judges' biases into the BTL model. Moreover, the literature advocates for the incorporation of relevant hierarchical structures into the statistical model to account for these dependencies. Together, these additions can result in a model resembling a Multilevel Structural Equation Model (MSEM) [@Hoyle_et_al_2023, chap. 26] combined with a multidimensional or two-parameter logistic Item Response Theory (IRT) model [@Hoyle_et_al_2023, chap. 15], depending on the theoretical and statistical treatment of judges' biases. -->


::: {#fig-cj03 layout-nrow=2}

::: {#fig-cj03_scm fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  O^{cp}_{hiabjk} & := f_{O}(D_{hiabjk}) \\
  D_{hiabjk} & := f_{D}(T_{ha}, T_{ib}, B_{jk})
\end{aligned}
$$

SCM
:::

![DAG](/images/png/CJ_TM_03.png){#fig-cj03_dag fig-align="center" fig-pos="H" width=35%}


Conceptual-population model, scalar form.
:::

<!-- 3. The DAGs -->
Notably, every SCM has an associated DAG [@Pearl_et_al_2016; @Cinelli_et_al_2020]. A DAG is a *graph* consisting of nodes connected by edges, where nodes represent random variables. The term *directed* indicates that edges or arrows extend from one node to another, indicating the direction of causal influence. The absence of an edge implies no direct relationship between the nodes. The term *acyclic* means that the causal influences do not form loops, ensuring the influences do not cycle back on themselves [@McElreath_2020]. DAGs conventionally depict observed variables as solid black circles and unobserved (latent) variables as open circles [@Morgan_et_al_2014]. Although DAGs often omit exogenous variables for simplicity, the DAGs presented in this section includes exogenous variables to improve clarity and reveal potential issues related to conditioning and confounding [@Cinelli_et_al_2020].

<!-- the *standard representation* omit exogenous variables for simplicity -->
<!-- the *magnified representation* includes exogenous variables -->


<!-- 4. the preliminary DAG for CJ -->
@fig-cj03_dag displays the DAG corresponding to [SCM -@fig-cj03_scm], illustrating the expected causal relationships outlined in Thurstone's theory. The graph shows that the discriminal processes of the texts $(T_{ha}, T_{ib})$ influence their discriminal difference $(D_{hiabjk})$, which in turn determines the outcome $(O^{cp}_{hiabjk})$. It also highlights the influence of judges' biases $(B_{kj})$ on the discriminal difference. Additionally, the DAG differentiates between observed endogenous variables, such as the outcome (solid black circle), and latent endogenous variables, including the texts' discriminal processes, their discriminal difference, and the judges' biases (open circles).

<!-- To use graphs to reason about confounding control and other forms of bias requires that the representation on the graph be such that there is: -->
<!-- 1. No ungraphed confounding: Any variable that affects two or more variables in the graph via distinct direct effects must be shown on the graph as an ancestor of the affected variables, even if it is unmeasured. -->
<!-- 2. No ungraphed collider stratification: Any variable that affects selection or is used for stratification and is affected by two or more variables in the graph (including its random disturbance) must be shown on the graph as a descendant of the variables affecting it, even if it is unmeasured. -->
<!-- As may become clear from the descriptions below, these requirements are needed to ensure that any association between two variables in the graph can be atributed solely to open paths between the variables within the graph, and thus can be traced to either variation in graphed causal variables, or conditioning on effects of such variables, or both. Conditions 1 and 2 enforce the connectivity requirement of DAGs by demanding the graph we draw show all variables which can causally explain associations (either as uncontrolled confounders or as controlled colliders), even if those variables are unmeasured or hypothetical. [@Lash_et_al_2021, pp. 113] -->


### The *conceptual population* data structure {#sec-theory-theoretical_P2}

<!-- recording: Sven and Tine 25.03.28; time: 00:10:00 - 00:11:00 -->

<!-- 1. Why is useful to declare the data structure? -->
Although specifying a data structure is not mandatory when using SCMs and DAGs, defining one in this case can improve clarity and facilitate the description of the system. Thus, to re-express the scalar form of the CJ system shown in @fig-cj03 into an equivalent vectorized form, we first define the vectors $I$ and $J$, along with the matrices $IA$ and $JK$, as follows:

$$
I = \begin{bmatrix}
1 \\
2 \\
\vdots \\
h \\
\vdots \\
i \\
\vdots \\
n_{I}
\end{bmatrix} ; \;
J = \begin{bmatrix}
1 \\
2 \\
\vdots \\
j \\
\vdots \\
n_{J}
\end{bmatrix} ; \;
IA = \begin{bmatrix}
1 & 1 \\
1 & 2 \\
\vdots & \vdots \\
1 & n_{A}-1 \\
1 & n_{A} \\
\vdots & \vdots \\
h & a \\
\vdots & \vdots \\
i & b \\
\vdots & \vdots \\
n_{I} & n_{A}-1 \\
n_{I} & n_{A} \\
\end{bmatrix} ; \;
JK = \begin{bmatrix}
1 & 1 \\
1 & 2 \\
\vdots & \vdots \\
1 & n_{K}-1 \\
1 & n_{K} \\
\vdots & \vdots \\
j & k \\
\vdots & \vdots \\
n_{J} & n_{K}-1 \\
n_{J} & n_{K} \\
\end{bmatrix}
$$ {#eq-mat11}


<!-- 2. what is the data structure? -->
Here, each element of $I$ represents a unique individual $h$ or $i$, where $n_{I}$ denotes the total number of individuals. Similarly, each element of $J$ corresponds to a unique judge $j$, with $n_{J}$ indicating the total number of judges. Moreover, each row of $IA$ represents a unique pairing of individuals $h, i$ with stimuli $a, b$. As a result, the matrix $IA$ contains $n_{I} \cdot n_{A}$ rows and $2$ columns, where $n_{A}$ specifies the number of stimuli available per individual. Likewise, each row of $JK$ associates a judge $j$ with a judgment index $k$. Consequently, the matrix $JK$ has $n_{J} \cdot n_{K}$ rows and $2$ columns, where $n_{K}$ indicates the number of judgments each judge makes.

Additionally, we construct the matrix $R$ to map each row of the $IA$ matrix with a corresponding row from the $JK$ matrix. Thus, this matrix has $n$ rows and $6$ columns, where $n = {n_{I} \cdot n_{A} \choose 2} \cdot n_{J} \cdot n_{K}$. Here, the term ${n_{I} \cdot n_{A} \choose 2}$ represents the binomial coefficient, which quantifies the total number of unique comparisons possible between every pair of stimuli generated by each pair of individuals in the population. Thus, we define the matrix as follows:

<!-- $$ -->
<!-- {n_{I} \cdot n_{A} \choose 2} = \frac{ (n_{I} \cdot n_{A})! }{ 2! (n_{I} \cdot n_{A} - 2)! } -->
<!-- $$ -->

$$
R = \begin{bmatrix}
1 & 1 & 1 & 2 & 1 & 1 \\
1 & 1 & 1 & 2 & 1 & 2 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
1 & 1 & 1 & 2 & 1 & n_{K}-1 \\
1 & 1 & 1 & 2 & 1 & n_{K} \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
h & i & a & b & j & k \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
n_{I} & n_{I} & n_{A}-1 & n_{A} & n_{J} & 1 \\
n_{I} & n_{I} & n_{A}-1 & n_{A} & n_{J} & 2 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
n_{I} & n_{I} & n_{A}-1 & n_{A} & n_{J} & n_{K}-1 \\
n_{I} & n_{I} & n_{A}-1 & n_{A} & n_{J} & n_{K} \\
\end{bmatrix}
$$ {#eq-mat12}


It is easier to visualize the structure of these vectors and matrices by considering an example where $n_{I} = 5$, $n_{A} = 2$, $n_{J} = 3$, and $n_{K} = 3$. In this simple case, the vectors and matrices described in equations ([-@eq-mat11]) and ([-@eq-mat12]) take the following form:

$$
I = \begin{bmatrix}
1 \\
2 \\
3 \\
4 \\
5 \\
\end{bmatrix} ; \;
J = \begin{bmatrix}
1 \\
2 \\
3 \\
\end{bmatrix} ; \;
IA = \begin{bmatrix}
1 & 1 \\
1 & 2 \\
2 & 1 \\
2 & 2 \\
3 & 1 \\
3 & 2 \\
4 & 1 \\
4 & 2 \\
5 & 1 \\
5 & 2 \\
\end{bmatrix} ; \;
JK = \begin{bmatrix}
1 & 1 \\
1 & 2 \\
1 & 3 \\
2 & 1 \\
2 & 2 \\
2 & 3 \\
3 & 1 \\
3 & 2 \\
3 & 3 \\
\end{bmatrix} ; \;
R = \begin{bmatrix}
1 & 1 & 1 & 2 & 1 & 1 \\
1 & 1 & 1 & 2 & 1 & 2 \\
1 & 1 & 1 & 2 & 1 & 3 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
1 & 1 & 5 & 1 & 1 & 1 \\
1 & 1 & 5 & 1 & 1 & 2 \\
1 & 1 & 5 & 1 & 1 & 3 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
1 & 1 & 5 & 1 & 3 & 1 \\
1 & 1 & 5 & 1 & 3 & 2 \\
1 & 1 & 5 & 1 & 3 & 3 \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
5 & 1 & 5 & 2 & 3 & 1 \\
5 & 1 & 5 & 2 & 3 & 2 \\
5 & 1 & 5 & 2 & 3 & 3 \\
\end{bmatrix}
$$ {#eq-mat13}

::: {#fig-cj04 layout-nrow=2}

::: {#fig-cj04_scm fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  O^{cp}_{R} & := f_{O}(D_{R}) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK})
\end{aligned}
$$

SCM
:::


![DAG](/images/png/CJ_TM_04.png){#fig-cj04_dag fig-align="center" fig-pos="H" width=44%}

Conceptual-population model, vectorized form.
:::

<!-- 3. how de we use that data structure? -->
Now, using equations ([-@eq-mat11]) and ([-@eq-mat12]), we can re-express [SCM -@fig-cj03_scm] and [DAG -@fig-cj03_dag] in an equivalent vectorized form, as shown in @fig-cj04. In this depiction, the outcome $O^{cp}_{R}$, the texts' discriminal difference $D_{R}$, their discriminal processes $T_{IA}$, and the judges' biases $B_{JK}$ are represented as vectors rather than scalar values. These vectors capture all the observations from the conceptual population. Specifically, $O^{cp}_{R}$ and $D_{R}$ are observed and latent vectors of length $n$, respectively. Moreover, $T_{IA}$ and $B_{JK}$ are latent vectors of lengths $n_{I} \cdot n_{A}$ and $n_{J} \cdot n_{K}$, respectively.


### Integrating hierarchical structural components {#sec-theory-theoretical_P3}

<!-- recording: Sven and Tine 25.03.28; time: 00:12:45 - 00:33:00 -->

<!-- 1. What are we going to do? -->
Building on the principles of Structural Equation Modeling (SEM) [@Hoyle_et_al_2023, pp. 138] and Item Response Theory (IRT) [@Fox_2010, chap. 6; @vanderLinden_et_al_2017_I, chap. 24], the conceptual-population model integrates two *hierarchical structural components* to examine how different teaching methods influence students' writing ability. Each structural component defines how observed or latent variables affect the primary latent variable of interest [@Everitt_et_al_2010]. Their hierarchical nature enables researchers to test hypotheses considering the hierarchical structure of stimuli (see @sec-theory-issue1b) and the uncertainties in trait estimation (see @sec-theory-issue2).

<!-- 2 Explaining what we did -->
The top branch of [DAG -@fig-cj09_dag] illustrates the first component, where *relevant* [^1] student-related variables $(X_{I})$, such as the teaching method, causally influence the latent variable representing students' writing-quality trait $(T_{I})$. It also shows how $T_{I}$ and *relevant* [^2] text-related variables $(X_{IA})$ (e.g., text length) causally influence the texts' written-quality trait $(T_{IA})$, the first primary latent variable of interest. Additionally, the branch accounts for idiosyncratic errors: $e_{I}$ captures variations in students' traits unexplained by $X_{I}$, while $e_{IA}$ captures variations in texts' traits unexplained by $T_{I}$ or $X_{IA}$. Here, $X_{I}$ is an observed matrix with $n_{I}$ rows and $q_{I}$ columns (variables), and both $e_{I}$ and $T_{I}$ are latent vectors of length $n_{I}$. Similarly, $X_{IA}$ is an observed matrix with dimension $n_{I} \cdot n_{A}$ rows and $q_{IA}$ columns (variables), while $e_{IA}$ and $T_{IA}$ are latent vectors of length $n_{I} \cdot n_{A}$.

[^1]: Here, *relevant* refers to variables that satisfy the *backdoor criterion* [@Neal_2020, pp 37], that is, they belong to a *sufficient adjustment set* [@Pearl_2009; @Pearl_et_al_2016; @Morgan_et_al_2014]. A *sufficient* set (potentially empty) blocks all non-causal paths between a predictor and an outcome without opening new ones [@Pearl_2009]. These topics are beyond the scope of this study, thus, readers seeking a more profound understanding can refer to introductory papers such as @Pearl_2010, @Rohrer_2018, @Pearl_2019, and @Cinelli_et_al_2020, as well as introductory books like @Pearl_et_al_2018, @Neal_2020, and @McElreath_2020 useful. For more advanced study, seminal papers such as @Neyman_et_al_1923, @Rubin_1974, @Spirtes_et_al_1991, and @Sekhon_2009, along with books such as @Pearl_2009, @Morgan_et_al_2014, and @Hernan_et_al_2020, are recommended.

[^2]: refer to footnote 1.

::: {#fig-cj09 layout-nrow=2}

::: {#fig-cj09_scm fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  O^{cp}_{R} & := f_{O}(D_{R}) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\
  e_{I} & \dsep \{ e_{J}, e_{IA}, e_{JK} \} \\
  e_{J} & \dsep \{ e_{IA}, e_{JK} \} \\
  e_{IA} & \dsep e_{JK} 
\end{aligned}
$$

SCM
:::


![DAG](/images/png/CJ_TM_09.png){#fig-cj09_dag fig-align="center" fig-pos="H" width=70%}

Conceptual-population model, final vectorized form.
:::


Similarly, the bottom branch of [DAG -@fig-cj09_dag] depicts the second component, where *relevant* [^3] judge-related variables $(Z_{J})$, such as judgment expertise, causally influence the latent variable representing judges' bias $(B_{J})$. It also shows how $B_{J}$ and *relevant* [^4] judgment-related variables $(Z_{JK})$ (e.g., the number of judgments a judge makes) causally influence the biases associated with each text $B_{JK}$, the second primary latent variable of interest. Additionally, the branch accounts for idiosyncratic errors: $e_{J}$ captures variations in judges' bias unexplained by $Z_{J}$, while $e_{JK}$ captures variations in judgments unexplained by $B_{J}$ or $Z_{JK}$. Here, $Z_{J}$ is an observed matrix with $n_{J}$ rows and $q_{J}$ columns (variables), and both $e_{J}$ and $B_{J}$ are latent vectors of length $n_{J}$. Similarly, $Z_{JK}$ is an observed matrix with dimension $n_{J} \cdot n_{K}$ rows and $q_{JK}$ columns (variables), while $e_{JK}$ and $B_{JK}$ are latent vectors of length $n_{J} \cdot n_{K}$.

[^3]: refer to footnote 1.
[^4]: refer to footnote 1.

Notably, all variables and functions shown in [SCM -@fig-cj09_scm] and [DAG -@fig-cj09_dag] are part of the set of endogenous variables $V$, structural equations $F$, and exogenous variables $E$ for the conceptual-population model. Additionally, the figures demonstrate that all exogenous variables are independent of one another, as indicated by the relationships $e_{IA} \dsep \{ e_{I}, e_{JK}, e_{J} \}$, $e_{I} \dsep \{ e_{JK}, e_{J} \}$ and $e_{JK} \dsep e_{J}$.

<!-- 3. segway for next section -->
Overall, the conceptual-population model extends Thurstone's general form by introducing key innovations to address the limitations discussed in @sec-theory-issue1b and @sec-theory-issue2. These enhancements include accounting for judges' biases and integrating hierarchical structural components. Nevertheless, despite its promise of enhancing measurement accuracy and precision, the model still depends on the unrealistic assumption that researchers have access to a *conceptual population* of comparative data, encompassing all repeated judgments from every judge for each pair of stimuli produced by every individual in the population. Since researchers rarely meet this assumption in practice, they must consider a more realistic scenario. The extensions to the conceptual-population model, derived from this realistic scenario, are described in the sample-comparison model.


## The sample-comparison model {#sec-theory-theoretical_SC}

<!-- recording: Sven 24.10.04; time: 00:09:10 - 00:14:30 -->
<!-- recording: Sven 24.10.04; time: 00:34:10 - 00:41:00 -->

<!-- 1. What is the more realistic scenario: the sample mechanism -->
In the sample-comparison model, we assume a more realistic scenario than the conceptual-population model. Specifically, we assume researchers have access to a data sample consisting of a *limited number of judgments $(n^{s}_{K})$ from a sample of judges $(n^{s}_{J})$ and a specific number of texts $(n^{s}_{A})$ from a sample of students $(n^{s}_{I})$*, drawn from the conceptual population. In a subsequent step, we assume that judges *do not make all possible comparisons* allowed by the sample, but rather only $n_{C}$ comparisons.


### The sample mechanism {#sec-theory-theoretical_SC1}

<!-- recording: Sven and Tine 25.03.28; time: 00:09:00 - 00:10:00 -->
<!-- recording: Sven and Tine 25.03.28; time: 00:11:30 - 00:12:25 -->

<!-- Develop how you get the vectors S and C and sampling weights when you know the extension of the population. (See https://mc-stan.org/docs/stan-users-guide/poststratification.html ) -->

<!-- 1. start by defining the sampling vector and matrices  -->
To incorporate the sampling mechanism and facilitate the interpretation of the sample-comparison model, we first define the data sampling process using the binary vector variables $S_{I}$, $S_{J}$, $S_{IA}$, and $S_{JK}$ as follows:

$$
S_{I} = \begin{bmatrix}
i_{(1)} \\
\vdots \\
i_{(h)} \\
\vdots \\
i_{(i)} \\
\vdots \\
i_{(nI)}
\end{bmatrix} ; \;
S_{J} = \begin{bmatrix}
j_{(1)} \\
\vdots \\
j_{(j)} \\
\vdots \\
j_{(nJ)}
\end{bmatrix} ; \;
S_{IA} = \begin{bmatrix}
ia_{(1)} \\
\vdots \\
ia_{(ia)} \\
\vdots \\
ia_{(nI \cdot nA)} \\
\end{bmatrix} ; \;
S_{JK} = \begin{bmatrix}
jk_{(1)} \\
\vdots \\
jk_{(jk)} \\
\vdots \\
jk_{(nJ \cdot nK)} \\
\end{bmatrix}
$$ {#eq-mat21}

Where each element of $S_{I}$ and $S_{J}$ is a binary value indicating the presence or absence of data elements in the $I$ and $J$ vectors (see equation ([-@eq-mat11])). Thus, the vectors $S_{I}$ and $S_{J}$ contains $n_{I}$ and $n_{J}$ elements, respectively. Specifically, we define the vector $S_{I}$ as in equation ([-@eq-mat22]) and apply a similar definition to $S_{J}$.

$$
i_{(i)} = \begin{cases} 
1 & \text{if the data for the } i \text{ element of } I \text{ is observed} \\
0 & \text{if the data for the } i \text{ element of } I \text{ is missing}
\end{cases}
$$ {#eq-mat22}

Similarly, each element of $S_{IA}$ and $S_{JK}$ is a binary value indicating the presence or absence of data rows in the matrices $IA$ and $JK$ (see equation ([-@eq-mat11])). Thus, the vectors $S_{IA}$ and $S_{JK}$ contains $n_{I} \cdot n_{A}$ and $n_{J} \cdot n_{K}$ elements, respectively. Specifically, we define the vector $S_{IA}$ as in equation ([-@eq-mat23]) and apply a similar definition to $S_{JK}$.

$$
ia_{(ia)} = \begin{cases} 
1 & \text{if the data for the } i,a \text{ elements of } IA \text{ are observed} \\
0 & \text{if the data for the } i,a \text{ elements of } IA \text{ are missing}
\end{cases}
$$ {#eq-mat23}

We can visualize these vectors more clearly using the example in equation ([-@eq-mat13]). Suppose researchers exclude the second student and the third judge. Additionally, they do not include the second text from each individual and the third judgment from each judge. Given $n_{I} = 5$, $n_{A} = 2$, $n_{J} = 3$, and $n_{K} = 3$, these vectors take the following structure: 

$$
S_{I} = \begin{bmatrix}
1 \\
0 \\
1 \\
1 \\
1
\end{bmatrix} ; \;
S_{J} = \begin{bmatrix}
1 \\
1 \\
0
\end{bmatrix} ; \;
S_{IA} = \begin{bmatrix}
1 \\
0 \\
0 \\
0 \\
1 \\
0 \\
1 \\
0 \\
1 \\
0 
\end{bmatrix} ; \;
S_{JK} = \begin{bmatrix}
1 \\
1 \\
0 \\
1 \\
1 \\
0 \\
0 \\
0 \\
0 
\end{bmatrix}
$$ {#eq-mat24}

Equation ([-@eq-mat24]) shows that missing values in the $S_{I}$ and $S_{J}$ vectors directly determine those in the $S_{IA}$ and $S_{JK}$. In other words, researchers can only observe texts and judgments from students and judges initially included in the sample. Additionally, it shows that the sum of observed elements in $S_{I}$ equals the sampled students $(n^{s}_{I})$ and that a similar sum in vector $S_{J}$ equals the sampled judges $(n^{s}_{J})$. Conversely, the sum of observed elements in $S_{IA}$ represents the total sampled texts across all sampled students $(n^{s}_{I} \cdot n^{s}_{A})$, while a similar sum in vector $S_{JK}$ represents the total sampled judgments across all sampled judges $(n^{s}_{J} \cdot n^{s}_{K})$.

Finally, we define the *sample design* vector $S$ in equation ([-@eq-mat25]), which maps each element of $S_{IA}$ to every element of $S_{JK}$. The sum of its elements represents the total data sample $n^{s} = \binom{n^{s}_{I} \cdot n^{s}_{A}}{2} \cdot n^{s}_{J} \cdot n^{s}_{K}$. Here, the term ${n^{s}_{I} \cdot n^{s}_{A} \choose 2}$ represents the binomial coefficient, which quantifies the total number of unique comparisons possible between every pair of sampled stimuli generated by each pair of sampled individuals from the population.

$$
S = \begin{bmatrix}
s_{(1)} \\
\vdots \\
s_{(s)} \\
\vdots \\
s_{(n)} \\
\end{bmatrix}
$$ {#eq-mat25}

<!-- 2. What is the effect of the sampling mechanism -->
With the definition of $S$, we incorporate the sample mechanism into the conceptual-population model. Following the convention of @McElreath_2020 [pp. 499-516] and @Deffner_et_al_2022 [pp. 6], the [DAG -@fig-cj12_dag] represents the conceptual-population outcome $O^{cp}_{R}$ as unobserved, emphasizing that researchers cannot directly access this outcome due to the sampling mechanism.

::: {#fig-cj12 layout-nrow=2}

::: {#fig-cj12_scm fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  O^{sc}_{R} & := f_{S}(O^{cp}_{R}, S) \\
  O^{cp}_{R} & := f_{O}(D_{R}) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\
  e_{I} & \dsep \{ e_{J}, e_{IA}, e_{JK} \} \\
  e_{J} & \dsep \{ e_{IA}, e_{JK} \} \\
  e_{IA} & \dsep e_{JK} 
\end{aligned}
$$

SCM
:::


![DAG](/images/png/CJ_TM_12.png){#fig-cj12_dag fig-align="center" fig-pos="H" width=84%}

Sample-comparison model including sampling mechanism
:::

The DAG also depicts the *sample design* vector $S$ as a causal factor influencing the sample-comparison outcome $O^{sc}_{R}$. A square encloses this vector, indicating that it is a conditioned variable. In this context, *conditioning* means restricting the statistical analysis to a specific subset of the population based on the values of a conditioned variable [@Neal_2020, pp. 32], in this case $S$. Essentially, $S$ serves as the sample equivalent for the $R$ matrix (see equation ([-@eq-mat12])), that is, this vector determines *which repeated comparisons the subset of judges makes for the subset of stimuli produced by the subset of individuals* sampled from the conceptual-population. This process ultimately generates the sample-comparison outcome $O^{sc}_{R}$ from the conceptual-population outcome $O^{cp}_{R}$. 

Notably, the DAG shows that $S$ is independent of all other variables in the model. This implies that the conceptual model represented in [DAG -@fig-cj12_dag] applies exclusively to Simple Random Sampling (SRS) designs [@Kohler_et_al_2019, pp. 150]. In these designs, each judgment, judge, stimulus, and individual has the same probability of being included in the sample as any other observation within their respective groups [@Lawson_2015, pp. 16-112].

<!-- Follow conventions of McElreath (2020) NOT Schuessler et al (2023) regarding selection variables and missing data. -->

However, because CJ experiments rarely use the exhaustive pairing of sampled judges, stimuli, and individuals --due to concerns about the practical feasibility of the comparison task, like in @Boonen_et_al_2020 [p. 5]-- a realistic scenario must also account for judges comparing only specific stimuli from certain individuals.


### The comparison mechanism {#sec-theory-theoretical_SC2}

<!-- 1. What is the comparison mechanism -->
<!-- Conversely, we make the scenario depicted in @sec-theory-theoretical_SC1 more realistic by integrating the comparison mechanism, that is, we assume that researchers do not have access to *all comparisons* from the sample, but rather a sufficient number of comparisons $(n_{C})$ so that a proportion, $P(B>A)$, may be determined for each pair of stimuli [@Thurstone_1927b, pp. 267]. @fig-cj14 illustrates this model, incorporating both the sample and comparison mechanisms.  -->

<!-- It is assumed that the single observer compares each pair of stimuli a "sufficient number of times" so that a proportion, P(A>B), may be determined for each pair of stimuli [@Thurstone_1927b, pp. 267] -->

<!-- Actually algorithm can be thought as the observation mechanism that "transforms" the outcome in the population of comparisons to the outcome in the sample of comparisons, see fig. 2, Deffner et al (2022) -->

<!-- Consider algorithm used, as a child of the traits of judges and stimuli. It allows to talk about independence assumption between them and the perception of difference. Consider algorithm is a categorical variable. -->


<!-- 2. What is the effect of the sampling mechanism -->
<!-- Following the convention of @McElreath_2020 [pp. 499-516], the [DAG -@fig-cj14_dag] depicts the sample-comparison outcome $O^{sc}_{R}$ as an unobserved variable, emphasizing the researchers' inability to access such an outcome due to the comparison mechanism. Moreover, the DAG shows the conditioned *comparison design* variable $C$, which causally influence the observed outcome $O_{R}$. This variable reflects how this observed outcome is a sample drawn from the sample-comparison outcome $O^{sp}_{R}$. Specifically, the variable is a vector $C = \{ c_{1}, \dots, c_{n} \}$, where $n$ corresponds to the number of rows in the matrix $R$ (refer to @sec-theory-theoretical_P2), and each $c_{i}$ is a binary variable indicating the presence $(1)$ or absence $(0)$ of data in the corresponding positions of the sample-comparison outcome $O^{sp}_{R}$. Specifically, -->

$$
c_i = \begin{cases} 
1 & \text{if the data for the } i^{th} \text{ element of } O^{sp}_{R} \text{ is observed} \\
0 & \text{if the data for the } i^{th} \text{ element of } O^{sp}_{R} \text{ is missing}
\end{cases}
$$

::: {#fig-cj14 layout-nrow=2}

::: {#fig-cj14_scm fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  O_{R} & := f_{C}(O^{sc}_{R}, C) \\
  O^{sc}_{R} & := f_{S}(O^{cp}_{R}, S) \\
  O^{cp}_{R} & := f_{O}(D_{R}) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, X_{IA}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}, Z_{JK}, e_{JK}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\
  e_{I} & \dsep \{ e_{J}, e_{IA}, e_{JK} \} \\
  e_{J} & \dsep \{ e_{IA}, e_{JK} \} \\
  e_{IA} & \dsep e_{JK} 
\end{aligned}
$$

SCM
:::


![DAG](/images/png/CJ_TM_14.png){#fig-cj14_dag fig-align="center" fig-pos="H" width=100%}

Sample-comparison model including sample and comparison mechanisms
:::


<!-- It is assumed that the single observer compares each pair of stimuli a "sufficient number of times" so that a proportion, P(A>B), may be determined for each pair of stimuli [@Thurstone_1927b, pp. 267] -->



# Abandoning the BTL model {#sec-statistical}

<!-- recording: Sven 24.10.04; time: 00:46:00 - 01:01:00 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:24:50 - 00:30:35 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:49:30 - 00:53:30 -->
<!-- recording: Sven and Tine 25.03.28; time: 00:33:55 - 00:37:50 -->


<!-- To build the statistical part, start with the joint probability of observing the sample data P(Y, Z), then partition this joint probability in smaller conditional probabilities derived from the DAG. -->

<!-- The difficulty and discrimination parameters for the questions should then be given a diffuse, or ideally a hierarchical prior, which will identify these parameters by scaling and locating relative to the student ability parameters. -->
<!-- (https://mc-stan.org/docs/stan-users-guide/regression.html#priors-for-identification.section) -->


when you talk about the variability, refer that the equal dispersion is just assuming 1 for identification.

::: {#fig-cj15 layout-ncol=2}

::: {#fig-cj15_stat fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  O_{R} & = O^{sc}_{R} \odot C \\
  O^{sc}_{R} & = O^{cp}_{R} \odot S \\
  O^{cp}_{R} & \overset{iid}{\sim} \text{Bernoulli} \left[ \text{inv\_logit}( D_{R} ) \right] \\
  D_{R} & = \left( T_{IA}[R_{1},P_{1}] - T_{IA}[R_{2},P_{2}] \right) + B_{JK}[U,V] \\
  T_{IA} & = T_{I} + \beta_{XA} X_{IA} + e_{IA} \\
  T_{I} & = \beta_{XI} X_{I} + e_{I} \\
  B_{JK} & = B_{J} + \beta_{ZK} Z_{JK} + e_{JK} \\
  B_{J} & = \beta_{ZJ} Z_{J} + e_{J} \\
  e_{I} & \overset{iid}{\sim} \text{Normal}(0,s_{XI}) \\
  e_{J} & \overset{iid}{\sim} \text{Normal}(0,s_{ZJ}) \\
  e_{IA} & \overset{iid}{\sim} \text{Normal}(0, p_{IA}) \\  
  e_{JK} & \overset{iid}{\sim} \text{Normal}(0, p_{JK}) \\ \\
  & \textbf{Contraints:} \\
  & \sum_{g=1}^{G_{XI}} s_{XI}/G_{XI} = 1 ; \quad \sum_{g=1}^{G_{ZJ}} s_{ZJ}/G_{ZJ} = 1
\end{aligned}
$$

Statistical model
:::

::: {#fig-cj15_scm fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  O_{R} & := f_{C}(O^{sc}_{R}, C) \\
  O^{sc}_{R} & := f_{S}(O^{cp}_{R}, S) \\
  O^{cp}_{R} & := f_{O}(D_{R}) \\
  D_{R} & := f_{D}(T_{IA}, B_{JK}) \\
  T_{IA} & := f_{T}(T_{I}, X_{A}, e_{IA}) \\
  T_{I} & := f_{T}(X_{I}, e_{I}) \\
  B_{JK} & := f_{B}(B_{J}, Z_{K}, e_{JK}) \\
  B_{J} & := f_{B}(Z_{J}, e_{J}) \\
  e_{I} & := f_{e}(X_{I}) \\
  e_{J} & := f_{e}(Z_{J}) \\
  e_{IA} & \dsep e_{JK}
\end{aligned}
$$

SCM
:::

Sample-comparison model, including sample and comparison mechanisms and assuming different discriminal dispersions for the student's traits
:::


<!-- Second, @sec-theory-statistics uses *Bayesian inference methods* to convert these theoretical and practical elements into a statistical model that supports the analysis of paired comparison data. -->

<!-- These estimates are obtained through *estimation*, which is the process that integrates data with an estimator [@Everitt_et_al_2010]. -->

<!-- 2. What are the benefits of Bayesian inference?-->
<!-- Bayesian inference procedures offer three key advantages. First, they are well-suited to handling complex and overparameterized models, enabling researchers to estimate models where the number of parameters exceeds the number of observations for estimation [@Baker_1998; @Kim_et_al_1999]. Second, they allow researchers to incorporate prior information, which helps constrain parameters within specified bounds. This capability addresses challenges such as non-convergence or improper parameter estimation that often arise in complex models when analyzed with frequentist methods [@Martin_et_al_1975; @Seaman_et_al_2011]. Finally, Bayesian methods are particularly effective at drawing inferences from small sample sizes, where relying on the asymptotic properties of frequentist approaches may not be justified [@Baldwin_et_al_2013; @Lambert_et_al_2006; @Depaoli_2014]. -->


<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are [@Kohler_et_al_2019, pp. 150] -->


<!-- @Pritikin_2020 and @Gray_et_al_2024 bayesian modeling attempts -->

<!-- 6. So, how do we mitigate these risks? -->
<!-- Fortunately, the statistical literature offers a solution to address the abovementioned issues. This solution involves using models that extend traditional approaches to account for the different variability in the stimuli, referred to as over-dispersed models [@McElreath_2020, chap. 12]. -->

<!-- 11. How to solve the violation of the assumption? -->
<!-- Fortunately, the same literature offers solutions for addressing these issues. @Andrich_1978 and @Wainer_et_al_1978 recommend integrating judges' biases into the BTL model. Moreover, the literature advocates for the incorporation of relevant hierarchical structures into the statistical model to account for these dependencies. Together, these additions can result in a model resembling a Multilevel Structural Equation Model (MSEM) [@Hoyle_et_al_2023, chap. 26] combined with a multidimensional or two-parameter logistic Item Response Theory (IRT) model [@Hoyle_et_al_2023, chap. 15], depending on the theoretical and statistical treatment of judges' biases. -->

<!-- Brennen generalizability theory, generalize conclusions over groups. To generalize over judges, you need to estimate them. Akin to Frisch-Wough-Lovel theorem for latent variables?. -->

<!-- 4. So, how do we mitigate these risks? -->
<!-- To mitigate these risks, principles from Structural Equation Modeling (SEM) [@Hoyle_et_al_2023, pp. 138] and IRT [@Fox_2010, chap. 6; @vanderLinden_et_al_2017_I, chap. 24] recommend conducting these analyses and tests within a structural model. A structural model specifies how different manifest or latent variables influence the latent variable of interest [@Everitt_et_al_2010]. This approach allows analyses that can account for both the BTL scores and their uncertainties simultaneously, rather than treating them as separate elements.  -->

<!-- Remember: the "mitigate" paragraph have the purpose of being the design principles that will guide the development of the theoretical and statistical model. -->


<!-- In other words, researchers observe the CJ outcome only when texts' discriminal processes and the judges biases create a *pure interaction effect*, meaning that neither of them has a direct effect on the outcome, but their interaction produces an effect [@Attia_et_al_2022]. -->

<!-- This means that the cancellation of judges' biases may not hold in theory or practice, and that judges' biases may depend on the stimuli, by means of an interaction (but present) or because the judges works as a confounder -->

<!-- Using assumptions from IRT [@deAyala_2009, p. 20-21], we are assuming a multidimensional model, that violates the local independence assumption -->

<!-- [@deAyala_2009, p. 291-29] think about indeterminancies in MIRT. to solve metric indeterminancy you commonly fix a mu=0, and s=1, but for rotational indeterminancy, you need to define (maybe) orthogonality between units traits and judges bias -->


<!-- The correlation $\rho$, considered above is not the kind of correlation considered by Bock (1958) in studies of preference and choice of objects. The Bock correlation arises from a specific interaction between a subject and an item because the subject has a particular "preference", such as a taste preference, for the object. This preference for the object is then reflected in its comparisons with all other objects. However, it is less likely that subjects would have such particular preferences for some items in a test and, in any case, the assumption is open to empirical checking [@Andrich_1978, pp. 455]. -->

<!-- @Bramley_2008 proposes ranking instead of comparisons -->



# Discussion {#sec-discussion}

## Findings {#sec-discussion-finding}

<!-- recording: Sven 24.10.04; time: 00:09:10 - 00:14:30 -->
<!-- recording: Sven and Tine 24.11.25; time: 00:56:10 - 00:56:10 -->


<!-- Thus, this section addresses the issues identified in @sec-theory-issues by extending  Thurstone’s theory using the structural approach to causal inference. Specifically, it leverages the capabilities of this approach to formalize the combination of the core theoretical principles outlined in @sec-thurstone_theory with key assessment design features relevant to CJ experiments, such as the selection of judges, stimuli, and comparisons. In addition to enhancing statistical accuracy and strengthening measurement reliability and validity, the approach offers two key advantages. First, it clarifies the interactions among all actors and processes involved in CJ experiments. Second, it shifts the current comparative data analysis paradigm from passively accepting the model assumptions to actively testing whether those assumptions fit the data under analysis. -->


<!-- "If Thurstone’s Law is to be used in support of comparative judgment for assessment, his theory must be extended to cover the uses and applications that are required for assessment purposes." [@Kelly_et_al_2022, pp. 678] -->




<!-- (Is this a validity contention?) -->
<!-- Furthermore, it is not inconceivable that the selection of a particular group of judges used to perform the pairwise comparison could result in an incomplete depiction of the dimensions and complexity of the trait. Previous research has highlighted that factors such as age, culture, and education [@Kelly_et_al_2022, pp. 683], as well as individual differences among judges [@Gill_et_al_2013; @vanDaal_et_al_2017; @vanDaal_2020], could influence judgment accuracy, thereby affecting the "shared consensus" of the trait measurement. As @Kelly_et_al_2022 noted [pp. 683], “Would the aggregate view of young, British-Asian men always be the same as the aggregate view of older, black women?” -->

<!-- If it is acknowledged that judges may differ in what they value, it is not inconceivable that judges may differ as a function of their gender, age, ethnicity, culture, class, income, education and so on. Would the aggregate view of young, British-Asian men always be the same as the aggregate view of older, black women? [@Kelly_et_al_2022, pp. 683] -->

<!-- Samples from different sites often differ in terms of their demographic profiles (here, their age and gender distribution), and these demographic variables might in turn affect the distribution of the trait of interest. How should researchers deal with these differences? The answer depends on the processes that generated the observed disparities. Demographic disparities among samples may result from (a) differences in the actual populations from which the samples are taken or (b) sampling procedures that differ among sites. [@Deffner_et_al_2022, pp. 6] -->

<!-- Pollitt (2012a) argues that assessors in pairwise comparisons need less training, given intuitive comparison and decision making. However, there is a distinct lack of research on the role of training. [?] -->

<!-- To date, there is no evidence to support a minimum number of judges and judgments required to ensure an acceptable level of validity [@Kelly_et_al_2022, pp. 682]. -->

<!-- These examples demonstrate that the generalizability of experimental effects does not depend on the presence of population differences per se but on the exact mechanisms by which populations differ. While some differences—especially those concerning the independent variable—are inconsequential for intended generalizations, differences concerning effect modifiers or mediators require statistical adjustment. [@Deffner_et_al_2022, pp. 11] -->

<!-- Thus Thurstone’s model (in both its Case 5 and Rasch formulation) achieves the goal of sample-free calibration (Wright, 1977) in the sense that the estimate of the distance between A and B does not depend on which other objects they are compared with. [@Bramley_2008, pp. 256] -->




<!-- "Another challenge to the intrinsic validity argument is that the aggregate approach and valuing of diversity in expert views (Van Daal et al., 2019) is in tension with the idea of removing misfitting judges (Pollitt, 2012a). If someone is considered an expert, and the validity of comparative judgment rests on the collective expertise of a community of practice, the decision to remove them and discard their judgments can only be justifiable on the assumption that those judgments do not reflect their expertise. ... It is thus unclear whether or not this divergence is welcomed." [@Kelly_et_al_2022, pp. 681] -->

<!-- Such differences may not be detected through analyses of bias and misfit. McMahon and Jones (2015) found differences between students and teachers in what was valued in assessments of understanding of a chemistry experiment. Where students prioritized factual recall, teachers prioritized scientific explanation. Both groups produced highly reliable scales (reliability estimates of .893 for students, and .874 for teachers). Although, in this case, a clear argument as to whose consensus should take priority can be made, it demonstrates the existence of different, but equally reliable, sets of consensuses depending on who is asked. [@Kelly_et_al_2022, pp. 683] -->

<!-- We advocate for the no removal of judges, but rather identify them and treat the data with the appropriate model, so these 'misfits' do not affect the measurement of the trait -->

<!-- sampling and comparisons mechanism are effective generators of missing data. -->






<!-- Due to efficiency of scoring, most of research only collects only one text. This assumes that there is significant homogeneity between text of the same individual, compared to the between individual variability. However, this cannot be known ad-hoc.  -->

<!-- Use your example, teaching practice and Aptitude-Treatment Interaction (ATI), certain interventions do not have the same effect for all pupils, treatment is a random intercept and slope variable. Relevant variables depends on the context, you really have to think through which variables you have to put in. -->




<!-- The field of comparative judgment, while growing, is still relatively small, and at present we do not have compelling answers to fundamental questions such as: how many judges do we need? Who should judge? How many judgments should they make? And crucially, how can we be confident that they are basing their judgments on acceptable criteria? If judges are not using construct-relevant criteria, then the argument that comparative judgments are necessarily valid cannot be upheld. We recognise that there is unlikely to be a single answer to these questions for all the cases in which comparative judgment may be used. However, work to derive some general principles for good practice would be valuable. [@Kelly_et_al_2022, pp. 683] -->

<!-- It is assumed that the single observer compares each pair of stimuli a "sufficient number of times" so that a proportion, P(A>B), may be determined for each pair of stimuli [@Thurstone_1927b, pp. 267] -->




<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are. [@Kohler_et_al_2019, pp. 150] -->

<!-- An explicit causal-inference framework makes it (at times painfully) transparent how strong the assumptions are that we need to arrive at substantive conclusions and how little we collectively know about many real-world phenomena. But this is no reason to embrace the status quo that often avoids causal language (Grosz et al., 2020)—assumptions do not disappear just because we ignore them. [@Deffner_et_al_2022, pp. 14] -->

<!-- A structural causal framework encourages researchers to explicitly spell out their assumptions, removing verbal ambiguity and facilitating communication, and it calls for a cumulative approach to science as one study’s findings become the scaffolding assumptions of the next. [@Deffner_et_al_2022, pp. 14] -->

<!-- This approach makes strong causal assumptions about the nature of confounding and our ability to measure shared history. However, strong assumptions are always necessary in observational settings. What is important is that the assumptions are transparent and logically connected to data analysis. [@Deffner_et_al_2022, pp. 13] -->




<!-- DAGs are not about adding assumptions—they are about revealing the -->
<!-- assumptions that are otherwise made implicitly [@Sterner_et_al_2024, pp. 755; @Deffner_et_al_2022; @Pearl_et_al_2014] -->

<!-- It has been argued that causal DAGs can be considered graphical representations of nonparametric SEMs [@Pearl_2012; @Kunicki_et_al_2023, pp. 4; @Sterner_et_al_2024, pp. 749]. -->

<!-- DAG can be thought of as a “qualitative schematic” for a particular class of structural equation modeling (i.e., linear structural equation modeling), or a nonparametric SEM. Conversely, structural equation modeling may be thought of as an algebraic system for a causal DAG [@VanderWeele_et_al_2021; Kunicki_et_al_2023, pp. 12]. -->

<!-- we not only underline the value of causal graphs as an intuitive and powerful tool for survey researchers to communicate their assumptions, be it for inferences on descriptive or causal parameters, but also highlight their value in uncovering nontrivial insights for improving more complicated statistical practices. [@Schuessler_et_al_2023, pp. 3] -->

<!-- If we are willing to assume that the depicted DAG is a causal DAG—which means that it includes all common causes of any pair of variables (Elwert, 2013)—we can algorithmically derive which variables need to be “conditioned” (see Box 1) on to identify the causal effect of interest. [@Deffner_et_al_2022, pp. 4] -->

<!-- Our DAG is, of course, incomplete and possibly wrong, in particular when it comes to the nodes that have not been experimentally manipulated. But an incomplete model is still an improvement over no model at all. [@Deffner_et_al_2022, pp. 5] -->

<!-- remember to mention fidelity of the theory in the model -->

<!-- A causal framework is not only useful for analysis but also aids research design [@Deffner_et_al_2022, pp. 11] -->

<!-- A generalizable understanding of a given phenomenon, therefore, cannot be based only on the accumulation of data but requires the theory-driven testing of causal assumptions. [@Deffner_et_al_2022, pp. 13] -->

<!-- Causal inference frameworks do not magically guarantee value-free answers, but they force us to be precise about the questions we ask, and to be transparent about the assumptions that we are willing to make [@Rohrer_et_al_2022, pp. 4-5] -->




## Limitations and further research {#sec-discussion-limitations}

<!-- *Relevant* refers to variables that satisfy the *backdoor criterion* [@Neal_2020, pp 37], that is, they belong to a *sufficient adjustment set* [@Pearl_2009; @Pearl_et_al_2016; @Morgan_et_al_2014]. A *sufficient* set (potentially empty) blocks all non-causal paths between a predictor and an outcome without opening new ones [@Pearl_2009]. Use your example, teaching practice and Aptitude-Treatment Interaction (ATI), certain interventions do not have the same effect for all pupils, treatment is a random intercept and slope variable. Relevant variables depends on the context, you really have to think through which variables you have to put in. -->

<!-- Incorporating these variables into the conceptual-population model enables researchers to identify different estimands of interest and their causal effects, even with observational data. This identification works because conditioning on these variables ensures that the estimator meets several critical properties, including confounding elimination [@Morgan_et_al_2014]. -->

<!-- Naturally, the validity of causal claims now hinges on the assumption that these variables serve as a sufficient adjustment set, a property that cannot be guaranteed for any variable. Nevertheless, as @Kohler_et_al_2019 [pp. 150] noted, drawing conclusions about the real world from observed data inevitably requires assumptions, and these requirements hold true for both observational and experimental data. -->

<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are. [@Kohler_et_al_2019, pp. 150] -->

<!-- The condition of case selection to be independent from Y is always met in experiments because the Y is not realized before the experiment starts. [@Kohler_et_al_2019, pp. 160] -->

<!-- (do not do this yet!) Develop how you multiply the predictions by the inverse of the sample probability to get the estimates. Should I use the probability itself?: Remember that in a random sample the sample probability is n/N, so the the inverse of the sample probability is N/n. So, multiplying the estimate by the n * N/n gives you the prediction for the population?, yes. -->
<!-- (See https://timss2023.org/methods/, and pdf in mail, and https://discourse.mc-stan.org/t/survey-weighted-regression/1654 ) -->

<!-- (do not do this yet!) Then to get the differences between groups you need to aggregate the latent variable of interest using the variable of interest without considering any other variable (marginalization) (see https://www.r-bloggers.com/2017/06/sampling-weights-and-multilevel-modeling-in-r/ ) -->

<!-- Add to future research how would be to use the model when you do not know the weights of the sample, but you can use external data to approximate them. -->


<!-- Talk about Bayesian Workflow, and how it would fit the process to arrive to the proposed model. -->


<!-- (Done) It is more likely that we can decide the characteristics of the objects we want to include in the study (independent variables), ensuring groups that are more balanced. However, in the case of subjects sometimes the independent variables cannot be assigned (e.g., hearing status) -->

<!-- When you want to investigate objects, the experiment has an experimental unit: the trial on the objects, but you only have one object per subject. Consequently, objects and subjects are confounded. -->

<!-- Brought Rubin's missing data framework to the field. -->


# Conclusion {#sec-conclusion}



{{< pagebreak >}}

# Declarations {.unnumbered .appendix appendix-style=plain}

**Funding:** The Research Fund (BOF) of the University of Antwerp funded this project.

**Financial interests:** The authors declare no relevant financial interests.

**Non-financial interests:** The authors declare no relevant non-financial interests.

**Ethics approval:** The University of Antwerp Research Ethics Committee confirmed that this study does not require ethical approval.

**Consent to participate:** Not applicable

**Consent for publication:** All authors have read and approved the final version of the manuscript for publication.

**Data availability:** This study did not use any data.

**Materials and code availability:** The `CODE LINK` section at the top of the digital document located at: [https://jriveraespejo.github.io/paper2_manuscript/](https://jriveraespejo.github.io/paper2_manuscript/) provides access to all materials and code.  

**AI-assisted technologies in the writing process:** The authors used various AI-based language tools to refine phrasing, optimize wording, and enhance clarity and coherence throughout the manuscript. They take full responsibility for the final content of the publication.

**CRediT authorship contribution statement:** *Conceptualization:* S.G., S.DM., T.vD., and J.M.R.E; *Methodology:* S.DM., T.vD., and J.M.R.E; *Software:* J.M.R.E.; *Validation:* J.M.R.E.; *Formal Analysis:* J.M.R.E.; *Investigation:* J.M.R.E; *Resources:* S.G., S.DM., and T.vD.; *Data curation:* J.M.R.E.; *Writing - original draft:* J.M.R.E.; *Writing - review and editing:* S.G., S.DM., and T.vD.; *Visualization:* J.M.R.E.; *Supervision:* S.G. and S.DM.; *Project administration:* S.G. and S.DM.; *Funding acquisition:* S.G. and S.DM.

<!-- **Acknowledgements:** -->



{{< pagebreak >}}

# Appendix {#sec-appendix .appendix appendix-style=plain}

## Statistical and Causal inference {#sec-appendixB .appendix appendix-style=plain}

<!-- recording: Sven and Tine 25.01.22; time: 00:00:00 - 00:05:40 -->

This section introduces fundamental statistical and causal inference concepts necessary for understanding the core theoretical principles described in this document. It does not, however, offer a comprehensive overview of causal inference methods. Readers seeking more in-depth understanding may wish to explore introductory papers such as @Pearl_2010, @Rohrer_2018, @Pearl_2019, and @Cinelli_et_al_2020. They may also find it helpful to consult introductory books like @Pearl_et_al_2018, @Neal_2020, and @McElreath_2020. For more advanced study, readers may refer to seminal intermediate papers such as @Neyman_et_al_1923, @Rubin_1974, @Spirtes_et_al_1991, and @Sekhon_2009, as well as books such as @Pearl_2009, @Morgan_et_al_2014, and @Hernan_et_al_2020.


### Empirical research and randomized experiments {#sec-appendixB1 .appendix appendix-style=plain}

<!-- 1. What does empirical research do first? -->
Empirical research uses evidence from observation and experimentation to address real-world challenges. In this context, researchers typically formulate their research questions as *estimands* or *targets of inference*, i.e., the specific quantities they seek to determine [@Everitt_et_al_2010]. For instance, researchers might be interested in answering the following question: "To what extent do different teaching methods $(T)$ influence students' ability to produce high-quality written texts $(Y)$?" To investigate this, researchers could randomly assign students to two groups, each exposed to a different teaching method $(T_{i} = \{1,2\})$. Then, they would perform pairwise comparisons, generating a dichotomous outcome $(Y_{i} = \{0,1\})$ showing which student exhibits more of the ability. In this scenario, the research question can be rephrased as the estimand, "*On average*, is there a difference in the ability to produce high-quality written texts between the two groups of students?" and this estimand can be mathematically represented by the random associational quantity in @eq-group_diff, where $E[\cdot]$ denotes the expected value.

$$
E[Y_{i} \cond T_{i}=1] - E[Y_{i} \cond T_{i}=2]
$$ {#eq-group_diff}

<!-- 2. What do they do next? -->
Researchers then proceed to identify the estimands. *Identification* determines whether an estimator can accurately compute the estimand based solely on its assumptions, regardless of random variability [@Schuessler_et_al_2023, pp. 4]. An *estimator* refers to a method or function that transforms data into an estimate [@Neal_2020]. *Estimates* are numerical values that approximate the estimand derived through the process of *estimation*, which integrates data with an estimator [@Everitt_et_al_2010]. The Identification-Estimation flowchart [@McElreath_2020; @Neal_2020], shown in @fig-IEflow, visually represents the transition from estimands to estimates.

<!-- The causal assumptions encoded in a DAG constitute the theoretical model on which identification analysis rests. Identification analysis is concerned with determining whether or not the true value of a parameter can be estimated using the assumptions in the model (graph), regardless of random variability in the data due to small samples [@Schuessler_et_al_2023, pp. 4]. -->


![ Identification-Estimation flowchart. Extracted and slightly modified from @Neal_2020 [pp. 32] ](images/png/IEflow.png){#fig-IEflow fig-align="center" width=35%}


<!-- 3. the importance of identification -->
Identification is a necessary condition to ensure *consistent* estimators. An estimator achieves *consistency* when it converges to the "true" value of an estimand as the data size approaches infinity [@Everitt_et_al_2010]. Without identification, researchers cannot achieve consistency, even with "infinite" and error-free data. As a result, deriving meaningful insights about an estimand from finite data becomes impossible [@Schuessler_et_al_2023, pp. 5]. Therefore, to ensure accurate and reliable estimates, researchers prioritize estimators with desirable identification properties. For instance, the Z-test is a widely used estimator for comparing group proportions, yielding accurate estimates when its underlying assumptions are satisfied [@Kanji_2006]. Furthermore, researchers can interpret estimates from the Z-test as causal, provided the data is collected through a randomized experiment.

<!-- The main reason to focus on identification is that if these parameters cannot be identified using "infinite" and error free data, we certainly cannot learn anything about it using finite data. So, for the time being, we assume large samples and error-free measurements [@Schuessler_et_al_2023, pp. 5]. -->

<!-- If both assumptions are met, the Z-test is expressed as a signal-to-noise statistic $Z = (\hat{p}_{1} - \hat{p}_{2})/ \hat{s}_{p}$. The signal is defined as the difference between the groups' sample proportions, $\hat{p}_{1} = \sum_{i=1}^{n_{1}}{Y_{i}/n_{1}}$ and $\hat{p}_{2} = \sum_{i=1}^{n_{2}}{Y_{i}/n_{2}}$, analogous to $E[Y_{i} \cond T_{i}=1]$ and $E[Y_{i} \cond T_{i}=2]$, respectively. The noise, represented by $\hat{s}_{p}$, is defined as the unpooled sample variability observed between the two groups.  -->

<!-- the BTL model [@Bradley_et_al_1952; @Luce_1959] is an estimator known for its effectiveness in modeling pairwise comparisons, yielding accurate estimates for the comparison of two groups, as long as the assumptions of the model are met. Usually these estimates are expressed in terms of the proportions of groups  -->

<!-- However, researchers often seek to uncover the mechanisms underlying specific data and establish causal relationships rather than simply estimate associations. -->

<!-- 4. Why does causality stem from randomize experiments? -->
Randomized experiments are widely recognized as the gold standard in evidence-based science [@Hariton_et_al_2018; @Hansson_2014]. This recognition stems from their ability to enable researchers interpret associational estimates as causal. They achieve this by ensuring data, and by extension an estimator, satisfies several key identification properties, such as common support, no interference, and consistency [@Morgan_et_al_2014; @Neal_2020]. The most critical property, however, is the elimination of confounding. *Confounding* occurs when an external variable $X$ simultaneously influences the outcome $Y$ and the variable of interest $T$, resulting in spurious associations [@Everitt_et_al_2010]. Randomization addresses this issue by decoupling the association between the intervention allocation $T$ from any other variable $X$ [@Morgan_et_al_2014; @Neal_2020].

<!-- 5. Experiments are not available to everyone, then causal inference comes to the rescue -->
Nevertheless, researchers often face constraints that limit their ability to conduct randomized experiments. These constraints include ethical concerns, such as the assignment of individuals to potentially harmful interventions, and practical limitations, such as the infeasibility of, for example, assigning individuals to genetic modifications or physical impairments [@Neal_2020]. In these cases, causal inference offers a valuable alternative for generating causal estimates and understanding the mechanisms underlying specific data. In addition, the framework can provide significant theoretical insights that can enhance the design of experimental and observational studies [@McElreath_2020]. 


### Identification under causal inference {#sec-appendixB2 .appendix appendix-style=plain}

<!-- 1. What is causal inference? -->
Unlike classical statistical modeling, which focuses primarily on summarizing data and inferring associations, the *causal inference* framework is designed to identify causes and estimate their effects using data [@Shaughnessy_et_al_2010; @Neal_2020]. The framework uses rigorous mathematical techniques to address the *fundamental problem of causality* [@Pearl_2009; @Pearl_et_al_2016; @Morgan_et_al_2014]. This problem revolves around the question, "What would have happened 'in the world' under different circumstances?" This question introduces the concept of counterfactuals, which are instrumental in defining and identifying causal effects.

<!-- 2. What are counterfactuals? -->
*Counterfactuals* are hypothetical scenarios that are *contrary to fact*, where alternative outcomes resulting from a given cause are neither observed nor observable [@Neal_2020; @Counterfactual_2024]. The structural approach to causal inference [@Pearl_2009; @Pearl_et_al_2016] provides a formal framework for defining counterfactuals. For instance, in the scenario described in @sec-appendixB1, the approach begins by defining the *individual causal effect* (ICE) as the difference between each student's potential outcomes, as in @eq-ICE. 

$$
\tau_{i} = Y_{i} \cond do(T_{i}=1) - Y_{i} \cond do(T_{i}=2)
$$ {#eq-ICE} 

where $do(T_{i}=t)$ represents the intervention operator, $Y_{i} \cond do(T_{i}=1)$ represents the potential outcome under intervention $T_{i}=1$, and $Y_{i} \cond do(T_{i}=1)$ represents the potential outcome under intervention $T_{i}=2$. Here, an *intervention* involves assigning a constant value to the treatment variable for each student's potential outcomes. Note that if a student is assigned to intervention $T_{i}=1$, the potential outcome under $T_{i}=2$ becomes a counterfactual, as it is no longer observed nor observable. To address this challenge, the structural approach extends the ICE to the *average causal effect* (ACE, @eq-ACE), representing the average difference between the students' observed potential outcomes and their counterfactual counterparts.

$$
\begin{aligned}
\tau & = E[\tau_{i}] \\
  & = E[Y_{i} \cond do(T_{i}=1)]- E[Y_{i} \cond do(T_{i}=2)]
\end{aligned}
$$ {#eq-ACE}

<!-- [^1]: The potential outcomes approach [@Neyman_et_al_1923; @Rubin_1974] defines the ICE as $\tau_{i} = Y^{1}_{i} - Y^{2}_{i}$, while it defines the ACE as $\tau = E[\tau_{i}] = E[Y^{1}_{i}]- E[Y^{2}_{i}]$. -->

<!-- 3. But how does it work? -->
Even though counterfactuals are unobservable, researchers can still identify the ACE from associational estimates by leveraging the structural approach. The approach identifies the ACE by statistically conditioning data on a *sufficient adjustment set* of variables $X$ [@Pearl_2009; @Pearl_et_al_2016; @Morgan_et_al_2014]. This *sufficient* set (potentially empty) must block all non-causal paths between $T$ to $Y$ without opening new ones. When such a set exists, then $T$ and $Y$ are *d-separated* by $X$ ($T \dsep Y \cond X$) [@Pearl_2009], and $X$ satisfies the *backdoor criterion* [@Neal_2020, pp 37]. Here, *conditioning* describes the process of restricting the focus to the subset of the population defined by the conditioning variable [@Neal_2020, pp. 32] (see @eq-CACE). 

<!-- Conditioning on T=t just means that we are restricting our focus to the subset of the population to those who received treatment t. In contrast, an intervention would be to take the whole population and give everyone treatment t [@Neal_2020, pp. 32]. -->

Conditioning on a sufficient adjustment set enables researchers to estimate the ACE, even when the data comes from an observational study. This process is feasible because such conditioning ensures that the ACE estimator satisfies several critical properties, including confounding elimination [@Morgan_et_al_2014]. Naturally, the validity of claims about the causal effects of $T$ on $Y$ now hinges on the assumption that $X$ serves as a sufficient adjustment set. However, as @Kohler_et_al_2019 [pp. 150] noted, drawing conclusions about the real world from observed data inevitably requires assumptions. This requirement holds true for both observational and experimental data.

<!-- Statements about the real world from observed data require assumptions. This is true no matter what kind of data we have, and it is explicitly also true for statements based on data stemming from SRSg. The validity of our statements therefore critically hinges on the validity of those assumptions. If our statistical assumptions are wrong for the analysis at hand, the inferential statements will be incorrect no matter how sophisticated the statistical methods are. [@Kohler_et_al_2019, pp. 150] -->

For instance, if researchers cannot conduct the randomized experiments described in @sec-appendixB1 and must instead rely on observational data, they can still identify the ACE as long as an observed variable $X$, such as the socio-economic status of the school, satisfies the backdoor criterion. Under these circumstances, researchers first identify the *conditional average causal effect* (CACE, @eq-CACE)

$$
CACE_{t} = E[Y_{i} \cond T_{i}=t, X]
$$ {#eq-CACE}

From the CACE, researchers can identify the ACE from associational quantities as in @eq-mACE1. This identification process is commonly known as the *backdoor adjustment*. Here, $E_{X}[\cdot]$ represents the marginal expected value over $X$ [@Morgan_et_al_2014]. 

$$
\begin{aligned}
  \tau & = E[Y_{i} \cond do(T_{i}=1)]- E[Y_{i} \cond do(T_{i}=2)] \\
  & = E_{X}[CACE_{1} - CACE_{2}] \\
  & = E_{X}\left[ E[Y_{i} \cond T_{i}=1, X] - E[Y_{i} \cond T_{i}=2, X] \right]
\end{aligned}
$$ {#eq-mACE1}

Notably, the approach extends the ACE identification for a continuous variable $T$ as in @eq-mACE_cont, ensuring broad applicability across different causal scenarios [@Neal_2020, pp. 45]

$$
\begin{aligned}
  \tau &= E[Y_{i} \cond do(T_{i}=t)] \\
  & = d E_{X}\left[ E[Y_{i} \cond T_{i}=t, X]\right]/ dt
  \end{aligned}
$$ {#eq-mACE_cont}


### Diving into the specifics {#sec-appendixB3 .appendix appendix-style=plain}

<!-- 1. The benefits of SCMs and DAGs -->
The structural approach to causal inference uses SCMs and DAGs to formally and graphically represent the presumed causal structure underlying the ACE [@Pearl_2009; @Pearl_et_al_2016; @Gross_et_al_2018; @Neal_2020]. Essentially, these tools serve as *conceptual (theoretical) models* on which identification analysis rests [@Schuessler_et_al_2023, pp. 4]. Thus, using these tools, researchers can determine which statistical models can identify (ACE, CACE, or other), assuming the depicted causal structure is correct [@McElreath_2020], thus enabling valid causal inference. @fig-IEflow shows the role of theoretical models in the inference process.

<!-- The causal assumptions encoded in a DAG constitute the theoretical model on which identification analysis rests. Identification analysis is concerned with determining whether or not the true value of a parameter can be estimated using the assumptions in the model (graph), regardless of random variability in the data due to small samples [@Schuessler_et_al_2023, pp. 4]. -->

SCMs and DAGs support identification analysis through two key advantages. First, regardless of complexity, they can represent various causal structures using only five fundamental building blocks [@Neal_2020; @McElreath_2020]. This feature allows researchers to decompose complex structures into manageable components, facilitating their analysis [@McElreath_2020]. Second, they depict causal relationships in a non-parametric and fully interactive way. This flexibility enables feasible ACE identification strategies without defining the variables' data types, the functional form between them, or their parameters [@Pearl_et_al_2016, pp. 35]. 

Thus, @sec-appendixB31 and @sec-appendixB32 elaborate on the first advantage, while @sec-appendixB32 and @sec-appendixB33 do so for the second. Finally, @sec-appendixB34 explains how researchers use SCMs and DAGs alongside Bayesian inference methods in the estimation process. 

<!-- A heuristic is a strategy that simplifies information to make decisions more quickly, efficiently, and sometimes more accurately than complex methods [@Chow_2015]. -->


#### The five fundamental block for SCMs and DAGs {#sec-appendixB31 .appendix appendix-style=plain}

<!-- 2. the SCMs -->
Figures [-@fig-dags_scms1], [-@fig-dags_scms2], [-@fig-dags_scms3], [-@fig-dags_scms4], and [-@fig-dags_scms5] display the five fundamental building blocks for SCMs and DAGs. The left panels of the figures show the formal mathematical models, represented by the SCMs, defined in terms of a set of *endogenous* variables $V=\{X_{1},X_{2},X_{3}\}$, a set of *exogenous* variables $E=\{e_{X1},e_{X2},e_{X3}\}$, and a set of functions $F=\{f_{X1},f_{X2},f_{X3}\}$ [@Pearl_2009; @Cinelli_et_al_2020]. Endogenous variables are those whose causal mechanisms a researcher chooses to model [@Neal_2020]. In contrast, exogenous variables represent *errors* or *disturbances* arising from omitted factors that the investigator chooses not to model explicitly [@Pearl_2009, pp. 27,68]. Lastly, the functions, referred to as *structural equations*, express the endogenous variables as non-parametric functions of other variables. These functions use the symbol '$:=$' to denote the asymmetrical causal dependence of the variables and the symbol '$\dsep$' to represent *d-separation*, a concept akin to (conditional) independence.

<!-- 3. The DAGs -->
Notably, every SCM has an associated DAG [@Pearl_et_al_2016; @Cinelli_et_al_2020]. The right panels of the figures display these DAGs. A DAG is a graph consisting of nodes connected by edges, where the nodes represent random variables. The term *directed* means that the edges extend from one node to another, with arrows indicating the direction of causal influence. The term *acyclic* implies that the causal influences do not form loops, ensuring the influences do not cycle back on themselves [@McElreath_2020]. DAGs represent observed variables as solid black circles, while they use open circles for unobserved (latent) variables [@Morgan_et_al_2014]. Although the *standard representation* of DAGs typically omits exogenous variables for simplicity, the *magnified representation* depicted in the figures offers one key advantage: including exogenous variables can help researchers highlight potential issues related to conditioning and confounding [@Cinelli_et_al_2020]. 

::: {#fig-dags_scms1 layout-ncol=2}

::: {#fig-scm_bb1 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{3} & := f_{X3}(e_{X3}) \\
  e_{X1} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::


![DAG](images/png/mdag_bb1.png){#fig-mdag_bb1 fig-align="center" fig-pos="H" width=54%}

Two unconnected nodes
:::


::: {#fig-dags_scms2 layout-ncol=2}

::: {#fig-scm_bb2 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{3} & := f_{X3}(X_{1},e_{X3}) \\
  e_{X1} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb2.png){#fig-mdag_bb2 fig-align="center" fig-pos="H" width=54%}

Two connected nodes or descendant
:::


::: {#fig-dags_scms3 layout-ncol=2}

::: {#fig-scm_bb3 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{2} & := f_{X2}(X_{1},e_{X2}) \\
  X_{3} & := f_{X3}(X_{2},e_{X3}) \\
  e_{X1} & \dsep e_{X2} \\
  e_{X1} & \dsep e_{X3} \\
  e_{X2} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb3.png){#fig-mdag_bb3 fig-align="center" fig-pos="H" width=65%}

Chain or mediator
:::


::: {#fig-dags_scms4 layout-ncol=2}

::: {#fig-scm_bb4 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(X_{2},e_{X1}) \\
  X_{2} & := f_{X2}(e_{X2}) \\
  X_{3} & := f_{X3}(X_{2},e_{X3}) \\
  e_{X1} & \dsep e_{X2} \\
  e_{X1} & \dsep e_{X3} \\
  e_{X2} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb4.png){#fig-mdag_bb4 fig-align="center" fig-pos="H" width=65%}

Fork or confounder
:::


::: {#fig-dags_scms5 layout-ncol=2}

::: {#fig-scm_bb5 fig-align="center" fig-pos="H"}
$$
\begin{aligned}
  X_{1} & := f_{X1}(e_{X1}) \\
  X_{2} & := f_{X2}(X_{1},X_{3},e_{X2}) \\
  X_{3} & := f_{X3}(e_{X3}) \\
  e_{X1} & \dsep e_{X2} \\
  e_{X1} & \dsep e_{X3} \\
  e_{X2} & \dsep e_{X3}
\end{aligned}
$$

SCM
:::

![DAG](images/png/mdag_bb5.png){#fig-mdag_bb5 fig-align="center" fig-pos="H" width=65%}

Collider or inmorality
:::


<!-- 4. Theoretical implications of the basic building block of the SCMS and DAGs -->
A careful examination of these building blocks highlights the theoretical assumptions underlying their observed variables. SCM [-@fig-scm_bb1] and DAG [-@fig-mdag_bb1] depict two unconnected nodes, representing a scenario where variables $X_{1}$ and $X_{3}$ are independent or not causally related. SCM [-@fig-scm_bb2] and DAG [-@fig-mdag_bb2] illustrate two connected nodes, representing a scenario where a *parent* node $X_{1}$ exerts a causal influence on a *child* node $X_{3}$. In this setup, $X_{3}$ is considered a *descendant* of $X_{1}$. Additionally, $X_{1}$ and $X_{3}$ are described as *adjacent* because there is a *direct path* connecting them. SCM [-@fig-scm_bb3] and DAG [-@fig-mdag_bb3] depict a *chain*, where $X_{1}$ influences $X_{2}$, and $X_{2}$ influences $X_{3}$. In this configuration, $X_{1}$ is a parent node of $X_{2}$, which is a parent node of $X_{3}$. This structure creates a *directed path* between $X_{1}$ and $X_{3}$. Consequently, $X_{1}$ is an *ancestor* of $X_{3}$, and $X_{2}$ fully *mediates* the relationship between the two. SCM [-@fig-scm_bb4] and DAG [-@fig-mdag_bb4] illustrate a *fork*, where variables $X_{1}$ and $X_{3}$ are both influenced by $X_{2}$. Here, $X_{2}$ is a parent node that *confounds* the relationship between $X_{1}$ and $X_{3}$. Finally, SCM [-@fig-scm_bb5] and DAG [-@fig-mdag_bb5] show a *collider*, where variables $X_{1}$ and $X_{3}$ are concurrent causes of $X_{2}$. In this configuration, $X_{1}$ and $X_{3}$ are not causally related to each other but both influence $X_{2}$ (an *inmorality*). Notably, all building blocks assume the errors are independent of each other and from all other variables in the graph, as evidenced by the pairwise relations $e_{X1} \dsep e_{X2}$, $e_{X1} \dsep e_{X3}$, and $e_{X2} \dsep e_{X3}$.

<!-- 5. Continuing with the motivating example -->
Researchers can then use these building blocks to represent the scenario outlined in @sec-appendixB2. SCM [-@fig-scm_example1] and DAG [-@fig-mdag_example1] depict the plausible causal structure for this example. In this context, the variable $X$ (socio-economic status of the school) is thought to be a confounder in the relationship between the teaching method $T$ and the outcome $Y$. The figures display multiple descendant relationships such as $X \rightarrow T$, $X \rightarrow Y$, and $T \rightarrow Y$. They also highlight unconnected node pairs, evident from the relationships $e_{T} \dsep e_{X}$, $e_{T} \dsep e_{Y}$, and $e_{X} \dsep e_{Y}$. Additional, the figures show one fork, $X \rightarrow \{T, Y\}$, and two colliders: $\{X, e_{T}\} \rightarrow T$ and $\{X, T, e_{Y}\} \rightarrow Y$.

::: {#fig-example1 layout-ncol=2}

::: {#fig-scm_example1 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  T & := f_{T}(X,e_{T}) \\
  Y & := f_{Y}(T,X,e_{Y}) \\
  e_{T} & \dsep e_{X} \\
  e_{T} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Y}
\end{aligned}
$$

SCM
:::


![DAG](images/png/mdag_example1.png){#fig-mdag_example1 fig-align="center" width=65%}

Plausible causal structure the scenario outlined in @sec-appendixB2.
:::


#### The probabilistic implications of these blocks {#sec-appendixB32 .appendix appendix-style=plain}

<!-- 1. How the SCMS and DAGs encode probabilistic information? -->
Beyond their graphical capabilities, SCMs and DAGs can encode the probabilistic information embedded within a causal structure. They achieve this encoding by relying on three fundamental assumptions: the local Markov, the minimality, the causal edges assumption. The *local Markov assumption* encodes probabilistic independencies between variables by declaring that nodes in a graph are independent of all its non-descendants, given its parents [@Neal_2020, pp. 20]. Meanwhile, the *minimality assumption* encodes probabilistic dependencies among variables by stating that every pair of adjacent nodes exhibits a dependency [@Neal_2020, pp. 21]. Finally, the *causal edges assumption* encodes causal relationships between variables by declaring that each parent node acts as a direct cause of its children [@Neal_2020, pp. 22]. @fig-ACflow illustrates how these assumptions influence the statistical and causal interpretations of graphs. 

![ The flow of association and causation in graphs. Extracted and slightly modified from @Neal_2020 [pp. 31] ](images/png/ACflow.png){#fig-ACflow fig-align="center" width=80%}


<!-- 2. What are the general implications of this? -->
A notable implication of the assumptions underlying the probabilistic encoding is that any conceptual model described by an SCM and DAG can represent the joint distribution of variables more efficiently [@Pearl_et_al_2016, pp. 29]. This expression takes the form of a product of conditional probability distributions (CPDs) of the type $P(child \cond parents)$. This property is formally known as the *Bayesian Network factorization* (BNF, @eq-net_factor) [@Pearl_et_al_2016, pp. 29; @Neal_2020, pp. 21]. In this expression, $pa(X_{i})$ denotes the set of variables that are the parents of $X_{i}$.

$$
\begin{aligned}
P(X_{1}, X_{2}, \dots, X_{P}) & = X_{1} \cdot \prod^{P}_{p=2} P(X_{i} \cond X_{i-1}, \dots, X_{1}) & (\small{\text{by chain rule})}\\
& = X_{1} \cdot \prod^{P}_{p=2} P(X_{i} \cond pa(X_{i}) ) & (\small{\text{by BNF}})
\end{aligned}
$$ {#eq-net_factor}

<!-- 3. What is the net result of this? -->
This encoding enables researchers with conceptual (theoretical) knowledge in the form of an SCM and DAG to predict patterns of (in)dependencies in the data. As highlighted by @Pearl_et_al_2016 [pp. 35], these predictions depend solely on the structure of these conceptual models without requiring the quantitative details of the equations or the distributions of the errors. Moreover, once researchers observe empirical data, the patterns of (in)dependencies in the data can provide significant insights into the validity of the proposed conceptual model. 

<!-- The net result is that a researcher who has scientific knowledge in the form of a structural equation model is able to predict patterns of independencies in the data, based solely on the structure of the model’s graph, without relying on any quantitative information carried by the equations or by the distributions of the errors [@Pearl_et_al_2016, pp. 35]. -->

<!-- 4. can you illustrate this concept? -->
The five fundamental building blocks described in @sec-appendixB31 clearly illustrate which (in)dependencies can SMCs and DAGs predict. For instance, applying the BNF to the causal structure shown in the SCM [-@fig-scm_bb1] and DAG [-@fig-mdag_bb1] enables researchers to express the joint probability distribution of the observed variables as $P(X_{1}, X_{3}) = P(X_{1}) P(X_{3})$, supporting the theoretical assumption that the observed variables $X_{1}$ and $X_{3}$ are unconditionally independent ($X_{1} \dsep X_{3}$) [@Neal_2020, pp. 24]. Conversely, when $X_{3}$ is unconditionally dependent on $X_{1}$ ($X_{1} \ndsep X_{3}$), as depicted in the SCM [-@fig-scm_bb2] and DAG [-@fig-mdag_bb2], the BNF express their joint probability distribution as $P(X_{1}, X_{3}) = P(X_{3} \cond X_{1}) P(X_{1})$. Notably, these descriptions demonstrate the clear correspondence between the structural equations illustrated in @sec-appendixB31 and the CPDs.

Beyond the insights gained from two-node structures, researchers can uncover more nuanced patterns of(in)dependencies from chains, forks, and colliders. These (in)dependencies apply to any data set generated by a causal model with those structures, regardless of the specific functions attached to the SCM [@Pearl_et_al_2016, pp. 36]. For instance, applying the BNF to the chain structure depicted in the SCM [-@fig-scm_bb3] and DAG [-@fig-mdag_bb3] allow researchers to represent the joint distribution for the observed variables as $P(X_{1},X_{2},X_{3}) =$ $P(X_{1}) P(X_{2} \cond X_{1}) P(X_{3} \cond X_{2})$. This expression implies that $X_{1}$ and $X_{3}$ are unconditionally dependent $(X_{1} \ndsep X_{3})$, but conditionally independent when controlling for $X_{2}$ $(X_{1} \dsep X_{3} \cond X_{2})$. Moreover, in the fork structure shown in the SCM [-@fig-scm_bb4] and DAG [-@fig-mdag_bb4], researchers can express the joint distribution of the observed variables as $P(X_{1},X_{2},X_{3}) =$ $P(X_{1} \cond X_{2}) P(X_{2}) P(X_{3} \cond X_{2})$. Similar to the chain structure, this expression allows researchers to further infer that $X_{1}$ and $X_{3}$ are unconditionally dependent $(X_{1} \ndsep X_{3})$, but conditionally independent when controlling for $X_{2}$ $(X_{1} \dsep X_{3} \cond X_{2})$. Finally, researchers analyzing the collider structure illustrated in the SCM [-@fig-scm_bb5] and DAG [-@fig-mdag_bb5] can express the joint distribution of the observed variables as $P(X_{1},X_{2},X_{3}) =$ $P(X_{1}) P(X_{2} \cond X_{1}, X_{3}) P(X_{3})$. This representation allows researchers to infer that $X_{1}$ and $X_{3}$ are unconditionally independent $(X_{1} \dsep X_{3})$, but conditionally dependent when controlling for $X_{2}$ $(X_{1} \ndsep X_{3} \cond X_{2})$. The authors @Pearl_et_al_2016 [pp. 37, 40, 41] and @Neal_2020 [pp. 25–26] provide the mathematical proofs for these conclusions.

<!-- These (in)dependencies will be true of every data set generated by a causal model with that graphical structure, regardless of the specific functions attached to the SCM [@Pearl_et_al_2016, pp. 36]. -->


<!-- 5. Continuing with the motivating example -->
Using these additional probabilistic insights, researchers can revisit the scenario in @sec-appendixB2. In this context, applying the BNF to the SCM [-@fig-scm_example2] structure, enables the representation of the joint probability distribution of the observed variables as $P(Y, T, X) =$ $P(Y \cond T, X) P(T \cond X) P(X)$. From this expression, researchers can infer that the outcome $Y$ is unconditionally dependent on the teaching method $T$ $(Y \ndsep T)$. This dependency arises from two key structures: a direct causal path from the teaching method $T$ to the outcome $Y$, represented by the two-connected-nodes structure $T \rightarrow Y$ (black path in DAG [-@fig-mdag_example2]), and a confounding non-causal path from the teaching method $T$ to the outcome $Y$ through the socio-economic status of the school $X$, represented by the fork structure $T \leftarrow X \rightarrow Y$ (gray path in DAG [-@fig-mdag_example2]). 


::: {#fig-example2 layout-ncol=2}

::: {#fig-scm_example2 fig-align="center"}
$$
\begin{aligned}
  X & := x \\
  T & := f_{T}(x,e_{T}) \\
  Y & := f_{Y}(T,x,e_{Y}) \\
  e_{T} & \dsep e_{X} \\
  e_{T} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Y}
\end{aligned}
$$

SCM
:::


![Conditioned DAG](images/png/mdag_example1a.png){#fig-mdag_example2 fig-align="center" width=65%}

Plausible causal structure the scenario outlined in @sec-appendixB2.
:::


#### From probability to causality {#sec-appendixB33 .appendix appendix-style=plain}

<!-- 1. Transforming probabilistic association into causation?  -->
The structural approach to causal inference translates probabilistic insights into actionable strategies seeking to identify the ACE from associational quantities. The approach achieves this by relying on the *modularity assumption*, which posits that intervening on a node alters only the causal mechanism of that node, leaving others unchanged [@Neal_2020, pp. 34].

<!-- 2. additional necessary concepts  -->
The modularity assumption underpins the concepts of manipulated graphs and Truncated Factorization, which are essential for representing interventions $P(Y_{i} \cond do(T_{i}=t))$ within SCMs and DAGs. *Manipulated graphs* simulate physical interventions by removing specific edges from a DAG, while preserving the remaining structure unchanged [@Neal_2020, pp. 34]. In parallel, *Truncated Factorization* (TF) achieves a similar simulation by removing specific functions from the conceptual model and replacing them with constants, while keeping the rest of the structure unchanged [@Pearl_2010]. The probabilistic implications of this factorization are formalized in @eq-trunc_factor, where $S$ represents the subset of variables $X_{p}$ directly influenced by the intervention, while an example illustrating these concepts follows below.

$$
P(X_{1}, X_{2}, \dots, X_{P} \cond do(S)) =
\begin{cases}
  \prod P(X_{p} \cond pa(X_{p}) ) & \text{if} \: p \not\in S \\
  1 \quad & \text{otherwise}
\end{cases}
$$ {#eq-trunc_factor}


<!-- 3. How to use these concepts to finally define the ACE -->
Using the TF, researchers can define the *backdoor adjustment* to identify the ACE. This adjustment states that if a variable $X_{p} \in S$ serves as a *sufficient adjustment set* for the effect of $X_{a}$ on $X_{b}$, then the ACE can be identified using @eq-backdoor [@Pearl_2009; @Pearl_et_al_2016; @Morgan_et_al_2014]. The sufficient adjustment set (potentially empty) must block all non-causal paths between $X_{a}$ and $X_{b}$ without introducing new paths. If such a set exists, then $X_{a}$ and $X_{b}$ are *d-separated* by $X_{p}$ ($X_{a} \dsep X_{b} \cond X_{p}$) [@Pearl_2009], and $X_{p}$ satisfies the *backdoor criterion* [@Neal_2020, pp. 37].

$$
P(X_{a} \cond do(X_{b}=x)) = \sum_{Xp} P(X_{a} \cond X_{b}=x, X_{p}) P(X_{p})
$$ {#eq-backdoor}

Ultimately, the backdoor adjustment enables researchers to express the ACE as:

$$
\begin{aligned}
\tau & = E[X_{a} \cond do(X_{b}=1)]- E[X_{a} \cond do(X_{b}=2)] \\
  & = E_{Xp}\left[ E[X_{a} \cond do(X_{b}=1), X_{p}]- E[X_{a} \cond do(X_{b}=2), X_{p}] \right] \\
  & = \sum_{Xp} X_{a} \cdot P(X_{a} \cond X_{b}=1, X_{p}) \cdot P(X_{p}) - \sum_{Xp} X_{a} \cdot P(X_{a} \cond X_{b}=2, X_{p}) \cdot P(X_{p})
\end{aligned}
$$ {#eq-backdoor_adjustment}


<!-- 4. revisiting the motivating example -->
With these new insights, researchers revisiting the scenario in @sec-appendixB32 can infer that the socio-economic status of the school, $X$, satisfies the backdoor criterion, assuming the causal structure depicted by the SCM [-@fig-scm_example2] and DAG [-@fig-mdag_example2] is correct. This means that $X$ serves as a sufficient adjustment set, as it effectively blocks all confounding non-causal paths introduced by the fork structure. Nevertheless, since $Y$ remains dependent on $T$ even after conditioning $(Y \ndsep T \cond X)$, this dependency can only be attributed to the direct causal effect $T \rightarrow Y$. Notably, for the purpose of identification, the conditioned DAG [-@fig-mdag_example2] is equivalent to the manipulated DAG [-@fig-mdag_example3], because $X$ satisfies the backdoor criterion.

::: {#fig-example3 layout-ncol=2}

::: {#fig-scm_example3 fig-align="center"}
$$
\begin{aligned}
  X & := f_{X}(e_{X}) \\
  T & := t \\
  Y & := f_{Y}(t,X,e_{Y}) \\
  e_{T} & \dsep e_{X} \\
  e_{T} & \dsep e_{Y} \\
  e_{X} & \dsep e_{Y}
\end{aligned}
$$

SCM
:::

![Manipulated DAG](images/png/mdag_example1b.png){#fig-mdag_example3 fig-align="center" width=65%}

Plausible causal structure the scenario outlined in @sec-appendixB32.
:::


Researchers can then apply the *backdoor adjustment* to identify the ACE of $T$ on $Y$. They achieve this by first identifying the CACE of $T$ on $Y$ by conditioning on $X$, and then marginalizing this effect over $X$ to obtain the ACE. This process is expressed in @eq-mACE2 (see @sec-appendixB2). 

$$
\begin{aligned}
  \tau & = E[Y_{i} \cond do(T_{i}=1)]- E[Y_{i} \cond do(T_{i}=2)] \\
  & = E_{X}\left[ E[Y_{i} \cond T_{i}=1, X] - E[Y_{i} \cond T_{i}=2, X] \right] \\
  & = \sum_{X} Y_{i} \cdot P( Y_{i} \cond T_{i}=1, X) \cdot P(X) - \sum_{X} Y_{i} \cdot P( Y_{i} \cond T_{i}=2, X) \cdot P(X)
\end{aligned}
$$ {#eq-mACE2}



#### The estimation process {#sec-appendixB34 .appendix appendix-style=plain}

<!-- 1. How do we use Bayesian inference? -->
Ultimately, researchers can use Bayesian inference methods to estimate the ACE. The approach begins by defining two probability distributions: the likelihood of the data, $P(X_{1}, X_{2}, \dots, X_{P} \cond \theta)$, and the prior distribution, $P(\theta)$ [@Everitt_et_al_2010], where $X_{P}$ represents a random variable, and $\theta$ represents a one-dimensional parameter space for simplicity. After observing empirical data, researchers can update the priors to posterior distributions using Bayes' rule in @eq-bayes_rule [@Jeffreys_1998]:

$$
P(\theta \cond X_{1}, X_{2}, \dots, X_{P}) = \frac{P(X_{1}, X_{2}, \dots, X_{P} \cond \theta) \cdot P(\theta)}{P(X_{1}, X_{2}, \dots, X_{P})}
$$ {#eq-bayes_rule}


Given that the denominator on the right-hand side of @eq-bayes_rule serves as a normalizing constant independent of the parameter $\theta$, researchers can simplify the posterior updating process into three steps. First, they integrate new empirical data through the likelihood. Second, they update the parameters' priors to a posterior distribution according to @eq-prop_rule. Ultimately, they normalize these results to obtain a valid probability distribution.

$$
P(\theta \cond X_{1}, X_{2}, \dots, X_{P}) \propto P(X_{1}, X_{2}, \dots, X_{P}\cond \theta) \cdot P(\theta)
$$ {#eq-prop_rule}

<!-- check: -->
<!-- https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation -->
<!-- https://en.wikipedia.org/wiki/Bayesian_inference -->

<!-- 2. But what is the problem? -->

Temporarily setting aside the definition of prior distributions $P(\theta)$, note that the posterior updating process depends heavily on the assumptions underlying the likelihood of the data. However, as the number of random variables, $P$, increases, this joint distribution quickly becomes intractable [@Neal_2020]. This intractability is evident from @eq-like_chain, where the likelihood distribution is expressed by multiple chained CPDs.

$$
P(X_{1}, X_{2}, \dots, X_{P} \cond \theta) = P(X_{1} \cond \theta) \prod^{P}_{p=2} P(X_{i} \cond X_{i-1}, \dots, X_{1}, \theta )
$$ {#eq-like_chain}


<!-- 3. How do DAGs can help? -->
Nevertheless, researchers can manage the complexity of the likelihood by assuming specific local (in)dependencies among variables. SCMs and DAGs provide a formal framework to represent these assumptions, as detailed in @sec-appendixB32. These assumptions improve model tractability and simplify the estimation process by enabling the derivation of the BNF of the likelihood (@eq-like_BNF). With this simplified structure, any probabilistic programming language can model the system and compute the parameter's posterior distribution using @eq-bayes_rule.

$$
P(X_{1}, X_{2}, \dots, X_{P} \cond \theta) = P(X_{1} \cond \theta) \prod^{P}_{p=2} P(X_{i} \cond pa(X_{i}), \theta )
$$ {#eq-like_BNF}


{{< pagebreak >}}

# References {.unnumbered .appendix appendix-style=plain} 

<!-- {.unnumbered} -->

:::{#refs}

:::